{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "703636c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b93767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f300813a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288b542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import numpy as np\n",
    "# import networkx as nx\n",
    "# import torch\n",
    "# from multiprocessing import Pool\n",
    "\n",
    "# def initialize_graph():\n",
    "#     coordinates = pd.read_csv(\"vienna_dist.csv\", header=None, sep=' ')\n",
    "#     coordinates.columns = ['coord1', 'coord2', 'dist']\n",
    "#     graph = nx.DiGraph()\n",
    "\n",
    "#     for _, row in coordinates.iterrows():\n",
    "#         graph.add_edge(row['coord1'], row['coord2'], weight=row['dist'])\n",
    "\n",
    "#     return graph\n",
    "\n",
    "# def compute_distance(graph, node_ids):\n",
    "#     distances = []\n",
    "#     for i, id1 in enumerate(node_ids):\n",
    "#         row = []\n",
    "#         for j, id2 in enumerate(node_ids):\n",
    "#             shortest_path = nx.shortest_path(graph, id1, id2)\n",
    "#             shortest_path_distance = sum(graph.get_edge_data(u, v)['weight'] for u, v in zip(shortest_path, shortest_path[1:]))\n",
    "#             row.append(shortest_path_distance)\n",
    "#         distances.append(row)\n",
    "#     return distances\n",
    "\n",
    "# def precompute_distance_matrix(graph, node_ids, save_path):\n",
    "#     num_nodes = len(node_ids)\n",
    "\n",
    "#     # Use multiprocessing to parallelize distance computation\n",
    "#     with Pool() as pool:\n",
    "#         result = pool.starmap(compute_distance, [(graph, [id1]) for id1 in node_ids])\n",
    "\n",
    "#     # Convert result to numpy array\n",
    "#     distance_matrix = np.array(result).reshape((num_nodes, num_nodes, 1))\n",
    "\n",
    "#     # Save distance matrix as a pickle file\n",
    "#     with open(save_path, 'wb') as f:\n",
    "#         pickle.dump(distance_matrix, f)\n",
    "\n",
    "#     return distance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c866a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# def initialize_graph():\n",
    "    \n",
    "#         coordinates = pd.read_csv(\"vienna_dist.csv\", header = None, sep=' ')\n",
    "#         coordinates.columns = ['coord1','coord2','dist']\n",
    "#         graph = nx.DiGraph()\n",
    "\n",
    "#         # add the rows to the graph for shortest path and distance calculations\n",
    "#         for _, row in coordinates.iterrows():\n",
    "#             graph.add_edge(row['coord1'], row['coord2'], weight=row['dist'])\n",
    "\n",
    "#         return graph\n",
    "\n",
    "# def precompute_distance_matrix(graph, node_ids, save_path):\n",
    "#     num_nodes = len(node_ids)\n",
    "#     distance_matrix = torch.zeros((num_nodes, num_nodes, 1))\n",
    "#     for i, id1 in enumerate(node_ids):\n",
    "#         for j, id2 in enumerate(node_ids):\n",
    "            \n",
    "#             shortest_path = nx.shortest_path(graph, start_node, end_node)\n",
    "\n",
    "#             # TODO: distance need to be normalized afterwords\n",
    "#             shortest_path_distace = sum(graph.get_edge_data(u, v)['weight'] \n",
    "#                                    for u, v in zip(shortest_path, shortest_path[1:]))\n",
    "#             distance_matrix[i, j, 0] = shortest_path_distace\n",
    "            \n",
    "#         if i%100 == 0:\n",
    "#             print('distance calculataed till id: {}'.format(i))\n",
    "#     # Save distance matrix as a pickle file\n",
    "#     with open(save_path, 'wb') as f:\n",
    "#         pickle.dump(distance_matrix, f)\n",
    "#     return distance_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c0f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distance_matrix import *\n",
    "graph = initialize_graph()\n",
    "save_path = '.\\distance_matrix'\n",
    "data_vienna = pd.read_csv('vienna_cordinates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5dabe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_id = data_vienna['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e66ff87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            0\n",
       "1            1\n",
       "2            2\n",
       "3            3\n",
       "4            4\n",
       "         ...  \n",
       "16075    16075\n",
       "16076    16076\n",
       "16077    16077\n",
       "16078    16078\n",
       "16079    16079\n",
       "Name: id, Length: 16080, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b4c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = precompute_distance_matrix(graph, nodes_id, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88db8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d503e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DVRPSR_Dataset(Dataset):\n",
    "\n",
    "    customer_feature = 4 # customer features location (x_i,y_i) and duration of service(d), appearance (u)\n",
    "\n",
    "    @classmethod\n",
    "    def create_data(cls,\n",
    "                    batch_size = 2,\n",
    "                    vehicle_count = 2,\n",
    "                    vehicle_speed = 1,\n",
    "                    Lambda = 0.025, # request rate per min\n",
    "                    dod = 0.5,\n",
    "                    horizon = 400,\n",
    "                    fDmean = 10,\n",
    "                    fDstd = 2.5):\n",
    "\n",
    "\n",
    "        # static customer counts V = Lambda*horizon*(1-dod)/(dod+0.5)\n",
    "        V_static = int(Lambda*horizon*(1-dod)/(dod)+0.5)\n",
    "\n",
    "        # total customer count\n",
    "        V = int(Lambda*horizon/(dod) + 0.5)\n",
    "\n",
    "        size = (batch_size, V, 1)\n",
    "        \n",
    "        # initialize the graph of vienna network\n",
    "        graph = cls.initialize_graph()\n",
    "\n",
    "        # get the coordinates of customers\n",
    "        data_vienna = pd.read_csv('vienna_cordinates.csv')\n",
    "\n",
    "        # get depot coordinates: Id, xcoords, ycoords\n",
    "        depot = cls.get_depot_location(data_vienna)\n",
    "\n",
    "        # get location of customers: id, xcoords, ycoords\n",
    "        locations = cls.get_customers_coordinates(data_vienna, batch_size, V, depot)\n",
    "\n",
    "        # get edges index and attributes, which is distance between one node to others n_i*n_j\n",
    "        edges_index, edges_attributes = cls.get_edges_attributes(batch_size, graph, depot, locations, V)\n",
    "        \n",
    "        ### generate Static_Dynamic customer requests\n",
    "        dynamic_request = cls.generateRandomDynamicRequests(batch_size,\n",
    "                                                            V,\n",
    "                                                            V_static,\n",
    "                                                            fDmean,\n",
    "                                                            fDstd,\n",
    "                                                            Lambda,\n",
    "                                                            horizon)\n",
    "\n",
    "        customers = torch.zeros((batch_size,V,cls.customer_feature))\n",
    "        customers[:,:,:2] = locations[:,:,1:]\n",
    "        customers[:,:,2:4] = dynamic_request\n",
    "\n",
    "\n",
    "\n",
    "        depo = torch.zeros((batch_size, 1, cls.customer_feature))\n",
    "        depo[:,:,0:2] = torch.from_numpy(depot[0][1:])\n",
    "        depo[:,:,2] =  0\n",
    "\n",
    "        nodes = torch.cat((depo, customers), 1)\n",
    "        \n",
    "        dataset = cls(vehicle_count, vehicle_speed, horizon, nodes, V, \n",
    "                      edges_index, edges_attributes, customer_mask = None)\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    def __init__(self, vehicle_count, vehicle_speed, horizon, nodes, V,\n",
    "                 edges_index, edges_attributes, customer_mask=None):\n",
    "        \n",
    "        self.vehicle_count = vehicle_count\n",
    "        self.vehicle_speed = vehicle_speed\n",
    "        self.nodes = nodes\n",
    "        self.vehicle_time_budget = horizon\n",
    "        self.edges_index = edges_index\n",
    "        self.edges_attributes = edges_attributes\n",
    "\n",
    "        self.batch_size, self.nodes_count, d = self.nodes.size()\n",
    "\n",
    "        if d!= self.customer_feature:\n",
    "            raise ValueError(\"Expected {} customer features per nodes, got {}\".format(\n",
    "                self.customer_feature, d))\n",
    "\n",
    "        self.customer_mask = customer_mask\n",
    "        self.customer_count = V\n",
    "        \n",
    "        \n",
    "    def initialize_graph():\n",
    "    \n",
    "        coordinates = pd.read_csv(\"vienna_dist.csv\", header = None, sep=' ')\n",
    "        coordinates.columns = ['coord1','coord2','dist']\n",
    "        graph = nx.DiGraph()\n",
    "\n",
    "        # add the rows to the graph for shortest path and distance calculations\n",
    "        for _, row in coordinates.iterrows():\n",
    "            graph.add_edge(row['coord1'], row['coord2'], weight=row['dist'])\n",
    "\n",
    "        return graph\n",
    "\n",
    "\n",
    "    def precompute_shortest_path(graph, start_node, end_node):\n",
    "\n",
    "        shortest_path = nx.shortest_path(graph, start_node, end_node)\n",
    "\n",
    "        # TODO: distance need to be normalized afterwords\n",
    "        shortest_path_length = sum(graph.get_edge_data(u, v)['weight'] \n",
    "                                   for u, v in zip(shortest_path, shortest_path[1:]))\n",
    "\n",
    "        return shortest_path, shortest_path_length\n",
    "    \n",
    "    \n",
    "    def get_distanceLL(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "        R = 6371  # Radius of the Earth in kilometers\n",
    "\n",
    "        lat1_rad = math.radians(lat1)\n",
    "        lon1_rad = math.radians(lon1)\n",
    "        lat2_rad = math.radians(lat2)\n",
    "        lon2_rad = math.radians(lon2)\n",
    "\n",
    "        dlat = lat2_rad - lat1_rad\n",
    "        dlon = lon2_rad - lon1_rad\n",
    "\n",
    "        a = math.sin(dlat / 2) ** 2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2) ** 2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "        distance = R * c\n",
    "        return distance\n",
    "    \n",
    "\n",
    "    def get_NearestNodeLL(lat, lon, lats, lons):\n",
    "        nearest = (-1, sys.float_info.max)\n",
    "        for i in range(len(lats)):\n",
    "            dist = DVRPSR_Dataset.get_distanceLL(lat, lon, lats[i], lons[i])\n",
    "            if dist < nearest[1]:\n",
    "                nearest = (i, dist)\n",
    "        return nearest[0]\n",
    "    \n",
    "\n",
    "\n",
    "    def get_depot_location(data_vienna):\n",
    "\n",
    "        ll = (48.178808, 16.438460)\n",
    "        lat = ll[0] / 180 * math.pi\n",
    "        lon = ll[1] / 180 * math.pi\n",
    "        lats = data_vienna['lats']\n",
    "        lons = data_vienna['lons']\n",
    "        depot = DVRPSR_Dataset.get_NearestNodeLL(lat, lon, lats, lons)\n",
    "        depot_coordinates = np.array(data_vienna[data_vienna['id']==depot][['id','xcoords', 'ycoords']])\n",
    "\n",
    "        return depot_coordinates\n",
    "    \n",
    "    def get_customers_coordinates(data_vienna, batch_size, customers_count, depot):\n",
    "        # Set random seed for reproducibility\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # Excluding depot id from the customers selection\n",
    "        data_vienna_without_depot = data_vienna[data_vienna['id'] != int(depot[0][0])].reset_index()\n",
    "\n",
    "        # Sample customers indices for all batches at once\n",
    "        sampled_customers = torch.multinomial(torch.tensor(data_vienna_without_depot['id'], dtype=torch.float),\n",
    "                                              num_samples=batch_size * customers_count, replacement=True)\n",
    "        \n",
    "        sampled_customers = sampled_customers.reshape(batch_size, customers_count)\n",
    "\n",
    "        # Gather the sampled locations using the indices\n",
    "        sampled_locations = data_vienna_without_depot.loc[sampled_customers.flatten()].reset_index(drop=True)\n",
    "\n",
    "        # Reshape the locations to match the batch size\n",
    "        locations = sampled_locations.groupby(sampled_locations.index // customers_count)\n",
    "\n",
    "        # Create PyTorch tensors for the batched data\n",
    "        locations_tensors = []\n",
    "        for _, batch in locations:\n",
    "            id_tensor = torch.tensor(batch['id'].values, dtype=torch.long)\n",
    "            coords_tensor = torch.tensor(batch[['xcoords', 'ycoords']].values, dtype=torch.float)\n",
    "            batch_tensor = torch.cat((id_tensor.unsqueeze(1), coords_tensor), dim=1)\n",
    "            locations_tensors.append(batch_tensor)\n",
    "\n",
    "        return torch.stack(locations_tensors)\n",
    "\n",
    "    \n",
    "    def precompute_distance_matrix(graph, node_ids):\n",
    "        num_nodes = len(node_ids)\n",
    "        distance_matrix = torch.zeros((num_nodes, num_nodes, 1))\n",
    "        for i, id1 in enumerate(node_ids):\n",
    "            for j, id2 in enumerate(node_ids):\n",
    "                _, distance = DVRPSR_Dataset.precompute_shortest_path(graph, int(id1), int(id2))\n",
    "                distance_matrix[i, j, 0] = distance\n",
    "        return distance_matrix\n",
    "    \n",
    "\n",
    "    def get_edges_attributes(batch_size, graph, depot, locations, V):\n",
    "        # All customers ID including depot\n",
    "        edge_depot = torch.full((batch_size, 1, 1), depot[0][0])\n",
    "        edge_data = torch.cat((edge_depot, locations[:, :, None, 0]), dim=1)\n",
    "\n",
    "        # Generate edge index\n",
    "        edges_index = torch.cartesian_prod(torch.arange(V+1), torch.arange(V+1)).T\n",
    "        \n",
    "        print('**edge** process')\n",
    "\n",
    "        # Precalculate distance matrix\n",
    "        distance_matrix = DVRPSR_Dataset.precompute_distance_matrix(graph, edge_data.flatten().unique())\n",
    "\n",
    "        # Generate nodes attributes\n",
    "        edges_batch = []\n",
    "        for batch in edge_data:\n",
    "            distances = distance_matrix[batch.long().squeeze()]\n",
    "            edges_batch.append(distances.reshape(-1, 1))\n",
    "\n",
    "        return edges_index, torch.stack(edges_batch)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def generateRandomDynamicRequests(batch_size=2 ,\n",
    "                                      V=20,\n",
    "                                      V_static=10,\n",
    "                                      fDmean=10,\n",
    "                                      fDstd=2.5,\n",
    "                                      Lambda=0.025,\n",
    "                                      horizon=400,\n",
    "                                      dep = 0,\n",
    "                                      u = 0):\n",
    "        gen = random.Random()\n",
    "        gen.seed() # uses the default system seed\n",
    "        unifDist = gen.random # uniform distribution\n",
    "        durDist = lambda: max(0.01, gen.gauss(fDmean, fDstd)) # normal distribution with fDmean and fDstd\n",
    "\n",
    "        # TODO: in actual data , we need to add a depo node with corrdinate, which should be removed from selected\n",
    "        #       nodes as well.\n",
    "\n",
    "        requests = []\n",
    "        for b in range(batch_size):\n",
    "\n",
    "            static_request = []\n",
    "            dynamic_request = []\n",
    "            u = 0\n",
    "\n",
    "            while True:\n",
    "                unif = unifDist()\n",
    "                u += -(1/Lambda) * math.log(unif)\n",
    "                if u > horizon or len(dynamic_request) > (V-V_static+2):\n",
    "                    break\n",
    "                d = round(durDist(),2)\n",
    "                while d<=0:\n",
    "                    d = round(durDist(),2)\n",
    "\n",
    "                dynamic_request.append([d, round(u,2)])\n",
    "\n",
    "            for j in range(V-len(dynamic_request)):\n",
    "                d = round(durDist(),2)\n",
    "                while d<=0:\n",
    "                    d = round(durDist(),2)\n",
    "                static_request.append([d,0])\n",
    "\n",
    "            request = static_request+dynamic_request\n",
    "            random.shuffle(request)\n",
    "            requests.append(request)\n",
    "\n",
    "        return torch.tensor(requests)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.customer_mask is None:\n",
    "            return self.nodes[i]\n",
    "        else:\n",
    "            return self.nodes[i], self.customer_mask[i]\n",
    "\n",
    "    def nodes_generate(self):\n",
    "        if self.customer_mask is None:\n",
    "            yield from self.nodes\n",
    "        else:\n",
    "            yield from (n[m^1] for n,m in zip(self.nodes, self.customer_mask))  \n",
    "            \n",
    "            \n",
    "    def normalize(self):\n",
    "        loc_max, loc_min = self.nodes[:,:,:2].max().item(), self.nodes[:,:,:2].min().item()\n",
    "        loc_max -= loc_min\n",
    "\n",
    "        self.nodes[:,:,:2] -= loc_min\n",
    "        self.nodes[:,:,:2] /= loc_max\n",
    "        self.nodes[:,:,2:] /=self.vehicle_time_budget\n",
    "\n",
    "        self.veh_speed *= self.vehicle_time_budget/loc_max\n",
    "        self.vehicle_time_budget = 1\n",
    "        return loc_max, 1\n",
    "\n",
    "    def save(self, folder_path):\n",
    "        torch.save({\n",
    "            'veh_count':self.veh_count,\n",
    "            'veh_speed':self.veh_speed,\n",
    "            'nodes':self.nodes,\n",
    "            'cust_mask':self.cust_mask\n",
    "        }, folder_path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, folder_path):\n",
    "        return cls(**torch.load(folder_path))\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9250dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DVRPSR_Dataset.create_data(batch_size=1, vehicle_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d58aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccfdc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92864110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb284f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6905a602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0764f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b1216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58ea391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d09bc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f4b69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fc582b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb8e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afc1b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73abcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb67268b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
