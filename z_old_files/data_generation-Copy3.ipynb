{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "703636c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db32c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_graph():\n",
    "    \n",
    "        coordinates = pd.read_csv(\"../vienna_data/vienna_dist.csv\", header = None, sep=' ')\n",
    "        coordinates.columns = ['coord1','coord2','dist']\n",
    "        graph = nx.DiGraph()\n",
    "\n",
    "        # add the rows to the graph for shortest path and distance calculations\n",
    "        for _, row in coordinates.iterrows():\n",
    "            graph.add_edge(row['coord1'], row['coord2'], weight=row['dist'])\n",
    "\n",
    "        return graph\n",
    "\n",
    "\n",
    "def precompute_shortest_path(graph, start_node, end_node):\n",
    "\n",
    "    shortest_path = nx.shortest_path(graph, start_node, end_node)\n",
    "\n",
    "    # TODO: distance need to be normalized afterwords\n",
    "    shortest_path_length = sum(graph.get_edge_data(u, v)['weight'] \n",
    "                               for u, v in zip(shortest_path, shortest_path[1:]))\n",
    "\n",
    "    return shortest_path_length \n",
    "\n",
    "\n",
    "def get_distanceLL(lat1, lon1, lat2, lon2):\n",
    "\n",
    "    R = 6371  # Radius of the Earth in kilometers\n",
    "\n",
    "    lat1_rad = math.radians(lat1)\n",
    "    lon1_rad = math.radians(lon1)\n",
    "    lat2_rad = math.radians(lat2)\n",
    "    lon2_rad = math.radians(lon2)\n",
    "\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    a = math.sin(dlat / 2) ** 2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "\n",
    "def get_NearestNodeLL(lat, lon, lats, lons):\n",
    "    nearest = (-1, sys.float_info.max)\n",
    "    for i in range(len(lats)):\n",
    "        dist = get_distanceLL(lat, lon, lats[i], lons[i])\n",
    "        if dist < nearest[1]:\n",
    "            nearest = (i, dist)\n",
    "    return nearest[0]\n",
    "\n",
    "\n",
    "\n",
    "def get_depot_location(data_vienna):\n",
    "\n",
    "    ll = (48.178808, 16.438460)\n",
    "    lat = ll[0] / 180 * math.pi\n",
    "    lon = ll[1] / 180 * math.pi\n",
    "    lats = data_vienna['lats']\n",
    "    lons = data_vienna['lons']\n",
    "    depot = get_NearestNodeLL(lat, lon, lats, lons)\n",
    "    depot_coordinates = np.array(data_vienna[data_vienna['id']==depot][['id','xcoords', 'ycoords']])\n",
    "\n",
    "    return depot_coordinates\n",
    "\n",
    "def get_customers_coordinates(data_vienna, batch_size, customers_count, depot):\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Excluding depot id from the customers selection\n",
    "    data_vienna_without_depot = data_vienna[data_vienna['id'] != int(depot[0][0])].reset_index()\n",
    "\n",
    "    # Sample customers indices for all batches at once\n",
    "    sampled_customers = torch.multinomial(torch.tensor(data_vienna_without_depot['id'], dtype=torch.float),\n",
    "                                          num_samples=batch_size * customers_count, replacement=True)\n",
    "\n",
    "    sampled_customers = sampled_customers.reshape(batch_size, customers_count)\n",
    "\n",
    "    # Gather the sampled locations using the indices\n",
    "    sampled_locations = data_vienna_without_depot.loc[sampled_customers.flatten()].reset_index(drop=True)\n",
    "\n",
    "    # Reshape the locations to match the batch size\n",
    "    locations = sampled_locations.groupby(sampled_locations.index // customers_count)\n",
    "\n",
    "    # Create PyTorch tensors for the batched data\n",
    "    locations_tensors = []\n",
    "    for _, batch in locations:\n",
    "        id_tensor = torch.tensor(batch['id'].values, dtype=torch.long)\n",
    "        coords_tensor = torch.tensor(batch[['xcoords', 'ycoords']].values, dtype=torch.float)\n",
    "        batch_tensor = torch.cat((id_tensor.unsqueeze(1), coords_tensor), dim=1)\n",
    "        locations_tensors.append(batch_tensor)\n",
    "\n",
    "    return torch.stack(locations_tensors)\n",
    "\n",
    "def get_edges_attributes(batch_size, graph, depot, locations, V):\n",
    "\n",
    "    # all customers ID inclusing depot\n",
    "\n",
    "    print('Initialzing edges')\n",
    "    edge_depot = torch.zeros((batch_size, 1, 1))\n",
    "    edge_depot[:,:,:1] = depot[0][0]\n",
    "    edge_data = torch.cat((edge_depot, locations[:,:,None,0]), dim=1)\n",
    "\n",
    "    # generate edge index\n",
    "    edges_index = []\n",
    "\n",
    "    for i in range(V+1):\n",
    "        for j in range(V+1):\n",
    "            edges_index.append([i, j])\n",
    "    edges_index = torch.LongTensor(edges_index)\n",
    "    edges_index = edges_index.transpose(dim0=0,dim1=1)\n",
    "\n",
    "    # generate nodes attributes\n",
    "    edges_batch = []\n",
    "\n",
    "    for batch in edge_data:\n",
    "        edges = np.zeros((V+1, V+1, 1))\n",
    "        for i, id1 in enumerate(batch):\n",
    "            for j, id2 in enumerate(batch):\n",
    "                distance = precompute_shortest_path(graph, int(id1), int(id2))\n",
    "                edges[i][j][0] = distance\n",
    "\n",
    "        edges = edges.reshape(-1, 1)\n",
    "        edges_batch.append(torch.from_numpy(edges))\n",
    "\n",
    "    return edges_index, torch.stack(edges_batch)\n",
    "\n",
    "\n",
    "def generateRandomDynamicRequests(batch_size=2 ,\n",
    "                                  V=20,\n",
    "                                  V_static=10,\n",
    "                                  fDmean=10,\n",
    "                                  fDstd=2.5,\n",
    "                                  Lambda=0.025,\n",
    "                                  horizon=400,\n",
    "                                  dep = 0,\n",
    "                                  u = 0):\n",
    "    gen = random.Random()\n",
    "    gen.seed() # uses the default system seed\n",
    "    unifDist = gen.random # uniform distribution\n",
    "    durDist = lambda: max(0.01, gen.gauss(fDmean, fDstd)) # normal distribution with fDmean and fDstd\n",
    "\n",
    "    # TODO: in actual data , we need to add a depo node with corrdinate, which should be removed from selected\n",
    "    #       nodes as well.\n",
    "\n",
    "    requests = []\n",
    "    for b in range(batch_size):\n",
    "\n",
    "        static_request = []\n",
    "        dynamic_request = []\n",
    "        u = 0\n",
    "\n",
    "        while True:\n",
    "            unif = unifDist()\n",
    "            u += -(1/Lambda) * math.log(unif)\n",
    "            if u > horizon or len(dynamic_request) > (V-V_static+2):\n",
    "                break\n",
    "            d = round(durDist(),2)\n",
    "            while d<=0:\n",
    "                d = round(durDist(),2)\n",
    "\n",
    "            dynamic_request.append([d, round(u,2)])\n",
    "\n",
    "        for j in range(V-len(dynamic_request)):\n",
    "            d = round(durDist(),2)\n",
    "            while d<=0:\n",
    "                d = round(durDist(),2)\n",
    "            static_request.append([d,0])\n",
    "\n",
    "        request = static_request+dynamic_request\n",
    "        random.shuffle(request)\n",
    "        requests.append(request)\n",
    "\n",
    "    return torch.tensor(requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d503e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DVRPSR_Dataset(Dataset):\n",
    "\n",
    "    customer_feature = 4 # customer features location (x_i,y_i) and duration of service(d), appearance (u)\n",
    "\n",
    "    @classmethod\n",
    "    def create_data(cls,\n",
    "                    batch_size = 2,\n",
    "                    vehicle_count = 2,\n",
    "                    vehicle_speed = 20, # km/hr\n",
    "                    Lambda = 0.025, # request rate per min\n",
    "                    dod = 0.5,\n",
    "                    horizon = 400,\n",
    "                    fDmean = 10,\n",
    "                    fDstd = 2.5):\n",
    "\n",
    "\n",
    "        # static customer counts V = Lambda*horizon*(1-dod)/(dod+0.5)\n",
    "        V_static = int(Lambda*horizon*(1-dod)/(dod)+0.5)\n",
    "\n",
    "        # total customer count\n",
    "        V = int(Lambda*horizon/(dod) + 0.5)\n",
    "\n",
    "        size = (batch_size, V, 1)\n",
    "        \n",
    "        # initialize the graph of vienna network\n",
    "        graph = initialize_graph()\n",
    "\n",
    "        # get the coordinates of customers\n",
    "        data_vienna = pd.read_csv('../vienna_data/vienna_cordinates.csv')\n",
    "\n",
    "        # get depot coordinates: Id, xcoords, ycoords\n",
    "        depot = get_depot_location(data_vienna)\n",
    "\n",
    "        # get location of customers: id, xcoords, ycoords\n",
    "        locations = get_customers_coordinates(data_vienna, batch_size, V, depot)\n",
    "\n",
    "        # get edges index and attributes, which is distance between one node to others n_i*n_j\n",
    "        edges_index, edges_attributes = get_edges_attributes(batch_size, graph, depot, locations, V)\n",
    "        \n",
    "        ### generate Static_Dynamic customer requests\n",
    "        dynamic_request = generateRandomDynamicRequests(batch_size,\n",
    "                                                            V,\n",
    "                                                            V_static,\n",
    "                                                            fDmean,\n",
    "                                                            fDstd,\n",
    "                                                            Lambda,\n",
    "                                                            horizon)\n",
    "\n",
    "        customers = torch.zeros((batch_size,V,cls.customer_feature))\n",
    "        customers[:,:,:2] = locations[:,:,1:]\n",
    "        customers[:,:,2:4] = dynamic_request\n",
    "\n",
    "\n",
    "\n",
    "        depo = torch.zeros((batch_size, 1, cls.customer_feature))\n",
    "        depo[:,:,0:2] = torch.from_numpy(depot[0][1:])\n",
    "        depo[:,:,2] =  0\n",
    "\n",
    "        nodes = torch.cat((depo, customers), 1)\n",
    "        \n",
    "        dataset = cls(vehicle_count, vehicle_speed, horizon, nodes, V, \n",
    "                      edges_index, edges_attributes, customer_mask = None)\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    def __init__(self, vehicle_count, vehicle_speed, horizon, nodes, V,\n",
    "                 edges_index, edges_attributes, customer_mask=None):\n",
    "        \n",
    "        self.vehicle_count = vehicle_count\n",
    "        self.vehicle_speed = vehicle_speed\n",
    "        self.nodes = nodes\n",
    "        self.vehicle_time_budget = horizon\n",
    "        self.edges_index = edges_index\n",
    "        self.edges_attributes = edges_attributes\n",
    "\n",
    "        self.batch_size, self.nodes_count, d = self.nodes.size()\n",
    "\n",
    "        if d!= self.customer_feature:\n",
    "            raise ValueError(\"Expected {} customer features per nodes, got {}\".format(\n",
    "                self.customer_feature, d))\n",
    "\n",
    "        self.customer_mask = customer_mask\n",
    "        self.customer_count = V\n",
    "    \n",
    "     \n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.customer_mask is None:\n",
    "            return self.nodes[i]\n",
    "        else:\n",
    "            return self.nodes[i], self.customer_mask[i]\n",
    "\n",
    "    def nodes_generate(self):\n",
    "        if self.customer_mask is None:\n",
    "            yield from self.nodes\n",
    "        else:\n",
    "            yield from (n[m^1] for n,m in zip(self.nodes, self.customer_mask))  \n",
    "            \n",
    "            \n",
    "    def normalize(self):\n",
    "        loc_max, loc_min = self.nodes[:,:,:2].max().item(), self.nodes[:,:,:2].min().item()\n",
    "        loc_max -= loc_min\n",
    "        edge_max_length = self.edges_attributes[:,:,0].max().item()\n",
    "\n",
    "        self.nodes[:,:,:2] -= loc_min\n",
    "        self.nodes[:,:,:2] /= loc_max\n",
    "        self.nodes[:,:,2:] /=self.vehicle_time_budget\n",
    "\n",
    "        self.vehicle_speed *= self.vehicle_time_budget/edge_max_length\n",
    "        self.vehicle_time_budget = 1\n",
    "        return loc_max, 1\n",
    "\n",
    "    def save(self, folder_path):\n",
    "        torch.save({\n",
    "            'veh_count':self.vehicle_count,\n",
    "            'veh_speed':self.vehicle_speed,\n",
    "            'nodes':self.nodes,\n",
    "            'edges_index':self.edges_index,\n",
    "            'edges_attributes':self.edges_attributes,\n",
    "            'customer_count':self.customer_count,\n",
    "            'cust_mask':self.cust_mask\n",
    "        }, folder_path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, folder_path):\n",
    "        return cls(**torch.load(folder_path))\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9250dd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialzing edges\n"
     ]
    }
   ],
   "source": [
    "data = DVRPSR_Dataset.create_data(batch_size=1, vehicle_count=2, Lambda=0.0125, dod=0.5, horizon=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "17c231c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5348e+02, -2.7868e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 1.3548e+02,  6.3629e+00,  1.3980e+01,  3.3848e+02],\n",
       "         [ 1.3853e+02,  4.1748e+01,  1.3850e+01,  1.3171e+02],\n",
       "         [ 1.5720e+02,  3.8793e+01,  7.7900e+00,  1.5093e+02],\n",
       "         [ 1.2608e+02,  1.9041e+00,  9.2000e+00,  3.4049e+02],\n",
       "         [ 1.3274e+02,  7.2597e+00,  1.1460e+01,  0.0000e+00],\n",
       "         [ 1.1312e+02, -7.5473e-02,  1.0030e+01,  0.0000e+00],\n",
       "         [ 1.2074e+02,  1.7892e+01,  1.2050e+01,  6.1810e+01],\n",
       "         [ 1.4845e+02, -8.4152e+00,  1.1620e+01,  3.1111e+02],\n",
       "         [ 1.3364e+02, -4.9474e+00,  8.5200e+00,  1.9118e+02],\n",
       "         [ 1.3663e+02,  2.6947e+00,  9.9400e+00,  1.1331e+02]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e3ca49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[    0.0000],\n",
       "         [ 8528.7071],\n",
       "         [21696.1956],\n",
       "         [19061.6620],\n",
       "         [11161.3693],\n",
       "         [ 9821.1578],\n",
       "         [18955.1887],\n",
       "         [24534.7807],\n",
       "         [ 3749.3110],\n",
       "         [10543.2372],\n",
       "         [ 7620.2595],\n",
       "         [ 8808.3717],\n",
       "         [    0.0000],\n",
       "         [20078.6634],\n",
       "         [17444.1297],\n",
       "         [ 3233.8395],\n",
       "         [ 1292.4506],\n",
       "         [ 6954.6278],\n",
       "         [ 6873.3717],\n",
       "         [ 9245.7757],\n",
       "         [ 4124.6964],\n",
       "         [ 1034.3410],\n",
       "         [16867.5184],\n",
       "         [12569.9681],\n",
       "         [    0.0000],\n",
       "         [ 7453.6376],\n",
       "         [20377.9866],\n",
       "         [13862.4188],\n",
       "         [28171.8061],\n",
       "         [13206.4928],\n",
       "         [17304.9224],\n",
       "         [19759.8545],\n",
       "         [16836.8768],\n",
       "         [16346.6555],\n",
       "         [17224.4616],\n",
       "         [11525.0083],\n",
       "         [    0.0000],\n",
       "         [19857.1238],\n",
       "         [18516.9122],\n",
       "         [27650.9432],\n",
       "         [14138.3445],\n",
       "         [16784.0596],\n",
       "         [19238.9917],\n",
       "         [16316.0140],\n",
       "         [12073.8241],\n",
       "         [ 3338.7414],\n",
       "         [14262.4419],\n",
       "         [20709.5822],\n",
       "         [    0.0000],\n",
       "         [ 2661.1174],\n",
       "         [ 4236.9135],\n",
       "         [ 5729.2050],\n",
       "         [12511.2282],\n",
       "         [ 4582.6479],\n",
       "         [ 3841.2778],\n",
       "         [ 9749.1803],\n",
       "         [ 1068.2286],\n",
       "         [12825.8050],\n",
       "         [18384.9384],\n",
       "         [ 2859.6494],\n",
       "         [    0.0000],\n",
       "         [ 6580.4376],\n",
       "         [ 6336.2907],\n",
       "         [10186.5844],\n",
       "         [ 5065.5050],\n",
       "         [ 1975.1497],\n",
       "         [18945.3863],\n",
       "         [ 8795.1795],\n",
       "         [30215.6780],\n",
       "         [27581.1444],\n",
       "         [ 4213.9159],\n",
       "         [ 7051.2976],\n",
       "         [    0.0000],\n",
       "         [ 6025.7959],\n",
       "         [19382.7903],\n",
       "         [ 7109.7200],\n",
       "         [ 7697.0971],\n",
       "         [20847.4477],\n",
       "         [ 5951.8289],\n",
       "         [12265.2247],\n",
       "         [14355.4350],\n",
       "         [ 6465.3944],\n",
       "         [ 5140.2310],\n",
       "         [ 6206.0821],\n",
       "         [    0.0000],\n",
       "         [21284.8518],\n",
       "         [ 8551.6609],\n",
       "         [ 6858.7500],\n",
       "         [ 3625.7522],\n",
       "         [ 6889.1097],\n",
       "         [20513.1748],\n",
       "         [17878.6412],\n",
       "         [ 9367.8472],\n",
       "         [ 8181.5603],\n",
       "         [19497.8791],\n",
       "         [23351.7599],\n",
       "         [    0.0000],\n",
       "         [ 8038.2893],\n",
       "         [ 5826.7374],\n",
       "         [ 9972.5369],\n",
       "         [ 4131.1100],\n",
       "         [21242.8286],\n",
       "         [18608.2949],\n",
       "         [ 3842.1369],\n",
       "         [ 5423.5606],\n",
       "         [ 7299.0625],\n",
       "         [ 9276.7545],\n",
       "         [ 5146.6519],\n",
       "         [    0.0000],\n",
       "         [ 3068.7378],\n",
       "         [ 7774.0306],\n",
       "         [ 1062.3723],\n",
       "         [19044.3224],\n",
       "         [16409.7887],\n",
       "         [ 4419.9133],\n",
       "         [ 2354.8229],\n",
       "         [ 7885.7777],\n",
       "         [ 7935.7439],\n",
       "         [ 8211.4347],\n",
       "         [ 3090.3553],\n",
       "         [    0.0000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edges_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dde9ad9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.1910])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = torch.pairwise_distance(data.nodes[:,0,:2], data.nodes[:,1,:2])\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29dc8227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8528.7071, dtype=torch.float64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_real = data.edges_attributes[0,1][0]\n",
    "edges_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ad178b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3411, dtype=torch.float64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_real/25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8dc41c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0426, dtype=torch.float64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(edges_real/(20*1000/60))/600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58eea8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.1910])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2662bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808eb94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb2ae9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c409bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01327daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1367</td>\n",
       "      <td>112.736160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10445</td>\n",
       "      <td>176.062978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12881</td>\n",
       "      <td>92.183050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2676</td>\n",
       "      <td>16.391515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2664</td>\n",
       "      <td>173.987554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1           2\n",
       "0  0   1367  112.736160\n",
       "1  0  10445  176.062978\n",
       "2  1  12881   92.183050\n",
       "3  1   2676   16.391515\n",
       "4  2   2664  173.987554"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates = pd.read_csv(\"./vienna_data/vienna_dist.csv\", header = None, sep=' ')\n",
    "coordinates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c1f53411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 161, 161])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edges_attributes.view((2, 161, 161)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db6c3346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 25921, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edges_attributes.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "941a8114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 108, 4])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nodes.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d58aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = DVRPSR_Dataset.initialize_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7b4d216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544.0006549938314"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = nx.shortest_path_length(graph, 2, 0, weight='weight')\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7f24492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565.2582942952082"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: distance need to be normalized afterwords\n",
    "shortest_path_length = sum(graph.get_edge_data(u, v)['weight'] \n",
    "                                   for u, v in zip(shortest_path, shortest_path[1:]))\n",
    "shortest_path_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e51ddc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2664.0, 14941.0, 10443.0, 10445.0, 0]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = nx.shortest_path(graph, 2, 0)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e5acf28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10445.0, 2671.0, 2669.0, 10401.0, 2676.0, 2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_path = nx.shortest_path(graph, 0, 2)\n",
    "shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b795e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "243c08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # reset vehicle (minibatch*veh_count*veh_feature)\n",
    "    \n",
    "minibatch = 3\n",
    "vehicle_count = 2\n",
    "vehicle_feature = 8\n",
    "customer_feature = 4\n",
    "vehicle_budget = 400\n",
    "init_cust_mask = None\n",
    "nodes_count = 21\n",
    "customer_size = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d4926749",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_mat = data.edges_attributes.view((minibatch, customer_size, customer_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6905a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nodes = data.nodes\n",
    "\n",
    "vehicles = nodes.new_zeros((minibatch, vehicle_count, vehicle_feature))\n",
    "vehicles[:, :, :2] = data.nodes[:, :1, :2]\n",
    "vehicles[:, :, 2] = data.vehicle_time_budget\n",
    "\n",
    "\n",
    "# reset vehicle done\n",
    "veh_done = nodes.new_zeros((minibatch, vehicle_count), dtype=torch.bool)\n",
    "done = False\n",
    "\n",
    "# reset cust_mask\n",
    "customer_mask = nodes[:, :, 3] > 0\n",
    "if init_cust_mask is not None:\n",
    "    customer_mask = customer_mask | init_cust_mask\n",
    "\n",
    "# reset new customers and served customer since now to zero (all false)\n",
    "new_customer = True\n",
    "served = torch.zeros_like(customer_mask)\n",
    "\n",
    "# reset mask (minibatch*veh_count*nodes)\n",
    "mask = customer_mask[:, None, :].repeat(1, vehicle_count, 1)\n",
    "\n",
    "# reset current vehicle idx, current vehicle, current vehicle mask\n",
    "current_vehicle_index = nodes.new_zeros((minibatch, 1), dtype=torch.int64)\n",
    "current_vehicle = vehicles.gather(1, current_vehicle_index[:, :, None].expand(-1, -1, vehicle_feature))\n",
    "current_vehicle_mask = mask.gather(1, current_vehicle_index[:, :, None].expand(-1, -1, nodes_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a0764f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_index = torch.tensor([[4],[5],[2]])\n",
    "dest = nodes.gather(1, customer_index[:, :, None].expand(-1, -1, customer_feature))\n",
    "current_vehicle[:,:,4] = customer_index\n",
    "\n",
    "dist = torch.zeros((minibatch, 1))\n",
    "for i in range(minibatch):\n",
    "    dist[i,0] = distance_mat[i][int(current_vehicle[i,:,4])][int(current_vehicle[i,:,5])]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "670e3c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c8f813cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27.7970],\n",
       "        [34.0259],\n",
       "        [34.1713]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_pair = torch.pairwise_distance(current_vehicle[:, 0, :2], dest[:, 0, :2], keepdim=True)\n",
    "dist_pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "bdf51e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[153.4832,  -2.7868, 400.0000,   0.0000,   4.0000,   4.0000,   0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "        [[153.4832,  -2.7868, 400.0000,   0.0000,   5.0000,   5.0000,   0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "        [[153.4832,  -2.7868, 400.0000,   0.0000,   2.0000,   2.0000,   0.0000,\n",
       "            0.0000]]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c8704e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.zeros((minibatch, customer_size,1))\n",
    "for i in range(minibatch):\n",
    "    for j in range(customer_size):\n",
    "        dist_vehicle_customer_depot = distance_mat[i][int(current_vehicle[i, :, 4])][j] + \\\n",
    "                                      distance_mat[i][j][0]\n",
    "        cost[i,j] = dist_vehicle_customer_depot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0b8de571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[12073.8242],\n",
       "         [12147.1133],\n",
       "         [31129.9609],\n",
       "         [37056.2383],\n",
       "         [12073.8242],\n",
       "         [12410.2979],\n",
       "         [23182.2988],\n",
       "         [26576.6523],\n",
       "         [16136.9805],\n",
       "         [14555.1846],\n",
       "         [11615.3086],\n",
       "         [12442.7627],\n",
       "         [42607.6875],\n",
       "         [13425.7148],\n",
       "         [28457.6504],\n",
       "         [26837.7070],\n",
       "         [41775.5234],\n",
       "         [24483.6934],\n",
       "         [25110.4375],\n",
       "         [23246.2363],\n",
       "         [40783.8203]],\n",
       "\n",
       "        [[19942.3477],\n",
       "         [15831.9141],\n",
       "         [35233.6016],\n",
       "         [23313.8301],\n",
       "         [50010.0781],\n",
       "         [19942.3477],\n",
       "         [22123.5977],\n",
       "         [21357.6172],\n",
       "         [24604.2949],\n",
       "         [22227.8223],\n",
       "         [30858.2832],\n",
       "         [26969.6445],\n",
       "         [48152.0039],\n",
       "         [22627.5508],\n",
       "         [22856.3594],\n",
       "         [36536.7461],\n",
       "         [24623.3574],\n",
       "         [14645.5352],\n",
       "         [24672.2383],\n",
       "         [50429.2031],\n",
       "         [47135.8164]],\n",
       "\n",
       "        [[14458.9795],\n",
       "         [38607.6992],\n",
       "         [14458.9795],\n",
       "         [34566.5078],\n",
       "         [23715.8965],\n",
       "         [44606.6172],\n",
       "         [16533.0938],\n",
       "         [44098.9844],\n",
       "         [14190.5830],\n",
       "         [15693.0498],\n",
       "         [14116.2578],\n",
       "         [17453.5137],\n",
       "         [41867.4258],\n",
       "         [28259.7695],\n",
       "         [16099.0498],\n",
       "         [18147.7715],\n",
       "         [19698.3574],\n",
       "         [52072.2734],\n",
       "         [23124.6680],\n",
       "         [20584.2422],\n",
       "         [24296.4355]]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "28961182",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[233], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m destination_indices \u001b[38;5;241m=\u001b[39m current_vehicle[:, :, \u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Gather the distances for each vehicle\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[43mdistance_mat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_indices\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Gather distances from source indices\u001b[39;00m\n\u001b[1;32m     12\u001b[0m dist \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m2\u001b[39m, destination_indices)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming distance_mat is a tensor of shape (batch_size, customer_size, customer_size)\n",
    "# And current_vehicle is a tensor of shape (batch_size, num_vehicles, vehicle_feature)\n",
    "\n",
    "# Get the indices of the current vehicle and destination nodes\n",
    "source_indices = current_vehicle[:, :, 4].long()\n",
    "destination_indices = current_vehicle[:, :, 5].long()\n",
    "\n",
    "# Gather the distances for each vehicle\n",
    "dist = distance_mat.gather(1, source_indices)  # Gather distances from source indices\n",
    "dist = dist.gather(2, destination_indices)  # Gather distances to destination indices\n",
    "\n",
    "# Note: Make sure `distance_mat` and `current_vehicle` are torch.Tensors and have the correct shapes and data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f8360fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 21, 21])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_mat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2a10b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_indices = source_indices.unsqueeze(-1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "70ca4349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4],\n",
       "        [5],\n",
       "        [2]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1a18b241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[12073.8241]],\n",
       "\n",
       "        [[19942.3471]],\n",
       "\n",
       "        [[14458.9796]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_source = distance_mat.gather(1, source_indices)  \n",
    "dist_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9a424de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[11161.3693]],\n",
       "\n",
       "        [[20370.8089]],\n",
       "\n",
       "        [[21599.6604]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_dest = dist = distance_mat.gather(2, destination_indices)  \n",
    "dist_dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d8cb8e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[153.4832,  -2.7868, 400.0000,   0.0000,   2.0000,   2.0000,   0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "        [[153.4832,  -2.7868, 400.0000,   0.0000,   3.0000,   3.0000,   0.0000,\n",
       "            0.0000]]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6afc1b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73abcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb67268b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
