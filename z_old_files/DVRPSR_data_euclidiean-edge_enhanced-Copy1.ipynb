{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703636c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d503e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DVRPSR_Dataset(Dataset):\n",
    "\n",
    "    customer_feature = 4 # customer features location (x_i,y_i) and duration of service(d), appearance (u)\n",
    "\n",
    "    @classmethod\n",
    "    def create_data(cls,\n",
    "                    batch_size = 2,\n",
    "                    vehicle_count = 2,\n",
    "                    vehicle_speed = 20, # km/hr\n",
    "                    Lambda = 0.025, # request rate per min\n",
    "                    dod = 0.5,\n",
    "                    horizon = 400,\n",
    "                    fDmean = 10,\n",
    "                    fDstd = 2.5):\n",
    "\n",
    "\n",
    "        # static customer counts V = Lambda*horizon*(1-dod)/(dod+0.5)\n",
    "        V_static = int(Lambda*horizon*(1-dod)/(dod)+0.5)\n",
    "\n",
    "        # total customer count\n",
    "        V = int(Lambda*horizon/(dod) + 0.5)\n",
    "\n",
    "        size = (batch_size, V, 1)\n",
    "        \n",
    "        # initialize the graph of vienna network\n",
    "        graph = cls.initialize_graph()\n",
    "\n",
    "        # get the coordinates of customers\n",
    "        data_vienna = pd.read_csv('vienna_cordinates.csv')\n",
    "\n",
    "        # get depot coordinates: Id, xcoords, ycoords\n",
    "        depot = cls.get_depot_location(data_vienna)\n",
    "\n",
    "        # get location of customers: id, xcoords, ycoords\n",
    "        locations = cls.get_customers_coordinates(data_vienna, batch_size, V, depot)\n",
    "\n",
    "        # get edges index and attributes, which is distance between one node to others n_i*n_j\n",
    "        edges_index, edges_attributes = cls.get_edges_attributes(batch_size, graph, depot, locations, V)\n",
    "        \n",
    "        ### generate Static_Dynamic customer requests\n",
    "        dynamic_request = cls.generateRandomDynamicRequests(batch_size,\n",
    "                                                            V,\n",
    "                                                            V_static,\n",
    "                                                            fDmean,\n",
    "                                                            fDstd,\n",
    "                                                            Lambda,\n",
    "                                                            horizon)\n",
    "\n",
    "        customers = torch.zeros((batch_size,V,cls.customer_feature))\n",
    "        customers[:,:,:2] = locations[:,:,1:]\n",
    "        customers[:,:,2:4] = dynamic_request\n",
    "\n",
    "\n",
    "\n",
    "        depo = torch.zeros((batch_size, 1, cls.customer_feature))\n",
    "        depo[:,:,0:2] = torch.from_numpy(depot[0][1:])\n",
    "        depo[:,:,2] =  0\n",
    "\n",
    "        nodes = torch.cat((depo, customers), 1)\n",
    "        \n",
    "        dataset = cls(vehicle_count, vehicle_speed, horizon, nodes, V, \n",
    "                      edges_index, edges_attributes, customer_mask = None)\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    def __init__(self, vehicle_count, vehicle_speed, horizon, nodes, V,\n",
    "                 edges_index, edges_attributes, customer_mask=None):\n",
    "        \n",
    "        self.vehicle_count = vehicle_count\n",
    "        self.vehicle_speed = vehicle_speed\n",
    "        self.nodes = nodes\n",
    "        self.vehicle_time_budget = horizon\n",
    "        self.edges_index = edges_index\n",
    "        self.edges_attributes = edges_attributes\n",
    "\n",
    "        self.batch_size, self.nodes_count, d = self.nodes.size()\n",
    "\n",
    "        if d!= self.customer_feature:\n",
    "            raise ValueError(\"Expected {} customer features per nodes, got {}\".format(\n",
    "                self.customer_feature, d))\n",
    "\n",
    "        self.customer_mask = customer_mask\n",
    "        self.customer_count = V\n",
    "        \n",
    "        \n",
    "    def initialize_graph():\n",
    "    \n",
    "        coordinates = pd.read_csv(\"vienna_dist.csv\", header = None, sep=' ')\n",
    "        coordinates.columns = ['coord1','coord2','dist']\n",
    "        graph = nx.DiGraph()\n",
    "\n",
    "        # add the rows to the graph for shortest path and distance calculations\n",
    "        for _, row in coordinates.iterrows():\n",
    "            graph.add_edge(row['coord1'], row['coord2'], weight=row['dist'])\n",
    "\n",
    "        return graph\n",
    "\n",
    "\n",
    "    def precompute_shortest_path(graph, start_node, end_node):\n",
    "\n",
    "        shortest_path = nx.shortest_path(graph, start_node, end_node)\n",
    "\n",
    "        # TODO: distance need to be normalized afterwords\n",
    "        shortest_path_length = sum(graph.get_edge_data(u, v)['weight'] \n",
    "                                   for u, v in zip(shortest_path, shortest_path[1:]))\n",
    "\n",
    "        return shortest_path, shortest_path_length \n",
    "    \n",
    "    \n",
    "    def get_distanceLL(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "        R = 6371  # Radius of the Earth in kilometers\n",
    "\n",
    "        lat1_rad = math.radians(lat1)\n",
    "        lon1_rad = math.radians(lon1)\n",
    "        lat2_rad = math.radians(lat2)\n",
    "        lon2_rad = math.radians(lon2)\n",
    "\n",
    "        dlat = lat2_rad - lat1_rad\n",
    "        dlon = lon2_rad - lon1_rad\n",
    "\n",
    "        a = math.sin(dlat / 2) ** 2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2) ** 2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "        distance = R * c\n",
    "        return distance\n",
    "    \n",
    "\n",
    "    def get_NearestNodeLL(lat, lon, lats, lons):\n",
    "        nearest = (-1, sys.float_info.max)\n",
    "        for i in range(len(lats)):\n",
    "            dist = DVRPSR_Dataset.get_distanceLL(lat, lon, lats[i], lons[i])\n",
    "            if dist < nearest[1]:\n",
    "                nearest = (i, dist)\n",
    "        return nearest[0]\n",
    "    \n",
    "\n",
    "\n",
    "    def get_depot_location(data_vienna):\n",
    "\n",
    "        ll = (48.178808, 16.438460)\n",
    "        lat = ll[0] / 180 * math.pi\n",
    "        lon = ll[1] / 180 * math.pi\n",
    "        lats = data_vienna['lats']\n",
    "        lons = data_vienna['lons']\n",
    "        depot = DVRPSR_Dataset.get_NearestNodeLL(lat, lon, lats, lons)\n",
    "        depot_coordinates = np.array(data_vienna[data_vienna['id']==depot][['id','xcoords', 'ycoords']])\n",
    "\n",
    "        return depot_coordinates\n",
    "    \n",
    "    def get_customers_coordinates(data_vienna, batch_size, customers_count, depot):\n",
    "        \n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # Excluding depot id from the customers selection\n",
    "        data_vienna_without_depot = data_vienna[data_vienna['id'] != int(depot[0][0])].reset_index()\n",
    "\n",
    "        # Sample customers indices for all batches at once\n",
    "        sampled_customers = torch.multinomial(torch.tensor(data_vienna_without_depot['id'], dtype=torch.float32),\n",
    "                                              num_samples=batch_size * customers_count, replacement=True)\n",
    "        \n",
    "        sampled_customers = sampled_customers.reshape(batch_size, customers_count)\n",
    "\n",
    "        # Gather the sampled locations using the indices\n",
    "        sampled_locations = data_vienna_without_depot.loc[sampled_customers.flatten()].reset_index(drop=True)\n",
    "\n",
    "        # Reshape the locations to match the batch size\n",
    "        locations = sampled_locations.groupby(sampled_locations.index // customers_count)\n",
    "\n",
    "        # Create PyTorch tensors for the batched data\n",
    "        locations_tensors = []\n",
    "        for _, batch in locations:\n",
    "            id_tensor = torch.tensor(batch['id'].values, dtype=torch.long)\n",
    "            coords_tensor = torch.tensor(batch[['xcoords', 'ycoords']].values, dtype=torch.float32)\n",
    "            batch_tensor = torch.cat((id_tensor.unsqueeze(1), coords_tensor), dim=1)\n",
    "            locations_tensors.append(batch_tensor)\n",
    "\n",
    "        return torch.stack(locations_tensors)\n",
    "    \n",
    "    def c_dist(x1,x2):\n",
    "        return ((x1[0]-x2[0])**2+(x1[1]-x2[1])**2)**0.5\n",
    "    \n",
    "    def get_edges_attributes(batch_size, graph, depot, locations, V):\n",
    "    \n",
    "        # all customers ID inclusing depot\n",
    "        \n",
    "        print('Initialzing edges')\n",
    "        edge_depot = torch.zeros((batch_size, 1, 2))\n",
    "        edge_depot[:,:,0] = depot[0][1]\n",
    "        edge_depot[:,:,1] = depot[0][2]\n",
    "        edge_data = torch.cat((edge_depot, locations[:,:,1:3]), dim=1)\n",
    "\n",
    "        # generate edge index\n",
    "        edges_index = []\n",
    "\n",
    "        for i in range(V+1):\n",
    "            for j in range(V+1):\n",
    "                edges_index.append([i, j])\n",
    "        edges_index = torch.LongTensor(edges_index)\n",
    "        edges_index = edges_index.transpose(dim0=0,dim1=1)\n",
    "\n",
    "        # generate nodes attributes\n",
    "        edges_batch = []\n",
    "\n",
    "        for batch in edge_data:\n",
    "            edges = torch.zeros((V+1, V+1, 1), dtype=torch.float32)\n",
    "            for i, node1 in enumerate(batch):\n",
    "                for j, node2 in enumerate(batch):\n",
    "                    distance = DVRPSR_Dataset.c_dist(node1, node2)\n",
    "                    edges[i][j][0] = distance\n",
    "\n",
    "            edges = edges.reshape(-1, 1)\n",
    "            edges_batch.append(edges)\n",
    "\n",
    "        return edges_index, torch.stack(edges_batch)\n",
    "    \n",
    "    \n",
    "    def generateRandomDynamicRequests(batch_size=2 ,\n",
    "                                      V=20,\n",
    "                                      V_static=10,\n",
    "                                      fDmean=10,\n",
    "                                      fDstd=2.5,\n",
    "                                      Lambda=0.025,\n",
    "                                      horizon=400,\n",
    "                                      dep = 0,\n",
    "                                      u = 0):\n",
    "        gen = random.Random()\n",
    "        gen.seed() # uses the default system seed\n",
    "        unifDist = gen.random # uniform distribution\n",
    "        durDist = lambda: max(0.01, gen.gauss(fDmean, fDstd)) # normal distribution with fDmean and fDstd\n",
    "\n",
    "        # TODO: in actual data , we need to add a depo node with corrdinate, which should be removed from selected\n",
    "        #       nodes as well.\n",
    "\n",
    "        requests = []\n",
    "        for b in range(batch_size):\n",
    "\n",
    "            static_request = []\n",
    "            dynamic_request = []\n",
    "            u = 0\n",
    "\n",
    "            while True:\n",
    "                unif = unifDist()\n",
    "                u += -(1/Lambda) * math.log(unif)\n",
    "                if u > horizon or len(dynamic_request) > (V-V_static+2):\n",
    "                    break\n",
    "                d = round(durDist(),2)\n",
    "                while d<=0:\n",
    "                    d = round(durDist(),2)\n",
    "\n",
    "                dynamic_request.append([d, round(u,2)])\n",
    "\n",
    "            for j in range(V-len(dynamic_request)):\n",
    "                d = round(durDist(),2)\n",
    "                while d<=0:\n",
    "                    d = round(durDist(),2)\n",
    "                static_request.append([d,0])\n",
    "\n",
    "            request = static_request+dynamic_request\n",
    "            random.shuffle(request)\n",
    "            requests.append(request)\n",
    "\n",
    "        return torch.tensor(requests)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.customer_mask is None:\n",
    "            return self.nodes[i]\n",
    "        else:\n",
    "            return self.nodes[i], self.customer_mask[i]\n",
    "\n",
    "    def nodes_generate(self):\n",
    "        if self.customer_mask is None:\n",
    "            yield from self.nodes\n",
    "        else:\n",
    "            yield from (n[m^1] for n,m in zip(self.nodes, self.customer_mask))  \n",
    "            \n",
    "            \n",
    "    def normalize(self):\n",
    "        loc_max, loc_min = self.nodes[:,:,:2].max().item(), self.nodes[:,:,:2].min().item()\n",
    "        loc_max -= loc_min\n",
    "        edge_max_length = self.edges_attributes.max().item()\n",
    "\n",
    "        self.nodes[:,:,:2] -= loc_min\n",
    "        self.nodes[:,:,:2] /= loc_max\n",
    "        self.nodes[:,:,2:] /=self.vehicle_time_budget\n",
    "\n",
    "        self.vehicle_speed *= self.vehicle_time_budget/edge_max_length\n",
    "        self.vehicle_time_budget = 1\n",
    "        self.edges_attributes /= edge_max_length\n",
    "        return loc_max, 1\n",
    "\n",
    "    def save(self, folder_path):\n",
    "        torch.save({\n",
    "            'veh_count':self.vehicle_count,\n",
    "            'veh_speed':self.vehicle_speed,\n",
    "            'nodes':self.nodes,\n",
    "            'edges_index':self.edges_index,\n",
    "            'edges_attributes':self.edges_attributes,\n",
    "            'customer_count':self.customer_count,\n",
    "            'customer_mask':self.customer_mask\n",
    "        }, folder_path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, folder_path):\n",
    "        return cls(**torch.load(folder_path))\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebd818",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a38b6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class DVRPSR_Environment:\n",
    "    vehicle_feature = 8  # vehicle coordinates(x_i,y_i), veh_time_time_budget, total_travel_time, last_customer,\n",
    "                         # next(destination) customer, last rewards, next rewards\n",
    "    customer_feature = 4\n",
    "\n",
    "    # TODO: change pending cost for rewards\n",
    "\n",
    "    def __init__(self, data, nodes=None, customer_mask=None, edges_attributes = None,\n",
    "                 pending_cost=1, \n",
    "                 dynamic_reward=0.2,\n",
    "                 budget_penalty = 10):\n",
    "\n",
    "        self.vehicle_count = data.vehicle_count\n",
    "        self.vehicle_speed = data.vehicle_speed\n",
    "        self.vehicle_time_budget = data.vehicle_time_budget\n",
    "\n",
    "        self.nodes = data.nodes if nodes is None else nodes\n",
    "        self.edge_index = data.edges_index\n",
    "        self.edge_attributes = data.edges_attributes if edges_attributes is None else edges_attributes\n",
    "        self.init_customer_mask = data.customer_mask if customer_mask is None else customer_mask\n",
    "\n",
    "        self.minibatch, self.nodes_count, _ = self.nodes.size()\n",
    "        self.distance_matrix = self.edge_attributes.view((self.minibatch, self.nodes_count, self.nodes_count))\n",
    "        self.pending_cost = pending_cost\n",
    "        self.dynamic_reward = dynamic_reward\n",
    "        self.budget_penalty = budget_penalty\n",
    "\n",
    "    def _update_current_vehicles(self, dest, customer_index, tau=0):\n",
    "\n",
    "        # calculate travel time\n",
    "        # TODO: 1) in real world setting we need to calculate the distance of arc\n",
    "        # If nodes i and j are directly connected by a road segment (i, j) ∈ A, then t(i,j)=t_ij;\n",
    "        # otherwise, t(i,j)=t_ik1 +t_k1k2 +...+t_knj, where k1,...,kn ∈ V are the nodes along the\n",
    "        # shortest path from node i to node j.\n",
    "        #      2) calculate stating time for each vehicle $\\tau $, currently is set to zero\n",
    "        \n",
    "        # update vehicle previous and next customer id\n",
    "        self.current_vehicle[:, :, 4] = self.current_vehicle[:, :, 5]\n",
    "        self.current_vehicle[:, :, 5] = customer_index\n",
    "        \n",
    "        # get the distance from current vehicle to its next destination\n",
    "        dist = torch.zeros((self.minibatch, 1))\n",
    "        for i in range(self.minibatch):\n",
    "            dist[i, 0] = self.distance_matrix[i][int(self.current_vehicle[i, :, 4])][int(self.current_vehicle[i, :, 5])]\n",
    "            \n",
    "        \n",
    "        # total travel time    \n",
    "        tt = dist / self.vehicle_speed\n",
    "\n",
    "        # customers which are dynamicaly appeared\n",
    "        dyn_cust = (dest[:, :, 3] > 0).float()\n",
    "\n",
    "        # budget left while travelling to destination nodes\n",
    "        budget = tau + tt + dest[:, :, 2]\n",
    "        # print(budget, tau, tt, dest[:,:,2])\n",
    "\n",
    "        # update vehicle features based on destination nodes\n",
    "        self.current_vehicle[:, :, :2] = dest[:, :, :2]\n",
    "        self.current_vehicle[:, :, 2] -= budget\n",
    "        self.current_vehicle[:, :, 3] += tt\n",
    "        self.current_vehicle[:, :, 6] = self.current_vehicle[:, :, 7]\n",
    "        self.current_vehicle[:, :, 7] = -dist\n",
    "\n",
    "        # update vehicles states\n",
    "        self.vehicles = self.vehicles.scatter(1,\n",
    "                                              self.current_vehicle_index[:, :, None].expand(-1, -1, self.vehicle_feature),\n",
    "                                              self.current_vehicle)\n",
    "\n",
    "        return dist, dyn_cust\n",
    "\n",
    "    def _done(self, customer_index):\n",
    "        \n",
    "        self.vehicle_done.scatter_(1, self.current_vehicle_index, torch.logical_or((customer_index == 0), \n",
    "                                                                     (self.current_vehicle[:, :, 2] <= 0)))\n",
    "        # print(self.veh_done, cust_idx==0,self.cur_veh[:,:,2]<=0, (cust_idx==0) | (self.cur_veh[:,:,2]<=0))\n",
    "        self.done = bool(self.vehicle_done.all())\n",
    "\n",
    "    def _update_mask(self, customer_index):\n",
    "\n",
    "        self.new_customer = False\n",
    "        self.served.scatter_(1, customer_index, customer_index > 0)\n",
    "\n",
    "        # cost for a vehicle to go to customer and back to deport considering service duration\n",
    "        cost = torch.zeros((self.minibatch, self.nodes_count,1))\n",
    "        for i in range(self.minibatch):\n",
    "            for j in range(self.nodes_count):\n",
    "                dist_vehicle_customer_depot = self.distance_matrix[i][int(self.current_vehicle[i, :, 4])][j] + \\\n",
    "                                              self.distance_matrix[i][j][0]\n",
    "                cost[i,j] = dist_vehicle_customer_depot\n",
    "                \n",
    "        cost = cost / self.vehicle_speed\n",
    "\n",
    "        cost += self.nodes[:, :, None, 2]\n",
    "\n",
    "        overtime_mask = self.current_vehicle[:, :, None, 2] - cost\n",
    "        overtime_mask = overtime_mask.squeeze(2).unsqueeze(1)\n",
    "        overtime = torch.zeros_like(self.mask).scatter_(1,\n",
    "                                                        self.current_vehicle_index[:, :, None].expand(-1, -1, self.nodes_count),\n",
    "                                                        overtime_mask < 0)\n",
    "\n",
    "        self.mask = self.mask | self.served[:, None, :] | overtime | self.vehicle_done[:, :, None]\n",
    "        self.mask[:, :, 0] = 0  # depot\n",
    "\n",
    "    # updating current vehicle to find the next available vehicle\n",
    "    def _update_next_vehicle(self, veh_index=None):\n",
    "        \n",
    "        if veh_index is None:\n",
    "            avail = self.vehicles[:, :, 3].clone()\n",
    "            avail[self.vehicle_done] = float('inf')\n",
    "            self.current_vehicle_index = avail.argmin(1, keepdim=True)\n",
    "        else:\n",
    "            self.current_vehicle_index = veh_index\n",
    "            \n",
    "        self.current_vehicle = self.vehicles.gather(1, self.current_vehicle_index[:, :, None].expand(-1, -1, self.vehicle_feature))\n",
    "        self.current_vehicle_mask = self.mask.gather(1, self.current_vehicle_index[:, :, None].expand(-1, -1, self.nodes_count))\n",
    "\n",
    "    def _update_dynamic_customers(self):\n",
    "\n",
    "        time = self.current_vehicle[:, :, 3].clone()\n",
    "\n",
    "        if self.init_customer_mask is None:\n",
    "            reveal_dyn_reqs = torch.logical_and((self.customer_mask), (self.nodes[:, :, 3] <= time))\n",
    "        else:\n",
    "            reveal_dyn_reqs = torch.logical_and((self.customer_mask ^ self.init_customer_mask), (self.nodes[:, :, 3] <= time))\n",
    "\n",
    "        if reveal_dyn_reqs.any():\n",
    "            self.new_customer = True\n",
    "            self.customer_mask = self.customer_mask ^ reveal_dyn_reqs\n",
    "            self.mask = self.mask ^ reveal_dyn_reqs[:, None, :].expand(-1, self.vehicle_count, -1)\n",
    "            self.vehicle_done = torch.logical_and(self.vehicle_done, (reveal_dyn_reqs.any(1) ^ True).unsqueeze(1))\n",
    "            self.vehicles[:, :, 3] = torch.max(self.vehicles[:, :, 3], time)\n",
    "            self._update_next_vehicle()\n",
    "\n",
    "    def reset(self):\n",
    "        # reset vehicle (minibatch*veh_count*veh_feature)\n",
    "        self.vehicles = self.nodes.new_zeros((self.minibatch, self.vehicle_count, self.vehicle_feature))\n",
    "        self.vehicles[:, :, :2] = self.nodes[:, :1, :2]\n",
    "        self.vehicles[:, :, 2] = self.vehicle_time_budget\n",
    "\n",
    "        # reset vehicle done\n",
    "        self.vehicle_done = self.nodes.new_zeros((self.minibatch, self.vehicle_count), dtype=torch.bool)\n",
    "        self.done = False\n",
    "\n",
    "        # reset cust_mask\n",
    "        self.customer_mask = self.nodes[:, :, 3] > 0\n",
    "        if self.init_customer_mask is not None:\n",
    "            self.customer_mask = self.customer_mask | self.init_customer_mask\n",
    "\n",
    "        # reset new customers and served customer since now to zero (all false)\n",
    "        self.new_customer = True\n",
    "        self.served = torch.zeros_like(self.customer_mask)\n",
    "\n",
    "        # reset mask (minibatch*veh_count*nodes)\n",
    "        self.mask = self.customer_mask[:, None, :].repeat(1, self.vehicle_count, 1)\n",
    "\n",
    "        # reset current vehicle index, current vehicle, current vehicle mask\n",
    "        self.current_vehicle_index = self.nodes.new_zeros((self.minibatch, 1), dtype=torch.int64)\n",
    "        \n",
    "        self.current_vehicle = self.vehicles.gather(1, \n",
    "                                                    self.current_vehicle_index[:, :, None].expand(-1, -1, self.vehicle_feature))\n",
    "        self.current_vehicle_mask = self.mask.gather(1, \n",
    "                                             self.current_vehicle_index[:, :, None].expand(-1, -1, self.nodes_count))\n",
    "\n",
    "    \n",
    "    def step(self, customer_index, veh_index = None):\n",
    "        dest = self.nodes.gather(1, customer_index[:, :, None].expand(-1, -1, self.customer_feature))\n",
    "        dist, dyn_cust = self._update_current_vehicles(dest, customer_index)\n",
    "\n",
    "        #cust = (dest[:, :, 3] >= 0).float()\n",
    "\n",
    "        self._done(customer_index)\n",
    "        self._update_mask(customer_index)\n",
    "        self._update_next_vehicle(veh_index)\n",
    "\n",
    "        #reward = -dist * (1 - dyn_cust*self.dynamic_reward)\n",
    "        reward = self.current_vehicle[:, :, 7] - self.current_vehicle[:,:,6] + self.dynamic_reward*dyn_cust\n",
    "        pending_static_customers = torch.logical_and((self.served ^ True), \n",
    "                                                     (self.nodes[:, :, 3] == 0)).float().sum(-1,keepdim=True) - 1\n",
    "        \n",
    "        reward -= self.pending_cost*pending_static_customers\n",
    "\n",
    "        if self.done:\n",
    "\n",
    "            if self.init_customer_mask is not None:\n",
    "                self.served += self.init_customer_mask\n",
    "            # penalty for pending customers\n",
    "            pending_customers = torch.logical_and((self.served ^ True), \n",
    "                                                  (self.nodes[:, :, 3] >= 0)).float().sum(-1, keepdim=True) - 1\n",
    "\n",
    "            # TODO: penalty for having unused time budget as well not serving customers\n",
    "            reward -= self.dynamic_reward*pending_customers\n",
    "            \n",
    "\n",
    "        self._update_dynamic_customers()\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def state_dict(self, dest_dict=None):\n",
    "        if dest_dict is None:\n",
    "            dest_dict = {'vehicles': self.vehicles,\n",
    "                         'vehicle_done': self.vehicle_done,\n",
    "                         'served': self.served,\n",
    "                         'mask': self.mask,\n",
    "                         'current_vehicle_index': self.current_vehicle_index}\n",
    "\n",
    "        else:\n",
    "            dest_dict[\"vehicles\"].copy_(self.vehicles)\n",
    "            dest_dict[\"vehicle_done\"].copy_(self.vehicle_done)\n",
    "            dest_dict[\"served\"].copy_(self.served)\n",
    "            dest_dict[\"mask\"].copy_(self.mask)\n",
    "            dest_dict[\"current_vehicle_index\"].copy_(self.current_vehicle_index)\n",
    "\n",
    "        return dest_dict\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.vehicles.copy_(state_dict[\"vehicles\"])\n",
    "        self.vehicle_done.copy_(state_dict[\"vehicle_done\"])\n",
    "        self.served.copy_(state_dict[\"served\"])\n",
    "        self.mask.copy_(state_dict[\"mask\"])\n",
    "        self.current_vehicle_index.copy_(state_dict[\"current_vehicle_index\"])\n",
    "\n",
    "        self.current_vehicle = self.vehicles.gather(1, \n",
    "                                                    self.current_vehicle_index[:, :, None].expand(-1, -1, self.vehicle_feature))\n",
    "        self.current_vehicle_mask = self.mask.gather(1, self.current_vehicle_index[:, :, None].expand(-1, -1, self.customer_feature))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97e8f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce_loss(logprobs, rewards, baseline = None, weights = None, discount = 1.0, reduction = 'mean'):\n",
    "    r\"\"\"\n",
    "    :param logprobs:  Iterable of length :math:`L` on tensors of size :math:`N \\times 1`\n",
    "    :param rewards:   Iterable of length :math:`L` on tensors of size :math:`N \\times 1`\n",
    "                    or single tensor of size :math:`N \\times 1` to use rewards cumulated on the whole trajectory\n",
    "    :param baseline:  Iterable of length :math:`L` on tensors of size :math:`N \\times 1`\n",
    "                    or single tensor of size :math:`N \\times 1` to use rewards cumulated on the whole trajectory\n",
    "    :param weights:   Iterable of length :math:`L` on tensors of size :math:`N \\times 1`\n",
    "    :param discount:  Discount applied to cumulated future reward\n",
    "    :param reduction: 'none' No reduction,\n",
    "                      'sum'  Compute sum of loss on batch,\n",
    "                      'mean' Compute mean of loss on batch\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = repeat(1.0)\n",
    "\n",
    "    if isinstance(rewards, torch.Tensor):\n",
    "        if baseline is None:\n",
    "            baseline = torch.zeros_like(rewards)\n",
    "\n",
    "        loss = torch.stack([-logp * w for logp,w in zip(logprobs, weights)]).sum(dim = 0)\n",
    "        loss *= (rewards - baseline.detach())\n",
    "\n",
    "        if baseline.requires_grad:\n",
    "            loss += F.smooth_l1_loss(baseline, rewards)\n",
    "\n",
    "    else:\n",
    "        if baseline is None:\n",
    "            baseline = repeat(torch.zeros_like(rewards[0]))\n",
    "\n",
    "        cumul = torch.zeros_like(rewards[0])\n",
    "        vals = []\n",
    "        for r in reversed(rewards):\n",
    "            cumul = r + discount * cumul\n",
    "            vals.append(cumul)\n",
    "        vals.reverse()\n",
    "\n",
    "        loss = []\n",
    "        bl_loss = []\n",
    "        for val, logp, bl, w in zip(vals, logprobs, baseline, weights):\n",
    "            loss.append( -logp * (val - bl.detach()) * w )\n",
    "            if bl.requires_grad:\n",
    "                bl_loss.append( F.smooth_l1_loss(bl, val) )\n",
    "        loss = torch.stack(loss).sum(dim = 0)\n",
    "\n",
    "        if bl_loss:\n",
    "            loss += torch.stack(bl_loss).sum(dim = 0)\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return loss\n",
    "    elif reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    else: # reduction == 'mean'\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac8789c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialzing edges\n"
     ]
    }
   ],
   "source": [
    "data = DVRPSR_Dataset.create_data(batch_size=4, \n",
    "                                  vehicle_count=2,\n",
    "                                  vehicle_speed=1/3, \n",
    "                                  Lambda=0.2, \n",
    "                                  dod=0.75, \n",
    "                                  horizon=600)\n",
    "data.normalize()\n",
    "envd = DVRPSR_Environment\n",
    "env = envd(data)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e9e7493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64eae784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 25921])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device = 'mps' if torch.device('mps') else 'cpu'\n",
    "device = 'cpu'\n",
    "env.nodes = env.nodes.to(device)\n",
    "env.edge_attributes = env.edge_attributes.to(device)\n",
    "env.edge_index = env.edge_index.to(device)\n",
    "env.edge_index.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16844ad1",
   "metadata": {},
   "source": [
    "## Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51333e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "import math\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f284f3",
   "metadata": {},
   "source": [
    "## Graph Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f34c0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_head, query_size, key_size = None, value_size = None, edge_dim_size = None, bias = False):\n",
    "        \n",
    "        super(GraphMultiHeadAttention, self).__init__()\n",
    "        self.num_head = num_head\n",
    "        self.query_size = query_size\n",
    "        \n",
    "        self.key_size = self.query_size if key_size is None else key_size\n",
    "        self.value_size = self.key_size if value_size is None else value_size\n",
    "        self.edge_dim_size = self.query_size//2 if edge_dim_size is None else edge_dim_size\n",
    "        \n",
    "        self.scaling_factor = self.key_size**-0.5\n",
    "        \n",
    "        self.keys_per_head = self.key_size // self.num_head\n",
    "        self.values_per_head = self.value_size // self.num_head\n",
    "        self.edge_size_per_head = self.edge_dim_size\n",
    "        \n",
    "        self.edge_embedding = nn.Linear(self.edge_dim_size, self.edge_size_per_head, bias = bias)\n",
    "        self.query_embedding = nn.Linear(self.query_size, self.num_head * self.keys_per_head, bias = bias)\n",
    "        self.key_embedding = nn.Linear(self.key_size, self.num_head * self.keys_per_head, bias = bias)\n",
    "        self.value_embedding = nn.Linear(self.value_size, self.num_head * self.values_per_head, bias = bias)\n",
    "        self.recombine = nn.Linear(self.num_head * self.values_per_head, self.value_size, bias = bias)\n",
    "        \n",
    "        \n",
    "        self.K_project_pre = None\n",
    "        self.V_project_pre = None\n",
    "        \n",
    "        self.initialize_weights()\n",
    "\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        #TODO: add xavier initialziation as well\n",
    "        \n",
    "        nn.init.uniform_(self.query_embedding.weight, -self.scaling_factor, self.scaling_factor)\n",
    "        nn.init.uniform_(self.key_embedding.weight, -self.scaling_factor, self.scaling_factor)\n",
    "        inv_sq_dv = self.value_size ** -0.5\n",
    "        nn.init.uniform_(self.value_embedding.weight, -inv_sq_dv, inv_sq_dv)\n",
    "        \n",
    "    def precompute(self, keys, values = None):\n",
    "        \n",
    "        values = keys if values is None else values\n",
    "        \n",
    "        size_KV = keys.size(-2)\n",
    "        \n",
    "        self.K_project_pre = self.key_embedding(keys).view(\n",
    "                             -1, size_KV, self.num_head, self.keys_per_head).permute(0, 2, 3, 1)\n",
    "        \n",
    "        self.V_project_pre = self.value_embedding(values).view(\n",
    "                              -1, size_KV, self.num_head, self.values_per_head).permute(0, 2, 1, 3)\n",
    "        \n",
    "        \n",
    "    def forward(self, queries, keys = None, values = None, edge_attributes = None, mask = None, edge_mask=None):\n",
    "        \n",
    "        *batch_size, size_Q, _ = queries.size()\n",
    "        \n",
    "        # get queries projection\n",
    "        Q_project = self.query_embedding(queries).view(\n",
    "                              -1, size_Q, self.num_head, self.keys_per_head).permute(0, 2, 1, 3)\n",
    "        \n",
    "        # get keys projection\n",
    "        if keys is None:\n",
    "            if self.K_project_pre is None:\n",
    "                size_KV = size_Q\n",
    "                K_project = self.key_embedding(queries).view(\n",
    "                                -1, size_KV, self.num_head, self.keys_per_head).permute(0, 2, 3, 1)\n",
    "            else:\n",
    "                size_KV = self.K_project_pre.size(-1)\n",
    "                K_project = self.K_project_pre\n",
    "        else:\n",
    "            size_KV = keys.size(-2)\n",
    "            K_project = self.key_embedding(keys).view(\n",
    "                            -1, size_KV, self.num_head, self.keys_per_head).permute(0, 2, 3, 1)\n",
    "            \n",
    "         # get values projection   \n",
    "        if values is None:\n",
    "            if self.V_project_pre is None:\n",
    "                V_project = self.value_embedding(queries).view(\n",
    "                                -1, size_KV, self.num_head, self.values_per_head).permute(0, 2, 1, 3)\n",
    "            else:\n",
    "                V_project = self.V_project_pre\n",
    "        else:\n",
    "            V_project = self.value_embedding(values).view(\n",
    "                            -1, size_KV, self.num_head, self.values_per_head).permute(0, 2, 1, 3)\n",
    "            \n",
    "        \n",
    "        # calculate the compability\n",
    "        attention = Q_project.matmul(K_project)\n",
    "        attention *= self.scaling_factor\n",
    "        \n",
    "        # if edge attributes are required\n",
    "        if edge_attributes is not None:\n",
    "                \n",
    "            #TODO: edge mask (is it required)\n",
    "            edge_project = self.edge_embedding(edge_attributes).view(\n",
    "                                -1, size_Q, size_Q, self.edge_size_per_head)\n",
    "                \n",
    "            # get enhanced attention inclusing edge attributes\n",
    "            attention_expanded = attention.unsqueeze(-1).expand(-1, -1, -1, -1, self.edge_size_per_head)\n",
    "            \n",
    "            # Expand edge attributes to match the number of attention heads\n",
    "            edge_project_expanded = edge_project.unsqueeze(1).expand(-1, attention.size(1), -1, -1, -1)\n",
    "            \n",
    "            attention = attention_expanded * edge_project_expanded\n",
    "            attention = attention.mean(-1)\n",
    "            \n",
    "            #print(attention.size())\n",
    "        \n",
    "            \n",
    "            \n",
    "        if mask is not None:\n",
    "\n",
    "            if mask.numel() * self.num_head == attention.numel():\n",
    "                m = mask.view(-1, 1, size_Q, size_KV).expand_as(attention)\n",
    "            else:\n",
    "                m = mask.view(-1, 1, 1, size_KV).expand_as(attention)\n",
    "\n",
    "            attention[m.bool()] = -float('inf')\n",
    "            \n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        attention = attention.matmul(V_project).permute(0, 2, 1, 3).contiguous().view(\n",
    "                                                *batch_size, size_Q, self.num_head * self.values_per_head)\n",
    "        \n",
    "        output = self.recombine(attention)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "044bfd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoderlayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_head, model_size, ff_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = GraphMultiHeadAttention(num_head, query_size=model_size)\n",
    "        self.BN1 = nn.BatchNorm1d(model_size)\n",
    "        self.FFN_layer1 = nn.Linear(model_size, ff_size)\n",
    "        \n",
    "        self.FFN_layer2 = nn.Linear(ff_size, model_size)\n",
    "        self.BN2 = nn.BatchNorm1d(model_size)\n",
    "        \n",
    "    def forward(self, h, e = None, mask = None):\n",
    "        \n",
    "        h_attn = self.attention(h, edge_attributes = e, mask=mask)\n",
    "        h_bn = self.BN1((h_attn + h).permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        \n",
    "        h_layer1 = F.relu(self.FFN_layer1(h_bn))\n",
    "        h_layer2 = self.FFN_layer2(h_layer1)\n",
    "        \n",
    "        h_out = self.BN2((h_bn + h_layer2).permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        \n",
    "        if mask is not None:\n",
    "            h_out[mask] = 0\n",
    "            \n",
    "        return h_out\n",
    "    \n",
    "class GraphEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder_layer, num_head, model_size, ff_szie):\n",
    "        super().__init__()\n",
    "        \n",
    "        for l in range(encoder_layer):\n",
    "            self.add_module(str(l), GraphEncoderlayer(num_head, model_size, ff_szie))\n",
    "            \n",
    "    def forward(self, h_in, e_in = None,  mask=None):\n",
    "        \n",
    "        h = h_in\n",
    "        e = e_in\n",
    "        \n",
    "        for child in self.children():\n",
    "            h = child(h, e, mask=mask)\n",
    "        return h\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5083689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 25921, 64])\n"
     ]
    }
   ],
   "source": [
    "## tetsing the encoder-decoder model\n",
    "\n",
    "customer_encoder = GraphEncoder(encoder_layer=3, num_head=8, model_size=128, ff_szie=256)\n",
    "\n",
    "cust_feature = 4\n",
    "edge_feature = 1\n",
    "model_size = 128\n",
    "edge_embedding_dim = 64\n",
    "customers = env.nodes\n",
    "edges = env.edge_attributes\n",
    "customer_mask = env.customer_mask\n",
    "vehicle_mask = env.current_vehicle_mask\n",
    "\n",
    "depot_embedding = nn.Linear(cust_feature, model_size)\n",
    "cust_embedding = nn.Linear(cust_feature, model_size)\n",
    "edge_embedding = nn.Linear(edge_feature, edge_embedding_dim)\n",
    "\n",
    "cust_emb = torch.cat((\n",
    "            depot_embedding(customers[:, 0:1, :]),\n",
    "            cust_embedding(customers[:, 1:, :])), dim=1)\n",
    "\n",
    "edge_emb = edge_embedding(edges)\n",
    "\n",
    "if customer_mask is not None:\n",
    "    cust_emb[customer_mask] = 0\n",
    "\n",
    "print(edge_emb.size())\n",
    "\n",
    "cust_encoding = customer_encoder(cust_emb, edge_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f32ba0",
   "metadata": {},
   "source": [
    "## Graph Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "daf3bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphAttentionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, customer_feature, vehicle_feature, model_size=128, encoder_layer=3, \n",
    "                 num_head=8, ff_size=128, tanh_xplor=10, edge_embedding_dim = 64, greedy = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # get models parameters for encoding-decoding\n",
    "        self.model_size = model_size\n",
    "        self.scaling_factor = self.model_size**0.5\n",
    "        self.tanh_xplor = tanh_xplor\n",
    "        self.greedy = greedy\n",
    "        \n",
    "        # Initialize encoder and embeddings\n",
    "        self.customer_encoder = GraphEncoder(encoder_layer=3, num_head=8, model_size=128, ff_szie=512)\n",
    "        self.customer_embedding = nn.Linear(customer_feature, model_size)\n",
    "        self.depot_embedding = nn.Linear(customer_feature, model_size)\n",
    "        \n",
    "        # initialize edge embedding\n",
    "        self.edge_embedding = nn.Linear(1, edge_embedding_dim)\n",
    "        \n",
    "        # Initialize vehicle embedding and encoding\n",
    "        #self.vehicle_embedding = nn.Linear(vehicle_feature, ff_size, bias=False)\n",
    "         \n",
    "        self.fleet_attention = GraphMultiHeadAttention(num_head, vehicle_feature, model_size)\n",
    "        \n",
    "        self.vehicle_attention = GraphMultiHeadAttention(num_head, model_size)\n",
    "        \n",
    "        # customer projection\n",
    "        self.customer_projection = nn.Linear(self.model_size, self.model_size) # TODO: MLP instaed of nn.Linear\n",
    "        \n",
    "        \n",
    "    \n",
    "    def encode_customers(self, env, customer_mask = None):\n",
    "        \n",
    "        customer_emb = torch.cat((self.depot_embedding(env.nodes[:,:1,:]),\n",
    "                                  self.customer_embedding(env.nodes[:,1:,:])), dim=1)\n",
    "        if customer_mask is not None:\n",
    "            customer_emb[customer_mask] = 0\n",
    "            \n",
    "        edge_emb = self.edge_embedding(env.edge_attributes)\n",
    "        \n",
    "        self.customer_encoding = self.customer_encoder(customer_emb, edge_emb, mask = customer_mask)\n",
    "        \n",
    "        self.fleet_attention.precompute(self.customer_encoding)\n",
    "        \n",
    "        self.customer_representation = self.customer_projection(self.customer_encoding)\n",
    "        if customer_mask is not None:\n",
    "            self.customer_representation[customer_mask] = 0\n",
    "            \n",
    "    \n",
    "        \n",
    "    def vehicle_representation(self, vehicles, vehicle_index, vehicle_mask=None):\n",
    "        \n",
    "        #vehicles_embedding = self.vehicle_embedding(vehicles)\n",
    "        \n",
    "        #print(vehicles_embedding.size(), self.customer_representation.size())\n",
    "        \n",
    "        fleet_representation = self.fleet_attention(vehicles, mask = vehicle_mask)\n",
    "        \n",
    "#         print(fleet_representation.size())\n",
    "        \n",
    "        vehicle_query = fleet_representation.gather(0, vehicle_index.unsqueeze(2).expand(-1, -1, self.model_size))\n",
    "        \n",
    "        self._vehicle_representation = self.vehicle_attention(vehicle_query, \n",
    "                                                              fleet_representation,\n",
    "                                                              fleet_representation)\n",
    "        \n",
    "        return self._vehicle_representation\n",
    "    \n",
    "    \n",
    "    \n",
    "    def score_customers(self, vehicle_representation):\n",
    "        \n",
    "        #print(vehicle_representation.size(), self.customer_representation.size())\n",
    "        compact = torch.bmm(vehicle_representation,\n",
    "                            self.customer_representation.transpose(2,1))\n",
    "        compact *= self.scaling_factor\n",
    "        \n",
    "        if self.tanh_xplor is not None:\n",
    "            compact = self.tanh_xplor*compact.tanh()\n",
    "        \n",
    "        return compact\n",
    "    \n",
    "    \n",
    "    def get_prop(self, compact, vehicle_mask = None):\n",
    "        \n",
    "        compact = compact\n",
    "        \n",
    "        compact[vehicle_mask] = -float('inf')\n",
    "        compact = F.softmax(compact, dim=-1)\n",
    "        return compact\n",
    "    \n",
    "    \n",
    "    def step(self, env, old_action=None):\n",
    "        \n",
    "        _vehicle_representation = self.vehicle_representation(env.vehicles, \n",
    "                                                              env.current_vehicle_index,\n",
    "                                                              env.current_vehicle_mask)\n",
    "        \n",
    "        compact = self.score_customers(_vehicle_representation)\n",
    "        prop = self.get_prop(compact, env.current_vehicle_mask)\n",
    "        print(compact.size())\n",
    "        \n",
    "        # step actions based on model act or evalaute\n",
    "        if old_action is not None:\n",
    "            \n",
    "            # get entropy\n",
    "            dist = Categorical(prop)\n",
    "            old_actions_logp = dist.log_prob(old_action[:, 1].unsqueeze(-1))\n",
    "            entropy = dist.entropy()\n",
    "            \n",
    "            is_done = float(env.done)\n",
    "            \n",
    "            entropy = entropy * (1. - is_done)\n",
    "            old_actions_logp = old_actions_logp*(1. - is_done)\n",
    "            return old_action[:, 1].unsqueeze(-1), entropy, old_actions_logp\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            dist = Categorical(prop)\n",
    "            \n",
    "            if self.greedy:\n",
    "                _, customer_index = p.max(dim=-1)\n",
    "            else:\n",
    "                customer_index = dist.sample()\n",
    "                \n",
    "            is_done = float(env.done)\n",
    "\n",
    "            logp = dist.log_prob(customer_index)\n",
    "            logp = logp * (1. - is_done)\n",
    "            \n",
    "            return customer_index, logp\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, env, old_actions=None, is_update=False):\n",
    "        \n",
    "        if is_update:\n",
    "            env.reset()\n",
    "            entropys, old_actions_logps = [], []\n",
    "            \n",
    "            steps = old_actions.size(0)\n",
    "\n",
    "            for i in range(steps):\n",
    "                if env.new_customer:\n",
    "                    self.encode_customers(env, env.customer_mask)\n",
    "                    \n",
    "                \n",
    "                if i < steps-1:\n",
    "                    old_action = old_actions[i,:,:]\n",
    "                    next_action = old_actions[i+1,:,:]\n",
    "                else:\n",
    "                    # this would be the last action which the agent takes and envrionment is done\n",
    "                    old_action = old_actions[i,:,:]\n",
    "                    next_action = old_actions[i,:,:]\n",
    "                    \n",
    "        \n",
    "                next_vehicle_index = next_action[:,0].unsqueeze(-1)\n",
    "                #print(next_vehicle_index)\n",
    "            \n",
    "\n",
    "                customer_index, entropy, logp = self.step(env, old_action)\n",
    "                \n",
    "                env.step(customer_index, next_vehicle_index)\n",
    "                \n",
    "                old_actions_logps.append(logp)\n",
    "                entropys.append(entropy)\n",
    "                \n",
    "            return entropys, old_actions_logps, 0\n",
    "        \n",
    "        else:\n",
    "            env.reset()\n",
    "            actions, logps, rewards = [], [], []\n",
    "\n",
    "            while not env.done:\n",
    "                if env.new_customer:\n",
    "                    self.encode_customers(env, env.customer_mask)\n",
    "\n",
    "                customer_index, logp = self.step(env)\n",
    "                actions.append((env.current_vehicle_index, customer_index))\n",
    "                logps.append(logp)\n",
    "                rewards.append(env.step(customer_index))\n",
    "                #entropys.append(entropy)\n",
    "\n",
    "            return actions, logps, rewards\n",
    "\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc2ee22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "torch.Size([4, 1, 161])\n",
      "Forward pass ok for DVRPSR\n",
      "Backward pass ok for DVRPSR\n"
     ]
    }
   ],
   "source": [
    "## testing GraphAttentionModel\n",
    "\n",
    "model = GraphAttentionModel(4, 8)\n",
    "actions, logps, rewards = model(env, old_actions, is_update = False)\n",
    "print(\"Forward pass ok for DVRPSR\")\n",
    "\n",
    "from itertools import repeat\n",
    "#loss = reinforce_loss(logps, rewards)\n",
    "#loss.backward()\n",
    "print(\"Backward pass ok for DVRPSR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ae37a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-4.1744],\n",
       "         [-3.6376],\n",
       "         [-3.6376],\n",
       "         [-3.8918]], grad_fn=<MulBackward0>),\n",
       " tensor([[-4.1589e+00],\n",
       "         [-1.1921e-07],\n",
       "         [-1.1921e-07],\n",
       "         [-2.3683e+00]], grad_fn=<MulBackward0>),\n",
       " tensor([[-1.8401e+00],\n",
       "         [-1.1921e-07],\n",
       "         [-2.2021e+00],\n",
       "         [-2.8870e+00]], grad_fn=<MulBackward0>),\n",
       " tensor([[-1.1921e-07],\n",
       "         [-7.2227e-01],\n",
       "         [-1.0987e+00],\n",
       "         [-1.8119e+00]], grad_fn=<MulBackward0>),\n",
       " tensor([[-1.1921e-07],\n",
       "         [-3.8148e+00],\n",
       "         [-1.8328e+00],\n",
       "         [-1.0986e+00]], grad_fn=<MulBackward0>),\n",
       " tensor([[-1.1921e-07],\n",
       "         [-4.1648e+00],\n",
       "         [-9.9588e-01],\n",
       "         [-2.9427e+00]], grad_fn=<MulBackward0>),\n",
       " tensor([[-0.4728],\n",
       "         [-4.0059],\n",
       "         [-2.4854],\n",
       "         [-3.1347]], grad_fn=<MulBackward0>),\n",
       " tensor([[-0.6904],\n",
       "         [-4.0247],\n",
       "         [-2.9444],\n",
       "         [-2.8904]], grad_fn=<MulBackward0>),\n",
       " tensor([[-1.1921e-07],\n",
       "         [-3.8501e+00],\n",
       "         [-3.1348e+00],\n",
       "         [-2.7725e+00]], grad_fn=<MulBackward0>),\n",
       " tensor([[-1.1921e-07],\n",
       "         [-3.0910e+00],\n",
       "         [-3.2581e+00],\n",
       "         [-3.0910e+00]], grad_fn=<MulBackward0>),\n",
       " tensor([[-1.1921e-07],\n",
       "         [-3.0027e+00],\n",
       "         [-3.8255e+00],\n",
       "         [-2.4849e+00]], grad_fn=<MulBackward0>),\n",
       " tensor([[-1.1921e-07],\n",
       "         [-2.4849e+00],\n",
       "         [-3.0444e+00],\n",
       "         [-2.5649e+00]], grad_fn=<MulBackward0>),\n",
       " tensor([[-1.1921e-07],\n",
       "         [-1.6094e+00],\n",
       "         [-3.8124e+00],\n",
       "         [-3.0445e+00]], grad_fn=<MulBackward0>),\n",
       " tensor([[-1.1921e-07],\n",
       "         [-1.7914e+00],\n",
       "         [-3.3673e+00],\n",
       "         [-2.3770e+00]], grad_fn=<MulBackward0>),\n",
       " tensor([[-1.1921e-07],\n",
       "         [-1.1921e-07],\n",
       "         [-2.7081e+00],\n",
       "         [-2.8332e+00]], grad_fn=<MulBackward0>),\n",
       " tensor([[-1.1921e-07],\n",
       "         [-1.1921e-07],\n",
       "         [-2.3026e+00],\n",
       "         [-1.1921e-07]], grad_fn=<MulBackward0>)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d368fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formate_old_actions(actions):\n",
    "    old_actions = []\n",
    "\n",
    "    for action in actions:\n",
    "        old_action = []\n",
    "        for i in range(action[0].size(0)):\n",
    "            old_action.append([action[0][i].item(), action[1][i].item()])\n",
    "        old_actions.append(old_action)             \n",
    "    return old_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebe8db12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w3/d_8f7c794lx5828018pzxrj40000gn/T/ipykernel_63822/2948116958.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  old_actions = torch.tensor(old_actions)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,  90],\n",
       "         [  0, 137],\n",
       "         [  0, 121],\n",
       "         [  0, 106]],\n",
       "\n",
       "        [[  1,  30],\n",
       "         [  1,  40],\n",
       "         [  1,  25],\n",
       "         [  1,  49]],\n",
       "\n",
       "        [[  0, 135],\n",
       "         [  0, 104],\n",
       "         [  0,  49],\n",
       "         [  0,  16]],\n",
       "\n",
       "        [[  0,  46],\n",
       "         [  1, 143],\n",
       "         [  1, 114],\n",
       "         [  1, 154]],\n",
       "\n",
       "        [[  1,  87],\n",
       "         [  1,  45],\n",
       "         [  1, 115],\n",
       "         [  0,  85]],\n",
       "\n",
       "        [[  0,  93],\n",
       "         [  0,  39],\n",
       "         [  0, 119],\n",
       "         [  1,  53]],\n",
       "\n",
       "        [[  0, 126],\n",
       "         [  1, 126],\n",
       "         [  1,   3],\n",
       "         [  0, 151]],\n",
       "\n",
       "        [[  0, 160],\n",
       "         [  1,  87],\n",
       "         [  1,  98],\n",
       "         [  1,  98]],\n",
       "\n",
       "        [[  0, 140],\n",
       "         [  0,  56],\n",
       "         [  0,  51],\n",
       "         [  0,  86]],\n",
       "\n",
       "        [[  1,  29],\n",
       "         [  1, 139],\n",
       "         [  0,  70],\n",
       "         [  0,  67]],\n",
       "\n",
       "        [[  0, 137],\n",
       "         [  0, 120],\n",
       "         [  1,  96],\n",
       "         [  0,   0]],\n",
       "\n",
       "        [[  1,  73],\n",
       "         [  1,  67],\n",
       "         [  0,  20],\n",
       "         [  1,  37]],\n",
       "\n",
       "        [[  0,   1],\n",
       "         [  0,  31],\n",
       "         [  0,  17],\n",
       "         [  0, 113]],\n",
       "\n",
       "        [[  0,   0],\n",
       "         [  1,  98],\n",
       "         [  1, 127],\n",
       "         [  1, 140]],\n",
       "\n",
       "        [[  0,   0],\n",
       "         [  0,   0],\n",
       "         [  0,   9],\n",
       "         [  0,   0]],\n",
       "\n",
       "        [[  0,   0],\n",
       "         [  0,   0],\n",
       "         [  1,  68],\n",
       "         [  0,   0]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_actions = torch.tensor(old_actions)\n",
    "old_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ff3a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = old_actions.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa55a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "786ea117",
   "metadata": {},
   "source": [
    "## PPO agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777defb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score_customers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5e74ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \n",
    "    # critic will take environment as imput and ouput the values for loss function \n",
    "    # which is basically the estimation of complexity of actions\n",
    "    \n",
    "    def __init__(self, model, customers_count, ff_size = 512):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.model = model\n",
    "        self.ff_layer1 = nn.Linear(customers_count, ff_size)\n",
    "        self.ff_layer2 = nn.Linear(ff_size, customers_count)\n",
    "        \n",
    "    def eval_step(self, env, compatibility, customer_index):\n",
    "        compact = compatibility.clone()\n",
    "        compact[env.current_vehicle_mask] = 0\n",
    "        \n",
    "        value = self.ff_layer1(compact)\n",
    "        value = F.relu(value)\n",
    "        value = self.ff_layer2(value)\n",
    "        \n",
    "        val = value.gather(2, customer_index.unsqueeze(1)).expand(-1, 1, -1)\n",
    "        return val.squeeze(1)\n",
    "        \n",
    "        \n",
    "    def __call__(self, env):\n",
    "        self.model.encode_customers(env)\n",
    "        env.reset()\n",
    "        \n",
    "        values = []\n",
    "        \n",
    "        while not env.done:\n",
    "            \n",
    "            _vehicle_presentation = self.model.vehicle_representation(env.vehicles,\n",
    "                                                                     env.current_vehicle_index,\n",
    "                                                                     env.current_vehicle_mask)\n",
    "            compatibility = self.model.score_customers(_vehicle_presentation)\n",
    "            prop = self.model.get_prop(compatibility, env.current_vehicle_mask)\n",
    "            dist = Categorical(prop)\n",
    "            customer_index = dist.sample()\n",
    "            \n",
    "            values.append(self.eval_step(env, compatibility, customer_index))\n",
    "            \n",
    "            return values\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c8544ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.1172],\n",
       "         [-1.0828],\n",
       "         [ 0.4967],\n",
       "         [-1.7914]], grad_fn=<SqueezeBackward1>)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_net = Critic(model, 161, 512)\n",
    "critic_net(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad60bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor_Critic(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                customer_feature,\n",
    "                vehicle_feature,\n",
    "                customers_count,\n",
    "                model_size = 128,\n",
    "                encoder_layer = 3,\n",
    "                num_head = 8,\n",
    "                ff_size_actor = 128,\n",
    "                ff_size_critic = 512,\n",
    "                tanh_xplor = 10,\n",
    "                edge_embedding_dim = 64,\n",
    "                greedy = False):\n",
    "        \n",
    "        super(Actor_Critic, self).__init__()\n",
    "        \n",
    "        model = GraphAttentionModel(customer_feature, vehicle_feature, model_size, encoder_layer, \n",
    "                                        num_head, ff_size_actor, tanh_xplor, edge_embedding_dim, greedy)\n",
    "        self.actor = model\n",
    "        \n",
    "        self.critic = Critic(model, customers_count, ff_size_critic)\n",
    "        \n",
    "    def act(self, env, old_actions, is_update):\n",
    "        \n",
    "        actions, logps, rewards = self.actor(env)\n",
    "        return actions, logps, rewards\n",
    "    \n",
    "    \n",
    "    def evaluate(self, env, old_actions, is_update):\n",
    "        \n",
    "        entropys, old_logps, _ = self.actor(env, old_actions, is_update)\n",
    "        values = self.Critic(env)\n",
    "        return entropys, values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989422cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767c070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c4497b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12b1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b8d2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d806d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea23be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98fc7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268858e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82964b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12507612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a3d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0f31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b10234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7290f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
