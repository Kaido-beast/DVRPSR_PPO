{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "703636c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d503e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DVRPSR_Dataset(Dataset):\n",
    "\n",
    "    customer_feature = 4 # customer features location (x_i,y_i) and duration of service(d), appearance (u)\n",
    "\n",
    "    @classmethod\n",
    "    def create_data(cls,\n",
    "                    batch_size = 2,\n",
    "                    vehicle_count = 2,\n",
    "                    vehicle_speed = 20, # km/hr\n",
    "                    Lambda = 0.025, # request rate per min\n",
    "                    dod = 0.5,\n",
    "                    horizon = 400,\n",
    "                    fDmean = 10,\n",
    "                    fDstd = 2.5):\n",
    "\n",
    "\n",
    "        # static customer counts V = Lambda*horizon*(1-dod)/(dod+0.5)\n",
    "        V_static = int(Lambda*horizon*(1-dod)/(dod)+0.5)\n",
    "\n",
    "        # total customer count\n",
    "        V = int(Lambda*horizon/(dod) + 0.5)\n",
    "\n",
    "        size = (batch_size, V, 1)\n",
    "        \n",
    "        # initialize the graph of vienna network\n",
    "        graph = cls.initialize_graph()\n",
    "\n",
    "        # get the coordinates of customers\n",
    "        data_vienna = pd.read_csv('vienna_cordinates.csv')\n",
    "\n",
    "        # get depot coordinates: Id, xcoords, ycoords\n",
    "        depot = cls.get_depot_location(data_vienna)\n",
    "\n",
    "        # get location of customers: id, xcoords, ycoords\n",
    "        locations = cls.get_customers_coordinates(data_vienna, batch_size, V, depot)\n",
    "\n",
    "        # get edges index and attributes, which is distance between one node to others n_i*n_j\n",
    "        edges_index, edges_attributes = cls.get_edges_attributes(batch_size, graph, depot, locations, V)\n",
    "        \n",
    "        ### generate Static_Dynamic customer requests\n",
    "        dynamic_request = cls.generateRandomDynamicRequests(batch_size,\n",
    "                                                            V,\n",
    "                                                            V_static,\n",
    "                                                            fDmean,\n",
    "                                                            fDstd,\n",
    "                                                            Lambda,\n",
    "                                                            horizon)\n",
    "\n",
    "        customers = torch.zeros((batch_size,V,cls.customer_feature))\n",
    "        customers[:,:,:2] = locations[:,:,1:]\n",
    "        customers[:,:,2:4] = dynamic_request\n",
    "\n",
    "\n",
    "\n",
    "        depo = torch.zeros((batch_size, 1, cls.customer_feature))\n",
    "        depo[:,:,0:2] = torch.from_numpy(depot[0][1:])\n",
    "        depo[:,:,2] =  0\n",
    "\n",
    "        nodes = torch.cat((depo, customers), 1)\n",
    "        \n",
    "        dataset = cls(vehicle_count, vehicle_speed, horizon, nodes, V, \n",
    "                      edges_index, edges_attributes, customer_mask = None)\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    def __init__(self, vehicle_count, vehicle_speed, horizon, nodes, V,\n",
    "                 edges_index, edges_attributes, customer_mask=None):\n",
    "        \n",
    "        self.vehicle_count = vehicle_count\n",
    "        self.vehicle_speed = vehicle_speed\n",
    "        self.nodes = nodes\n",
    "        self.vehicle_time_budget = horizon\n",
    "        self.edges_index = edges_index\n",
    "        self.edges_attributes = edges_attributes\n",
    "\n",
    "        self.batch_size, self.nodes_count, d = self.nodes.size()\n",
    "\n",
    "        if d!= self.customer_feature:\n",
    "            raise ValueError(\"Expected {} customer features per nodes, got {}\".format(\n",
    "                self.customer_feature, d))\n",
    "\n",
    "        self.customer_mask = customer_mask\n",
    "        self.customer_count = V\n",
    "        \n",
    "        \n",
    "    def initialize_graph():\n",
    "    \n",
    "        coordinates = pd.read_csv(\"vienna_dist.csv\", header = None, sep=' ')\n",
    "        coordinates.columns = ['coord1','coord2','dist']\n",
    "        graph = nx.DiGraph()\n",
    "\n",
    "        # add the rows to the graph for shortest path and distance calculations\n",
    "        for _, row in coordinates.iterrows():\n",
    "            graph.add_edge(row['coord1'], row['coord2'], weight=row['dist'])\n",
    "\n",
    "        return graph\n",
    "\n",
    "\n",
    "    def precompute_shortest_path(graph, start_node, end_node):\n",
    "\n",
    "        shortest_path = nx.shortest_path(graph, start_node, end_node)\n",
    "\n",
    "        # TODO: distance need to be normalized afterwords\n",
    "        shortest_path_length = sum(graph.get_edge_data(u, v)['weight'] \n",
    "                                   for u, v in zip(shortest_path, shortest_path[1:]))\n",
    "\n",
    "        return shortest_path, shortest_path_length \n",
    "    \n",
    "    \n",
    "    def get_distanceLL(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "        R = 6371  # Radius of the Earth in kilometers\n",
    "\n",
    "        lat1_rad = math.radians(lat1)\n",
    "        lon1_rad = math.radians(lon1)\n",
    "        lat2_rad = math.radians(lat2)\n",
    "        lon2_rad = math.radians(lon2)\n",
    "\n",
    "        dlat = lat2_rad - lat1_rad\n",
    "        dlon = lon2_rad - lon1_rad\n",
    "\n",
    "        a = math.sin(dlat / 2) ** 2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2) ** 2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "        distance = R * c\n",
    "        return distance\n",
    "    \n",
    "\n",
    "    def get_NearestNodeLL(lat, lon, lats, lons):\n",
    "        nearest = (-1, sys.float_info.max)\n",
    "        for i in range(len(lats)):\n",
    "            dist = DVRPSR_Dataset.get_distanceLL(lat, lon, lats[i], lons[i])\n",
    "            if dist < nearest[1]:\n",
    "                nearest = (i, dist)\n",
    "        return nearest[0]\n",
    "    \n",
    "\n",
    "\n",
    "    def get_depot_location(data_vienna):\n",
    "\n",
    "        ll = (48.178808, 16.438460)\n",
    "        lat = ll[0] / 180 * math.pi\n",
    "        lon = ll[1] / 180 * math.pi\n",
    "        lats = data_vienna['lats']\n",
    "        lons = data_vienna['lons']\n",
    "        depot = DVRPSR_Dataset.get_NearestNodeLL(lat, lon, lats, lons)\n",
    "        depot_coordinates = np.array(data_vienna[data_vienna['id']==depot][['id','xcoords', 'ycoords']])\n",
    "\n",
    "        return depot_coordinates\n",
    "    \n",
    "    def get_customers_coordinates(data_vienna, batch_size, customers_count, depot):\n",
    "        \n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # Excluding depot id from the customers selection\n",
    "        data_vienna_without_depot = data_vienna[data_vienna['id'] != int(depot[0][0])].reset_index()\n",
    "\n",
    "        # Sample customers indices for all batches at once\n",
    "        sampled_customers = torch.multinomial(torch.tensor(data_vienna_without_depot['id'], dtype=torch.float32),\n",
    "                                              num_samples=batch_size * customers_count, replacement=True)\n",
    "        \n",
    "        sampled_customers = sampled_customers.reshape(batch_size, customers_count)\n",
    "\n",
    "        # Gather the sampled locations using the indices\n",
    "        sampled_locations = data_vienna_without_depot.loc[sampled_customers.flatten()].reset_index(drop=True)\n",
    "\n",
    "        # Reshape the locations to match the batch size\n",
    "        locations = sampled_locations.groupby(sampled_locations.index // customers_count)\n",
    "\n",
    "        # Create PyTorch tensors for the batched data\n",
    "        locations_tensors = []\n",
    "        for _, batch in locations:\n",
    "            id_tensor = torch.tensor(batch['id'].values, dtype=torch.long)\n",
    "            coords_tensor = torch.tensor(batch[['xcoords', 'ycoords']].values, dtype=torch.float32)\n",
    "            batch_tensor = torch.cat((id_tensor.unsqueeze(1), coords_tensor), dim=1)\n",
    "            locations_tensors.append(batch_tensor)\n",
    "\n",
    "        return torch.stack(locations_tensors)\n",
    "    \n",
    "    def c_dist(x1,x2):\n",
    "        return ((x1[0]-x2[0])**2+(x1[1]-x2[1])**2)**0.5\n",
    "    \n",
    "    def get_edges_attributes(batch_size, graph, depot, locations, V):\n",
    "    \n",
    "        # all customers ID inclusing depot\n",
    "        \n",
    "        print('Initialzing edges')\n",
    "        edge_depot = torch.zeros((batch_size, 1, 2))\n",
    "        edge_depot[:,:,0] = depot[0][1]\n",
    "        edge_depot[:,:,1] = depot[0][2]\n",
    "        edge_data = torch.cat((edge_depot, locations[:,:,1:3]), dim=1)\n",
    "\n",
    "        # generate edge index\n",
    "        edges_index = []\n",
    "\n",
    "        for i in range(V+1):\n",
    "            for j in range(V+1):\n",
    "                edges_index.append([i, j])\n",
    "        edges_index = torch.LongTensor(edges_index)\n",
    "        edges_index = edges_index.transpose(dim0=0,dim1=1)\n",
    "\n",
    "        # generate nodes attributes\n",
    "        edges_batch = []\n",
    "\n",
    "        for batch in edge_data:\n",
    "            edges = torch.zeros((V+1, V+1, 1), dtype=torch.float32)\n",
    "            for i, node1 in enumerate(batch):\n",
    "                for j, node2 in enumerate(batch):\n",
    "                    distance = DVRPSR_Dataset.c_dist(node1, node2)\n",
    "                    edges[i][j][0] = distance\n",
    "\n",
    "            edges = edges.reshape(-1, 1)\n",
    "            edges_batch.append(edges)\n",
    "\n",
    "        return edges_index, torch.stack(edges_batch)\n",
    "    \n",
    "    \n",
    "    def generateRandomDynamicRequests(batch_size=2 ,\n",
    "                                      V=20,\n",
    "                                      V_static=10,\n",
    "                                      fDmean=10,\n",
    "                                      fDstd=2.5,\n",
    "                                      Lambda=0.025,\n",
    "                                      horizon=400,\n",
    "                                      dep = 0,\n",
    "                                      u = 0):\n",
    "        gen = random.Random()\n",
    "        gen.seed() # uses the default system seed\n",
    "        unifDist = gen.random # uniform distribution\n",
    "        durDist = lambda: max(0.01, gen.gauss(fDmean, fDstd)) # normal distribution with fDmean and fDstd\n",
    "\n",
    "        # TODO: in actual data , we need to add a depo node with corrdinate, which should be removed from selected\n",
    "        #       nodes as well.\n",
    "\n",
    "        requests = []\n",
    "        for b in range(batch_size):\n",
    "\n",
    "            static_request = []\n",
    "            dynamic_request = []\n",
    "            u = 0\n",
    "\n",
    "            while True:\n",
    "                unif = unifDist()\n",
    "                u += -(1/Lambda) * math.log(unif)\n",
    "                if u > horizon or len(dynamic_request) > (V-V_static+2):\n",
    "                    break\n",
    "                d = round(durDist(),2)\n",
    "                while d<=0:\n",
    "                    d = round(durDist(),2)\n",
    "\n",
    "                dynamic_request.append([d, round(u,2)])\n",
    "\n",
    "            for j in range(V-len(dynamic_request)):\n",
    "                d = round(durDist(),2)\n",
    "                while d<=0:\n",
    "                    d = round(durDist(),2)\n",
    "                static_request.append([d,0])\n",
    "\n",
    "            request = static_request+dynamic_request\n",
    "            random.shuffle(request)\n",
    "            requests.append(request)\n",
    "\n",
    "        return torch.tensor(requests)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.customer_mask is None:\n",
    "            return self.nodes[i]\n",
    "        else:\n",
    "            return self.nodes[i], self.customer_mask[i]\n",
    "\n",
    "    def nodes_generate(self):\n",
    "        if self.customer_mask is None:\n",
    "            yield from self.nodes\n",
    "        else:\n",
    "            yield from (n[m^1] for n,m in zip(self.nodes, self.customer_mask))  \n",
    "            \n",
    "            \n",
    "    def normalize(self):\n",
    "        loc_max, loc_min = self.nodes[:,:,:2].max().item(), self.nodes[:,:,:2].min().item()\n",
    "        loc_max -= loc_min\n",
    "        edge_max_length = self.edges_attributes[:,:,0].max().item()\n",
    "\n",
    "        self.nodes[:,:,:2] -= loc_min\n",
    "        self.nodes[:,:,:2] /= loc_max\n",
    "        self.nodes[:,:,2:] /=self.vehicle_time_budget\n",
    "\n",
    "        self.vehicle_speed *= self.vehicle_time_budget/edge_max_length\n",
    "        self.vehicle_time_budget = 1\n",
    "        self.edges_attributes /= edge_max_length\n",
    "        return loc_max, 1\n",
    "\n",
    "    def save(self, folder_path):\n",
    "        torch.save({\n",
    "            'veh_count':self.vehicle_count,\n",
    "            'veh_speed':self.vehicle_speed,\n",
    "            'nodes':self.nodes,\n",
    "            'edges_index':self.edges_index,\n",
    "            'edges_attributes':self.edges_attributes,\n",
    "            'customer_count':self.customer_count,\n",
    "            'customer_mask':self.customer_mask\n",
    "        }, folder_path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, folder_path):\n",
    "        return cls(**torch.load(folder_path))\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9250dd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialzing edges\n"
     ]
    }
   ],
   "source": [
    "data = DVRPSR_Dataset.create_data(batch_size=2, vehicle_count=2,vehicle_speed=1/3, Lambda=0.2, dod=0.75, horizon=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebd818",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a38b6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class DVRPSR_Environment:\n",
    "    vehicle_feature = 8  # vehicle coordinates(x_i,y_i), veh_time_time_budget, total_travel_time, last_customer,\n",
    "                         # next(destination) customer, last rewards, next rewards\n",
    "    customer_feature = 4\n",
    "\n",
    "    # TODO: change pending cost for rewards\n",
    "\n",
    "    def __init__(self, data, nodes=None, customer_mask=None, \n",
    "                 pending_cost=1, \n",
    "                 dynamic_reward=0.2,\n",
    "                 budget_penalty = 10):\n",
    "\n",
    "        self.vehicle_count = data.vehicle_count\n",
    "        self.vehicle_speed = data.vehicle_speed\n",
    "        self.vehicle_time_budget = data.vehicle_time_budget\n",
    "\n",
    "        self.nodes = data.nodes if nodes is None else nodes\n",
    "        self.edge_index = data.edges_index\n",
    "        self.edge_attributes = data.edges_attributes\n",
    "        self.init_customer_mask = data.customer_mask if customer_mask is None else customer_mask\n",
    "\n",
    "        self.minibatch, self.nodes_count, _ = self.nodes.size()\n",
    "        self.distance_matrix = data.edges_attributes.view((self.minibatch, self.nodes_count, self.nodes_count))\n",
    "        self.pending_cost = pending_cost\n",
    "        self.dynamic_reward = dynamic_reward\n",
    "        self.budget_penalty = budget_penalty\n",
    "\n",
    "    def _update_current_vehicles(self, dest, customer_index, tau=0):\n",
    "\n",
    "        # calculate travel time\n",
    "        # TODO: 1) in real world setting we need to calculate the distance of arc\n",
    "        # If nodes i and j are directly connected by a road segment (i, j) ∈ A, then t(i,j)=t_ij;\n",
    "        # otherwise, t(i,j)=t_ik1 +t_k1k2 +...+t_knj, where k1,...,kn ∈ V are the nodes along the\n",
    "        # shortest path from node i to node j.\n",
    "        #      2) calculate stating time for each vehicle $\\tau $, currently is set to zero\n",
    "        \n",
    "        # update vehicle previous and next customer id\n",
    "        self.current_vehicle[:, :, 4] = self.current_vehicle[:, :, 5]\n",
    "        self.current_vehicle[:, :, 5] = customer_index\n",
    "        \n",
    "        # get the distance from current vehicle to its next destination\n",
    "        dist = torch.zeros((self.minibatch, 1))\n",
    "        for i in range(self.minibatch):\n",
    "            dist[i, 0] = self.distance_matrix[i][int(self.current_vehicle[i, :, 4])][int(self.current_vehicle[i, :, 5])]\n",
    "            \n",
    "        \n",
    "        # total travel time    \n",
    "        tt = dist / self.vehicle_speed\n",
    "\n",
    "        # customers which are dynamicaly appeared\n",
    "        dyn_cust = (dest[:, :, 3] > 0).float()\n",
    "\n",
    "        # budget left while travelling to destination nodes\n",
    "        budget = tau + tt + dest[:, :, 2]\n",
    "        # print(budget, tau, tt, dest[:,:,2])\n",
    "\n",
    "        # update vehicle features based on destination nodes\n",
    "        self.current_vehicle[:, :, :2] = dest[:, :, :2]\n",
    "        self.current_vehicle[:, :, 2] -= budget\n",
    "        self.current_vehicle[:, :, 3] += tt\n",
    "        self.current_vehicle[:, :, 6] = self.current_vehicle[:, :, 7]\n",
    "        self.current_vehicle[:, :, 7] = -dist\n",
    "\n",
    "        # update vehicles states\n",
    "        self.vehicles = self.vehicles.scatter(1,\n",
    "                                              self.current_vehicle_index[:, :, None].expand(-1, -1, self.vehicle_feature),\n",
    "                                              self.current_vehicle)\n",
    "\n",
    "        return dist, dyn_cust\n",
    "\n",
    "    def _done(self, customer_index):\n",
    "        \n",
    "        self.vehicle_done.scatter_(1, self.current_vehicle_index, torch.logical_or((customer_index == 0), \n",
    "                                                                     (self.current_vehicle[:, :, 2] <= 0)))\n",
    "        # print(self.veh_done, cust_idx==0,self.cur_veh[:,:,2]<=0, (cust_idx==0) | (self.cur_veh[:,:,2]<=0))\n",
    "        self.done = bool(self.vehicle_done.all())\n",
    "\n",
    "    def _update_mask(self, customer_index):\n",
    "\n",
    "        self.new_customer = False\n",
    "        self.served.scatter_(1, customer_index, customer_index > 0)\n",
    "\n",
    "        # cost for a vehicle to go to customer and back to deport considering service duration\n",
    "        cost = torch.zeros((self.minibatch, self.nodes_count,1))\n",
    "        for i in range(self.minibatch):\n",
    "            for j in range(self.nodes_count):\n",
    "                dist_vehicle_customer_depot = self.distance_matrix[i][int(self.current_vehicle[i, :, 4])][j] + \\\n",
    "                                              self.distance_matrix[i][j][0]\n",
    "                cost[i,j] = dist_vehicle_customer_depot\n",
    "                \n",
    "        cost = cost / self.vehicle_speed\n",
    "\n",
    "        cost += self.nodes[:, :, None, 2]\n",
    "\n",
    "        overtime_mask = self.current_vehicle[:, :, None, 2] - cost\n",
    "        overtime_mask = overtime_mask.squeeze(2).unsqueeze(1)\n",
    "        overtime = torch.zeros_like(self.mask).scatter_(1,\n",
    "                                                        self.current_vehicle_index[:, :, None].expand(-1, -1, self.nodes_count),\n",
    "                                                        overtime_mask < 0)\n",
    "\n",
    "        self.mask = self.mask | self.served[:, None, :] | overtime | self.vehicle_done[:, :, None]\n",
    "        self.mask[:, :, 0] = 0  # depot\n",
    "\n",
    "    # updating current vehicle to find the next available vehicle\n",
    "    def _update_next_vehicle(self):\n",
    "        \n",
    "        avail = self.vehicles[:, :, 3].clone()\n",
    "        avail[self.vehicle_done] = float('inf')\n",
    "\n",
    "        self.current_vehicle_index = avail.argmin(1, keepdim=True)\n",
    "        self.current_vehicle = self.vehicles.gather(1, self.current_vehicle_index[:, :, None].expand(-1, -1, self.vehicle_feature))\n",
    "        self.current_vehicle_mask = self.mask.gather(1, self.current_vehicle_index[:, :, None].expand(-1, -1, self.nodes_count))\n",
    "\n",
    "    def _update_dynamic_customers(self):\n",
    "\n",
    "        time = self.current_vehicle[:, :, 3].clone()\n",
    "\n",
    "        if self.init_customer_mask is None:\n",
    "            reveal_dyn_reqs = torch.logical_and((self.customer_mask), (self.nodes[:, :, 3] <= time))\n",
    "        else:\n",
    "            reveal_dyn_reqs = torch.logical_and((self.customer_mask ^ self.init_customer_mask), (self.nodes[:, :, 3] <= time))\n",
    "\n",
    "        if reveal_dyn_reqs.any():\n",
    "            self.new_customer = True\n",
    "            self.customer_mask = self.customer_mask ^ reveal_dyn_reqs\n",
    "            self.mask = self.mask ^ reveal_dyn_reqs[:, None, :].expand(-1, self.vehicle_count, -1)\n",
    "            self.vehicle_done = torch.logical_and(self.vehicle_done, (reveal_dyn_reqs.any(1) ^ True).unsqueeze(1))\n",
    "            self.vehicles[:, :, 3] = torch.max(self.vehicles[:, :, 3], time)\n",
    "            self._update_next_vehicle()\n",
    "\n",
    "    def reset(self):\n",
    "        # reset vehicle (minibatch*veh_count*veh_feature)\n",
    "        self.vehicles = self.nodes.new_zeros((self.minibatch, self.vehicle_count, self.vehicle_feature))\n",
    "        self.vehicles[:, :, :2] = self.nodes[:, :1, :2]\n",
    "        self.vehicles[:, :, 2] = self.vehicle_time_budget\n",
    "\n",
    "        # reset vehicle done\n",
    "        self.vehicle_done = self.nodes.new_zeros((self.minibatch, self.vehicle_count), dtype=torch.bool)\n",
    "        self.done = False\n",
    "\n",
    "        # reset cust_mask\n",
    "        self.customer_mask = self.nodes[:, :, 3] > 0\n",
    "        if self.init_customer_mask is not None:\n",
    "            self.customer_mask = self.customer_mask | self.init_customer_mask\n",
    "\n",
    "        # reset new customers and served customer since now to zero (all false)\n",
    "        self.new_customer = True\n",
    "        self.served = torch.zeros_like(self.customer_mask)\n",
    "\n",
    "        # reset mask (minibatch*veh_count*nodes)\n",
    "        self.mask = self.customer_mask[:, None, :].repeat(1, self.vehicle_count, 1)\n",
    "\n",
    "        # reset current vehicle index, current vehicle, current vehicle mask\n",
    "        self.current_vehicle_index = self.nodes.new_zeros((self.minibatch, 1), dtype=torch.int64)\n",
    "        \n",
    "        self.current_vehicle = self.vehicles.gather(1, \n",
    "                                                    self.current_vehicle_index[:, :, None].expand(-1, -1, self.vehicle_feature))\n",
    "        self.current_vehicle_mask = self.mask.gather(1, \n",
    "                                             self.current_vehicle_index[:, :, None].expand(-1, -1, self.nodes_count))\n",
    "\n",
    "    \n",
    "    def step(self, customer_index):\n",
    "        dest = self.nodes.gather(1, customer_index[:, :, None].expand(-1, -1, self.customer_feature))\n",
    "        dist, dyn_cust = self._update_current_vehicles(dest, customer_index)\n",
    "\n",
    "        #cust = (dest[:, :, 3] >= 0).float()\n",
    "\n",
    "        self._done(customer_index)\n",
    "        self._update_mask(customer_index)\n",
    "        self._update_next_vehicle()\n",
    "\n",
    "        #reward = -dist * (1 - dyn_cust*self.dynamic_reward)\n",
    "        reward = self.current_vehicle[:, :, 7] - self.current_vehicle[:,:,6] + self.dynamic_reward*dyn_cust\n",
    "        pending_static_customers = torch.logical_and((self.served ^ True), \n",
    "                                                     (self.nodes[:, :, 3] == 0)).float().sum(-1,keepdim=True) - 1\n",
    "        \n",
    "        reward -= self.pending_cost*pending_static_customers\n",
    "\n",
    "        if self.done:\n",
    "\n",
    "            if self.init_customer_mask is not None:\n",
    "                self.served += self.init_customer_mask\n",
    "            # penalty for pending customers\n",
    "            pending_customers = torch.logical_and((self.served ^ True), \n",
    "                                                  (self.nodes[:, :, 3] >= 0)).float().sum(-1, keepdim=True) - 1\n",
    "\n",
    "            # TODO: penalty for having unused time budget as well not serving customers\n",
    "            reward -= self.dynamic_reward*pending_customers\n",
    "            \n",
    "\n",
    "        self._update_dynamic_customers()\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def state_dict(self, dest_dict=None):\n",
    "        if dest_dict is None:\n",
    "            dest_dict = {'vehicles': self.vehicles,\n",
    "                         'vehicle_done': self.vehicle_done,\n",
    "                         'served': self.served,\n",
    "                         'mask': self.mask,\n",
    "                         'current_vehicle_index': self.current_vehicle_index}\n",
    "\n",
    "        else:\n",
    "            dest_dict[\"vehicles\"].copy_(self.vehicles)\n",
    "            dest_dict[\"vehicle_done\"].copy_(self.vehicle_done)\n",
    "            dest_dict[\"served\"].copy_(self.served)\n",
    "            dest_dict[\"mask\"].copy_(self.mask)\n",
    "            dest_dict[\"current_vehicle_index\"].copy_(self.current_vehicle_index)\n",
    "\n",
    "        return dest_dict\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.vehicles.copy_(state_dict[\"vehicles\"])\n",
    "        self.vehicle_done.copy_(state_dict[\"vehicle_done\"])\n",
    "        self.served.copy_(state_dict[\"served\"])\n",
    "        self.mask.copy_(state_dict[\"mask\"])\n",
    "        self.current_vehicle_index.copy_(state_dict[\"current_vehicle_index\"])\n",
    "\n",
    "        self.current_vehicle = self.vehicles.gather(1, \n",
    "                                                    self.current_vehicle_index[:, :, None].expand(-1, -1, self.vehicle_feature))\n",
    "        self.current_vehicle_mask = self.mask.gather(1, self.current_vehicle_index[:, :, None].expand(-1, -1, self.customer_feature))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac8789c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.normalize()\n",
    "env = DVRPSR_Environment(data)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e3f2d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.step(torch.tensor([[1],[2],[3],[4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64eae784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 25921])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.edge_index.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e7b70cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16844ad1",
   "metadata": {},
   "source": [
    "## Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51333e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "import math\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22297a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT = True\n",
    "\n",
    "\n",
    "class GatConv(MessagePassing):\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel, edge_channel,\n",
    "                negative_slope = 0.2, dropout = 0):\n",
    "        \n",
    "        super(GatConv, self).__init__(aggr='sum')\n",
    "        \n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.edge_channel = edge_channel\n",
    "        \n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.fc = nn.Linear(self.in_channel, self.out_channel)\n",
    "        self.attention = nn.Linear(2*self.out_channel + self.edge_channel , self.out_channel)\n",
    "        \n",
    "        if INIT:\n",
    "            \n",
    "            for name, p in self.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    if len(p.size()) >= 2:\n",
    "                        nn.init.orthogonal_(p, gain=1)\n",
    "                elif 'bias' in name:\n",
    "                    nn.init.constant_(p, 0)\n",
    "                    \n",
    "    def forward(self, x, edge_index, edge_attributes, customer_mask = None, size = None):\n",
    "        x = self.fc(x)\n",
    "        return self.propagate(edge_index, size=size, x=x, edge_attributes = edge_attributes)\n",
    "\n",
    "\n",
    "    def message(self, edge_index_i, x_i, x_j, edge_attributes):\n",
    "\n",
    "        x = torch.cat([x_i, x_j, edge_attributes], dim=1)\n",
    "        alpha = self.attention(x)\n",
    "        alpha = F.leaky_relu(alpha, self.negative_slope)\n",
    "        alpha = softmax(alpha, edge_index_i)\n",
    "\n",
    "        # Sample attention coefficients stochastically.\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "\n",
    "        return x_j * alpha\n",
    "\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "class GatEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_node_dim, hidden_node_dim, input_edge_dim, hidden_edge_dim, conv_layers = 3):\n",
    "        \n",
    "        super(GatEncoder, self).__init__()\n",
    "        \n",
    "        self.hidden_node_dim = hidden_node_dim\n",
    "        self.fc_node = nn.Linear(input_node_dim, hidden_node_dim)\n",
    "        self.fc_depot = nn.Linear(input_node_dim, hidden_node_dim)\n",
    "        \n",
    "        self.fc_edge = nn.Linear(input_edge_dim, hidden_edge_dim)\n",
    "        \n",
    "        self.bn_node = nn.BatchNorm1d(hidden_node_dim)\n",
    "        self.bn_edge = nn.BatchNorm1d(hidden_edge_dim)\n",
    "        \n",
    "        self.convs = nn.ModuleList(\n",
    "                     [GatConv(hidden_node_dim, hidden_node_dim, hidden_edge_dim) for i in range(conv_layers)])\n",
    "            \n",
    "        if INIT:\n",
    "            for name, p in self.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    if len(p.size()) >= 2:\n",
    "                        nn.init.orthogonal_(p, gain=1)\n",
    "                elif 'bias' in name:\n",
    "                    nn.init.constant_(p, 0)\n",
    "            \n",
    "    def forward(self, env, mask=None):\n",
    "            \n",
    "        batch_size = env.minibatch\n",
    "        nodes_count = env.nodes_count\n",
    "        \n",
    "        x = env.nodes\n",
    "\n",
    "        customer_embed = torch.cat((self.fc_depot(x[:, :1, :]),\n",
    "                                    self.fc_node(x[:, 1:, :])), dim=1)\n",
    "        if mask is not None:\n",
    "            customer_embed[mask] = 0\n",
    "            \n",
    "        x = customer_embed.view(batch_size*nodes_count, self.hidden_node_dim)\n",
    "        x = self.bn_node(x)\n",
    "\n",
    "        edge_attributes = self.fc_edge(env.edge_attributes.view(batch_size*nodes_count*nodes_count,1).float())\n",
    "        edge_attributes = self.bn_edge(edge_attributes)\n",
    "        edge_index = env.edge_index.repeat(batch_size,1).view(2,batch_size*nodes_count*nodes_count)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x1 = conv(x, edge_index, edge_attributes)\n",
    "            x = x + x1\n",
    "\n",
    "        x = x.reshape((batch_size, -1, self.hidden_node_dim))\n",
    "\n",
    "        return x\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "baf4ae17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GatEncoder(\n",
       "  (fc_node): Linear(in_features=4, out_features=128, bias=True)\n",
       "  (fc_depot): Linear(in_features=4, out_features=128, bias=True)\n",
       "  (fc_edge): Linear(in_features=1, out_features=16, bias=True)\n",
       "  (bn_node): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn_edge): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (convs): ModuleList(\n",
       "    (0-2): 3 x GatConv()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "encoder = GatEncoder(input_node_dim = 4, hidden_node_dim=128, input_edge_dim=1, hidden_edge_dim=16, conv_layers=3)\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "016c4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.nodes = env.nodes.to(device)\n",
    "env.edge_attributes = env.edge_attributes.to(device)\n",
    "env.edge_index = env.edge_index.to(device)\n",
    "x = encoder(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9c48fba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmm\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mm' is not defined"
     ]
    }
   ],
   "source": [
    "mm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14ccc6",
   "metadata": {},
   "source": [
    "## Graph Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce3c311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_head, query_size, key_size = None, value_size = None, edge_dim_size = None, bias = False):\n",
    "        \n",
    "        super(GraphMultiHeadAttention, self).__init__()\n",
    "        self.num_head = num_head\n",
    "        self.query_size = query_size\n",
    "        \n",
    "        self.key_size = self.query_size if key_size is None else key_size\n",
    "        self.value_size = self.key_size if value_size is None else value_size\n",
    "        self.edge_dim_size = self.query_size//2 if edge_dim_size is None else edge_dim_size\n",
    "        \n",
    "        self.scaling_factor = self.key_size**-0.5\n",
    "        \n",
    "        self.keys_per_head = self.key_size // self.num_head\n",
    "        self.values_per_head = self.value_size // self.num_head\n",
    "        self.edge_size_per_head = self.edge_dim_size\n",
    "        \n",
    "        self.edge_embedding = nn.Linear(self.edge_dim_size, self.edge_size_per_head, bias = bias)\n",
    "        self.query_embedding = nn.Linear(self.query_size, self.num_head * self.keys_per_head, bias = bias)\n",
    "        self.key_embedding = nn.Linear(self.key_size, self.num_head * self.keys_per_head, bias = bias)\n",
    "        self.value_embedding = nn.Linear(self.value_size, self.num_head * self.values_per_head, bias = bias)\n",
    "        self.recombine = nn.Linear(self.num_head * self.values_per_head, self.value_size, bias = bias)\n",
    "        \n",
    "        \n",
    "        self.K_project_pre = None\n",
    "        self.V_project_pre = None\n",
    "        \n",
    "        self.initialize_weights()\n",
    "\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        #TODO: add xavier initialziation as well\n",
    "        \n",
    "        nn.init.uniform_(self.query_embedding.weight, -self.scaling_factor, self.scaling_factor)\n",
    "        nn.init.uniform_(self.key_embedding.weight, -self.scaling_factor, self.scaling_factor)\n",
    "        inv_sq_dv = self.value_size ** -0.5\n",
    "        nn.init.uniform_(self.value_embedding.weight, -inv_sq_dv, inv_sq_dv)\n",
    "        \n",
    "    def precompute(self, keys, values = None):\n",
    "        \n",
    "        values = keys if values is None else values\n",
    "        \n",
    "        size_KV = keys.size(-2)\n",
    "        \n",
    "        self.K_project_pre = self.key_embedding(keys).view(\n",
    "                             -1, size_KV, self.num_head, self.keys_per_head).permute(0, 2, 3, 1)\n",
    "        \n",
    "        self.V_project_pre = self.value_embedding(values).view(\n",
    "                              -1, size_KV, self.num_head, self.values_per_head).permute(0, 2, 1, 3)\n",
    "        \n",
    "        \n",
    "    def forward(self, queries, keys = None, values = None, edge_attributes = None, mask = None, edge_mask=None):\n",
    "        \n",
    "        *batch_size, size_Q, _ = queries.size()\n",
    "        \n",
    "        # get queries projection\n",
    "        Q_project = self.query_embedding(queries).view(\n",
    "                              -1, size_Q, self.num_head, self.keys_per_head).permute(0, 2, 1, 3)\n",
    "        \n",
    "        # get keys projection\n",
    "        if keys is None:\n",
    "            if self.K_project_pre is None:\n",
    "                size_KV = size_Q\n",
    "                K_project = self.key_embedding(queries).view(\n",
    "                                -1, size_KV, self.num_head, self.keys_per_head).permute(0, 2, 3, 1)\n",
    "            else:\n",
    "                size_KV = self.K_project_pre.size(-1)\n",
    "                K_project = self.K_project_pre\n",
    "        else:\n",
    "            size_KV = keys.size(-2)\n",
    "            K_project = self.key_embedding(keys).view(\n",
    "                            -1, size_KV, self.num_head, self.keys_per_head).permute(0, 2, 3, 1)\n",
    "            \n",
    "         # get values projection   \n",
    "        if values is None:\n",
    "            if self.V_project_pre is None:\n",
    "                V_project = self.value_embedding(queries).view(\n",
    "                                -1, size_KV, self.num_head, self.values_per_head).permute(0, 2, 1, 3)\n",
    "            else:\n",
    "                V_project = self.V_project_pre\n",
    "        else:\n",
    "            V_project = self.value_embedding(values).view(\n",
    "                            -1, size_KV, self.num_head, self.values_per_head).permute(0, 2, 1, 3)\n",
    "            \n",
    "        \n",
    "        # calculate the compability\n",
    "        attention = Q_project.matmul(K_project)\n",
    "        attention *= self.scaling_factor\n",
    "        \n",
    "        # if edge attributes are required\n",
    "        if edge_attributes is not None:\n",
    "                \n",
    "            #TODO: edge mask (is it required)\n",
    "            edge_project = self.edge_embedding(edge_attributes).view(\n",
    "                                -1, size_Q, size_Q, self.edge_size_per_head)\n",
    "                \n",
    "            # get enhanced attention inclusing edge attributes\n",
    "            attention_expanded = attention.unsqueeze(-1).expand(-1, -1, -1, -1, self.edge_size_per_head)\n",
    "            \n",
    "            # Expand edge attributes to match the number of attention heads\n",
    "            edge_project_expanded = edge_project.unsqueeze(1).expand(-1, attention.size(1), -1, -1, -1)\n",
    "            \n",
    "            attention = attention_expanded * edge_project_expanded\n",
    "            attention = attention.mean(-1)\n",
    "            \n",
    "            #print(attention.size())\n",
    "        \n",
    "            \n",
    "            \n",
    "        if mask is not None:\n",
    "\n",
    "            if mask.numel() * self.num_head == attention.numel():\n",
    "                m = mask.view(-1, 1, size_Q, size_KV).expand_as(attention)\n",
    "            else:\n",
    "                m = mask.view(-1, 1, 1, size_KV).expand_as(attention)\n",
    "\n",
    "            attention[m.bool()] = -float('inf')\n",
    "            \n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        attention = attention.matmul(V_project).permute(0, 2, 1, 3).contiguous().view(\n",
    "                                                *batch_size, size_Q, self.num_head * self.values_per_head)\n",
    "        \n",
    "        output = self.recombine(attention)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3c26e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoderlayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_head, model_size, ff_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = GraphMultiHeadAttention(num_head, query_size=model_size)\n",
    "        self.BN1 = nn.BatchNorm1d(model_size)\n",
    "        self.FFN_layer1 = nn.Linear(model_size, ff_size)\n",
    "        \n",
    "        self.FFN_layer2 = nn.Linear(ff_size, model_size)\n",
    "        self.BN2 = nn.BatchNorm1d(model_size)\n",
    "        \n",
    "    def forward(self, h, e = None, mask = None):\n",
    "        \n",
    "        h_attn = self.attention(h, edge_attributes = e, mask=mask)\n",
    "        h_bn = self.BN1((h_attn + h).permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        \n",
    "        h_layer1 = F.relu(self.FFN_layer1(h_bn))\n",
    "        h_layer2 = self.FFN_layer2(h_layer1)\n",
    "        \n",
    "        h_out = self.BN2((h_bn + h_layer2).permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        \n",
    "        if mask is not None:\n",
    "            h_out[mask] = 0\n",
    "            \n",
    "        return h_out\n",
    "    \n",
    "class GraphEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder_layer, num_head, model_size, ff_szie):\n",
    "        super().__init__()\n",
    "        \n",
    "        for l in range(encoder_layer):\n",
    "            self.add_module(str(l), GraphEncoderlayer(num_head, model_size, ff_szie))\n",
    "            \n",
    "    def forward(self, h_in, e_in = None,  mask=None):\n",
    "        \n",
    "        h = h_in\n",
    "        e = e_in\n",
    "        \n",
    "        for child in self.children():\n",
    "            h = child(h, e, mask=mask)\n",
    "        return h\n",
    "        \n",
    "        \n",
    "        \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7cf62479",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_encoder = GraphEncoder(encoder_layer=3, num_head=8, model_size=128, ff_szie=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da5ac490",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_feature = 4\n",
    "edge_feature = 1\n",
    "model_size = 128\n",
    "edge_embedding_dim = 64\n",
    "customers = env.nodes\n",
    "edges = env.edge_attributes\n",
    "customer_mask = env.customer_mask\n",
    "vehicle_mask = env.current_vehicle_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f08df179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 25921, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1f9af1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 25921, 64])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depot_embedding = nn.Linear(cust_feature, model_size)\n",
    "cust_embedding = nn.Linear(cust_feature, model_size)\n",
    "edge_embedding = nn.Linear(edge_feature, edge_embedding_dim)\n",
    "\n",
    "cust_emb = torch.cat((\n",
    "            depot_embedding(customers[:, 0:1, :]),\n",
    "            cust_embedding(customers[:, 1:, :])), dim=1)\n",
    "\n",
    "edge_emb = edge_embedding(edges)\n",
    "\n",
    "if customer_mask is not None:\n",
    "    cust_emb[customer_mask] = 0\n",
    "\n",
    "edge_emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42e2fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_emb = edge_emb.view(env.minibatch, env.nodes_count, env.nodes_count, edge_embedding_dim)\n",
    "# edge_emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15a49284",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_encoding = customer_encoder(cust_emb, edge_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6983eb3a",
   "metadata": {},
   "source": [
    "## Graph Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "daf3bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GatAgent(nn.Module):\n",
    "    \n",
    "    def __init__(self, customer_feature, vehicle_feature, model_size=128, layer_count=3, \n",
    "                 num_head=8, ff_size=128, tanh_xplor=10, greedy = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_size = model_size\n",
    "        self.scaling_factor = self.model_size**0.5\n",
    "        self.tanh_xplor = tanh_xplor\n",
    "        self.greedy = greedy\n",
    "        \n",
    "        self.customer_encoder = GatEncoder(input_node_dim = customer_feature, # TODO: need to automate rest of values\n",
    "                                           hidden_node_dim=ff_size, \n",
    "                                           input_edge_dim=1, \n",
    "                                           hidden_edge_dim=16, \n",
    "                                           conv_layers=layer_count)\n",
    "        \n",
    "        self.vehicle_embedding = nn.Linear(vehicle_feature, ff_size, bias=False)\n",
    "        \n",
    "        self.fleet_attention = nn.MultiheadAttention(self.model_size, num_head, \n",
    "                                                     kdim = self.model_size, \n",
    "                                                     vdim=self.model_size)\n",
    "        self.vehicle_attention = nn.MultiheadAttention(self.model_size, num_head)\n",
    "        \n",
    "        self.customer_to_action_projection = nn.Linear(self.model_size, self.model_size) # TODO: MLP instaed of nn.Linear\n",
    "        \n",
    "    \n",
    "    def encode_customers(self, env, customer_mask = None):\n",
    "        \n",
    "        self.customer_representation = self.customer_encoder(env, customer_mask)\n",
    "        if customer_mask is not None:\n",
    "            self.customer_representation[customer_mask] = 0\n",
    "            \n",
    "    \n",
    "        \n",
    "    def vehicle_representation(self, vehicles, vehicle_index, vehicle_mask=None):\n",
    "        \n",
    "        vehicles_embedding = self.vehicle_embedding(vehicles)\n",
    "        \n",
    "        print(vehicles_embedding.size(), self.customer_representation.size())\n",
    "        \n",
    "        fleet_representation, _ = self.fleet_attention(query = vehicles_embedding.permute(1,0, 2),\n",
    "                                                       key = self.customer_representation.permute(1,0, 2),\n",
    "                                                       value = self.customer_representation.permute(1,0, 2))\n",
    "        \n",
    "        vehicle_query = fleet_representation.gather(1, vehicle_index.unsqueeze(2).expand(-1, -1, self.model_size))\n",
    "        \n",
    "        print(vehicle_query.size(), fleet_representation.size())\n",
    "        self.vehicle_representation_, _ = self.vehicle_attention(query = vehicle_query.permute(1,0,2),\n",
    "                                                                key = fleet_representation.permute(1,0,2),\n",
    "                                                                value = fleet_representation.permute(1,0,2))\n",
    "        \n",
    "        return self.vehicle_representation_\n",
    "    \n",
    "    \n",
    "    \n",
    "    def score_customers(self, vehicle_representation):\n",
    "        \n",
    "        compact = torch.bmm(vehicle_representation.permute(1,0,2),\n",
    "                            self.customer_representation.permute(0,2,1))\n",
    "        compact *= self.scaling_factor\n",
    "        \n",
    "        print(compact.size(), vehicle_representation.size())\n",
    "        \n",
    "        if self.tanh_xplor is not None:\n",
    "            compact = self.tanh_xplor*compact.tanh()\n",
    "        \n",
    "        return compact\n",
    "    \n",
    "    \n",
    "    def get_logp(self, compact, vehicle_mask = None):\n",
    "        \n",
    "        compact[vehicle_mask] = -float('inf')\n",
    "        return compact.log_softmax(2).squeeze(1)\n",
    "    \n",
    "    \n",
    "    def step(self, env):\n",
    "        \n",
    "        vehicle_representation_ = self.vehicle_representation(env.vehicles, \n",
    "                                                             env.current_vehicle_index,\n",
    "                                                             env.current_vehicle_mask)\n",
    "        compact = self.score_customers(vehicle_representation_)\n",
    "        logp = self.get_logp(compact, env.current_vehicle_mask)\n",
    "        \n",
    "        if self.greedy:\n",
    "            customer_index = logp.argmax(dim=1, keepdim=True)\n",
    "        else:\n",
    "            customer_index = logp.exp().multinomial(1)\n",
    "\n",
    "        return customer_index, logp.gather(1, customer_index)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, env):\n",
    "        \n",
    "        env.reset()\n",
    "        actions, logps, rewards = [], [], []\n",
    "        \n",
    "        while not env.done:\n",
    "            if env.new_customer:\n",
    "                self.encode_customers(env, env.customer_mask)\n",
    "                \n",
    "            customer_index, logp = self.step(env)\n",
    "            actions.append((env.current_vehicle_index, customer_index))\n",
    "            logps.append(logp)\n",
    "            rewards.append(env.step(customer_index))\n",
    "\n",
    "        return actions, logps, rewards\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bc2ee22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GatAgent(4,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a2e50c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 128]) torch.Size([2, 161, 128])\n",
      "torch.Size([2, 1, 128]) torch.Size([2, 2, 128])\n",
      "torch.Size([2, 1, 161]) torch.Size([1, 2, 128])\n",
      "torch.Size([2, 2, 128]) torch.Size([2, 161, 128])\n",
      "torch.Size([2, 1, 128]) torch.Size([2, 2, 128])\n",
      "torch.Size([2, 1, 161]) torch.Size([1, 2, 128])\n",
      "torch.Size([2, 2, 128]) torch.Size([2, 161, 128])\n",
      "torch.Size([2, 1, 128]) torch.Size([2, 2, 128])\n",
      "torch.Size([2, 1, 161]) torch.Size([1, 2, 128])\n",
      "torch.Size([2, 2, 128]) torch.Size([2, 161, 128])\n",
      "torch.Size([2, 1, 128]) torch.Size([2, 2, 128])\n",
      "torch.Size([2, 1, 161]) torch.Size([1, 2, 128])\n",
      "torch.Size([2, 2, 128]) torch.Size([2, 161, 128])\n",
      "torch.Size([2, 1, 128]) torch.Size([2, 2, 128])\n",
      "torch.Size([2, 1, 161]) torch.Size([1, 2, 128])\n",
      "torch.Size([2, 2, 128]) torch.Size([2, 161, 128])\n",
      "torch.Size([2, 1, 128]) torch.Size([2, 2, 128])\n",
      "torch.Size([2, 1, 161]) torch.Size([1, 2, 128])\n",
      "torch.Size([2, 2, 128]) torch.Size([2, 161, 128])\n",
      "torch.Size([2, 1, 128]) torch.Size([2, 2, 128])\n",
      "torch.Size([2, 1, 161]) torch.Size([1, 2, 128])\n",
      "torch.Size([2, 2, 128]) torch.Size([2, 161, 128])\n",
      "torch.Size([2, 1, 128]) torch.Size([2, 2, 128])\n",
      "torch.Size([2, 1, 161]) torch.Size([1, 2, 128])\n",
      "torch.Size([2, 2, 128]) torch.Size([2, 161, 128])\n",
      "torch.Size([2, 1, 128]) torch.Size([2, 2, 128])\n",
      "torch.Size([2, 1, 161]) torch.Size([1, 2, 128])\n",
      "torch.Size([2, 2, 128]) torch.Size([2, 161, 128])\n",
      "torch.Size([2, 1, 128]) torch.Size([2, 2, 128])\n",
      "torch.Size([2, 1, 161]) torch.Size([1, 2, 128])\n",
      "torch.Size([2, 2, 128]) torch.Size([2, 161, 128])\n",
      "torch.Size([2, 1, 128]) torch.Size([2, 2, 128])\n",
      "torch.Size([2, 1, 161]) torch.Size([1, 2, 128])\n",
      "torch.Size([2, 2, 128]) torch.Size([2, 161, 128])\n",
      "torch.Size([2, 1, 128]) torch.Size([2, 2, 128])\n",
      "torch.Size([2, 1, 161]) torch.Size([1, 2, 128])\n",
      "torch.Size([2, 2, 128]) torch.Size([2, 161, 128])\n",
      "torch.Size([2, 1, 128]) torch.Size([2, 2, 128])\n",
      "torch.Size([2, 1, 161]) torch.Size([1, 2, 128])\n",
      "Forward pass ok for DVRPSR\n"
     ]
    }
   ],
   "source": [
    "actions, logps, rewards = model(env)\n",
    "print(\"Forward pass ok for DVRPSR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e96ec739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[0],\n",
       "          [0]]),\n",
       "  tensor([[ 0],\n",
       "          [35]])),\n",
       " (tensor([[1],\n",
       "          [1]]),\n",
       "  tensor([[137],\n",
       "          [ 22]])),\n",
       " (tensor([[0],\n",
       "          [1]]),\n",
       "  tensor([[ 72],\n",
       "          [147]])),\n",
       " (tensor([[1],\n",
       "          [0]]),\n",
       "  tensor([[ 32],\n",
       "          [132]])),\n",
       " (tensor([[0],\n",
       "          [0]]),\n",
       "  tensor([[ 26],\n",
       "          [101]])),\n",
       " (tensor([[1],\n",
       "          [1]]),\n",
       "  tensor([[ 85],\n",
       "          [148]])),\n",
       " (tensor([[0],\n",
       "          [0]]),\n",
       "  tensor([[55],\n",
       "          [ 0]])),\n",
       " (tensor([[0],\n",
       "          [1]]),\n",
       "  tensor([[8],\n",
       "          [0]])),\n",
       " (tensor([[1],\n",
       "          [0]]),\n",
       "  tensor([[  0],\n",
       "          [102]])),\n",
       " (tensor([[0],\n",
       "          [0]]),\n",
       "  tensor([[63],\n",
       "          [37]])),\n",
       " (tensor([[0],\n",
       "          [1]]),\n",
       "  tensor([[ 88],\n",
       "          [128]])),\n",
       " (tensor([[1],\n",
       "          [0]]),\n",
       "  tensor([[0],\n",
       "          [0]])),\n",
       " (tensor([[0],\n",
       "          [0]]),\n",
       "  tensor([[0],\n",
       "          [0]]))]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dc58d303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-37.],\n",
       "         [-40.]]),\n",
       " tensor([[-36.4398],\n",
       "         [-39.5029]]),\n",
       " tensor([[-36.2398],\n",
       "         [-38.6726]]),\n",
       " tensor([[-35.4363],\n",
       "         [-36.6738]]),\n",
       " tensor([[-35.1854],\n",
       "         [-36.1840]]),\n",
       " tensor([[-33.9776],\n",
       "         [-35.9468]]),\n",
       " tensor([[-33.5333],\n",
       "         [-35.9081]]),\n",
       " tensor([[-33.5521],\n",
       "         [-35.8597]]),\n",
       " tensor([[-34.2660],\n",
       "         [-35.8776]]),\n",
       " tensor([[-33.4706],\n",
       "         [-35.8776]]),\n",
       " tensor([[-33.4493],\n",
       "         [-35.8504]]),\n",
       " tensor([[-34.0729],\n",
       "         [-36.0961]]),\n",
       " tensor([[-64.1527],\n",
       "         [-65.8343]])]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a375f1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268858e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82964b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12507612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a3d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0f31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b10234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7290f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
