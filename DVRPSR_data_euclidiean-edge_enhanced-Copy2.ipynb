{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703636c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d503e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DVRPSR_Dataset(Dataset):\n",
    "\n",
    "    customer_feature = 4 # customer features location (x_i,y_i) and duration of service(d), appearance (u)\n",
    "\n",
    "    @classmethod\n",
    "    def create_data(cls,\n",
    "                    batch_size = 2,\n",
    "                    vehicle_count = 2,\n",
    "                    vehicle_speed = 20, # km/hr\n",
    "                    Lambda = 0.025, # request rate per min\n",
    "                    dod = 0.5,\n",
    "                    horizon = 400,\n",
    "                    fDmean = 10,\n",
    "                    fDstd = 2.5):\n",
    "\n",
    "\n",
    "        # static customer counts V = Lambda*horizon*(1-dod)/(dod+0.5)\n",
    "        V_static = int(Lambda*horizon*(1-dod)/(dod)+0.5)\n",
    "\n",
    "        # total customer count\n",
    "        V = int(Lambda*horizon/(dod) + 0.5)\n",
    "\n",
    "        size = (batch_size, V, 1)\n",
    "        \n",
    "        # initialize the graph of vienna network\n",
    "        graph = cls.initialize_graph()\n",
    "\n",
    "        # get the coordinates of customers\n",
    "        data_vienna = pd.read_csv('./vienna_data/vienna_cordinates.csv')\n",
    "\n",
    "        # get depot coordinates: Id, xcoords, ycoords\n",
    "        depot = cls.get_depot_location(data_vienna)\n",
    "\n",
    "        # get location of customers: id, xcoords, ycoords\n",
    "        locations = cls.get_customers_coordinates(data_vienna, batch_size, V, depot)\n",
    "\n",
    "        # get edges index and attributes, which is distance between one node to others n_i*n_j\n",
    "        edges_index, edges_attributes = cls.get_edges_attributes(batch_size, graph, depot, locations, V)\n",
    "        \n",
    "        ### generate Static_Dynamic customer requests\n",
    "        dynamic_request = cls.generateRandomDynamicRequests(batch_size,\n",
    "                                                            V,\n",
    "                                                            V_static,\n",
    "                                                            fDmean,\n",
    "                                                            fDstd,\n",
    "                                                            Lambda,\n",
    "                                                            horizon)\n",
    "\n",
    "        customers = torch.zeros((batch_size,V,cls.customer_feature))\n",
    "        customers[:,:,:2] = locations[:,:,1:]\n",
    "        customers[:,:,2:4] = dynamic_request\n",
    "\n",
    "\n",
    "\n",
    "        depo = torch.zeros((batch_size, 1, cls.customer_feature))\n",
    "        depo[:,:,0:2] = torch.from_numpy(depot[0][1:])\n",
    "        depo[:,:,2] =  0\n",
    "\n",
    "        nodes = torch.cat((depo, customers), 1)\n",
    "        \n",
    "        dataset = cls(vehicle_count, vehicle_speed, horizon, nodes, V, \n",
    "                      edges_index, edges_attributes, customer_mask = None)\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    def __init__(self, vehicle_count, vehicle_speed, horizon, nodes, V,\n",
    "                 edges_index, edges_attributes, customer_mask=None):\n",
    "        \n",
    "        self.vehicle_count = vehicle_count\n",
    "        self.vehicle_speed = vehicle_speed\n",
    "        self.nodes = nodes\n",
    "        self.vehicle_time_budget = horizon\n",
    "        self.edges_index = edges_index\n",
    "        self.edges_attributes = edges_attributes\n",
    "\n",
    "        self.batch_size, self.nodes_count, d = self.nodes.size()\n",
    "\n",
    "        if d!= self.customer_feature:\n",
    "            raise ValueError(\"Expected {} customer features per nodes, got {}\".format(\n",
    "                self.customer_feature, d))\n",
    "\n",
    "        self.customer_mask = customer_mask\n",
    "        self.customer_count = V\n",
    "        \n",
    "        \n",
    "    def initialize_graph():\n",
    "    \n",
    "        coordinates = pd.read_csv(\"./vienna_data/vienna_dist.csv\", header = None, sep=' ')\n",
    "        coordinates.columns = ['coord1','coord2','dist']\n",
    "        graph = nx.DiGraph()\n",
    "\n",
    "        # add the rows to the graph for shortest path and distance calculations\n",
    "        for _, row in coordinates.iterrows():\n",
    "            graph.add_edge(row['coord1'], row['coord2'], weight=row['dist'])\n",
    "\n",
    "        return graph\n",
    "\n",
    "\n",
    "    def precompute_shortest_path(graph, start_node, end_node):\n",
    "\n",
    "        shortest_path = nx.shortest_path(graph, start_node, end_node)\n",
    "\n",
    "        # TODO: distance need to be normalized afterwords\n",
    "        shortest_path_length = sum(graph.get_edge_data(u, v)['weight'] \n",
    "                                   for u, v in zip(shortest_path, shortest_path[1:]))\n",
    "\n",
    "        return shortest_path, shortest_path_length \n",
    "    \n",
    "    \n",
    "    def get_distanceLL(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "        R = 6371  # Radius of the Earth in kilometers\n",
    "\n",
    "        lat1_rad = math.radians(lat1)\n",
    "        lon1_rad = math.radians(lon1)\n",
    "        lat2_rad = math.radians(lat2)\n",
    "        lon2_rad = math.radians(lon2)\n",
    "\n",
    "        dlat = lat2_rad - lat1_rad\n",
    "        dlon = lon2_rad - lon1_rad\n",
    "\n",
    "        a = math.sin(dlat / 2) ** 2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2) ** 2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "        distance = R * c\n",
    "        return distance\n",
    "    \n",
    "\n",
    "    def get_NearestNodeLL(lat, lon, lats, lons):\n",
    "        nearest = (-1, sys.float_info.max)\n",
    "        for i in range(len(lats)):\n",
    "            dist = DVRPSR_Dataset.get_distanceLL(lat, lon, lats[i], lons[i])\n",
    "            if dist < nearest[1]:\n",
    "                nearest = (i, dist)\n",
    "        return nearest[0]\n",
    "    \n",
    "\n",
    "\n",
    "    def get_depot_location(data_vienna):\n",
    "\n",
    "        ll = (48.178808, 16.438460)\n",
    "        lat = ll[0] / 180 * math.pi\n",
    "        lon = ll[1] / 180 * math.pi\n",
    "        lats = data_vienna['lats']\n",
    "        lons = data_vienna['lons']\n",
    "        depot = DVRPSR_Dataset.get_NearestNodeLL(lat, lon, lats, lons)\n",
    "        depot_coordinates = np.array(data_vienna[data_vienna['id']==depot][['id','xcoords', 'ycoords']])\n",
    "\n",
    "        return depot_coordinates\n",
    "    \n",
    "    def get_customers_coordinates(data_vienna, batch_size, customers_count, depot):\n",
    "        \n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # Excluding depot id from the customers selection\n",
    "        data_vienna_without_depot = data_vienna[data_vienna['id'] != int(depot[0][0])].reset_index()\n",
    "\n",
    "        # Sample customers indices for all batches at once\n",
    "        sampled_customers = torch.multinomial(torch.tensor(data_vienna_without_depot['id'], dtype=torch.float32),\n",
    "                                              num_samples=batch_size * customers_count, replacement=True)\n",
    "        \n",
    "        sampled_customers = sampled_customers.reshape(batch_size, customers_count)\n",
    "\n",
    "        # Gather the sampled locations using the indices\n",
    "        sampled_locations = data_vienna_without_depot.loc[sampled_customers.flatten()].reset_index(drop=True)\n",
    "\n",
    "        # Reshape the locations to match the batch size\n",
    "        locations = sampled_locations.groupby(sampled_locations.index // customers_count)\n",
    "\n",
    "        # Create PyTorch tensors for the batched data\n",
    "        locations_tensors = []\n",
    "        for _, batch in locations:\n",
    "            id_tensor = torch.tensor(batch['id'].values, dtype=torch.long)\n",
    "            coords_tensor = torch.tensor(batch[['xcoords', 'ycoords']].values, dtype=torch.float32)\n",
    "            batch_tensor = torch.cat((id_tensor.unsqueeze(1), coords_tensor), dim=1)\n",
    "            locations_tensors.append(batch_tensor)\n",
    "\n",
    "        return torch.stack(locations_tensors)\n",
    "    \n",
    "    def c_dist(x1,x2):\n",
    "        return ((x1[0]-x2[0])**2+(x1[1]-x2[1])**2)**0.5\n",
    "    \n",
    "    def get_edges_attributes(batch_size, graph, depot, locations, V):\n",
    "    \n",
    "        # all customers ID inclusing depot\n",
    "        \n",
    "        print('Initialzing edges')\n",
    "        edge_depot = torch.zeros((batch_size, 1, 2))\n",
    "        edge_depot[:,:,0] = depot[0][1]\n",
    "        edge_depot[:,:,1] = depot[0][2]\n",
    "        edge_data = torch.cat((edge_depot, locations[:,:,1:3]), dim=1)\n",
    "\n",
    "        # generate edge index\n",
    "        edges_index = []\n",
    "\n",
    "        for i in range(V+1):\n",
    "            for j in range(V+1):\n",
    "                edges_index.append([i, j])\n",
    "        edges_index = torch.LongTensor(edges_index)\n",
    "        edges_index = edges_index.transpose(dim0=0,dim1=1)\n",
    "\n",
    "        # generate nodes attributes\n",
    "        edges_batch = []\n",
    "\n",
    "        for batch in edge_data:\n",
    "            edges = torch.zeros((V+1, V+1, 1), dtype=torch.float32)\n",
    "            for i, node1 in enumerate(batch):\n",
    "                for j, node2 in enumerate(batch):\n",
    "                    distance = DVRPSR_Dataset.c_dist(node1, node2)\n",
    "                    edges[i][j][0] = distance\n",
    "\n",
    "            edges = edges.reshape(-1, 1)\n",
    "            edges_batch.append(edges)\n",
    "\n",
    "        return edges_index, torch.stack(edges_batch)\n",
    "    \n",
    "    \n",
    "    def generateRandomDynamicRequests(batch_size=2 ,\n",
    "                                      V=20,\n",
    "                                      V_static=10,\n",
    "                                      fDmean=10,\n",
    "                                      fDstd=2.5,\n",
    "                                      Lambda=0.025,\n",
    "                                      horizon=400,\n",
    "                                      dep = 0,\n",
    "                                      u = 0):\n",
    "        gen = random.Random()\n",
    "        gen.seed() # uses the default system seed\n",
    "        unifDist = gen.random # uniform distribution\n",
    "        durDist = lambda: max(0.01, gen.gauss(fDmean, fDstd)) # normal distribution with fDmean and fDstd\n",
    "\n",
    "        # TODO: in actual data , we need to add a depo node with corrdinate, which should be removed from selected\n",
    "        #       nodes as well.\n",
    "\n",
    "        requests = []\n",
    "        for b in range(batch_size):\n",
    "\n",
    "            static_request = []\n",
    "            dynamic_request = []\n",
    "            u = 0\n",
    "\n",
    "            while True:\n",
    "                unif = unifDist()\n",
    "                u += -(1/Lambda) * math.log(unif)\n",
    "                if u > horizon or len(dynamic_request) > (V-V_static+2):\n",
    "                    break\n",
    "                d = round(durDist(),2)\n",
    "                while d<=0:\n",
    "                    d = round(durDist(),2)\n",
    "\n",
    "                dynamic_request.append([d, round(u,2)])\n",
    "\n",
    "            for j in range(V-len(dynamic_request)):\n",
    "                d = round(durDist(),2)\n",
    "                while d<=0:\n",
    "                    d = round(durDist(),2)\n",
    "                static_request.append([d,0])\n",
    "\n",
    "            request = static_request+dynamic_request\n",
    "            random.shuffle(request)\n",
    "            requests.append(request)\n",
    "\n",
    "        return torch.tensor(requests)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.customer_mask is None:\n",
    "            return self.nodes[i], self.edges_attributes[i]\n",
    "        else:\n",
    "            return self.nodes[i], self.customer_mask[i], self.edges_attributes[i]\n",
    "\n",
    "    def nodes_generate(self):\n",
    "        if self.customer_mask is None:\n",
    "            yield from self.nodes\n",
    "        else:\n",
    "            yield from (n[m^1] for n,m in zip(self.nodes, self.customer_mask))  \n",
    "            \n",
    "            \n",
    "    def normalize(self):\n",
    "        loc_max, loc_min = self.nodes[:,:,:2].max().item(), self.nodes[:,:,:2].min().item()\n",
    "        loc_max -= loc_min\n",
    "        edge_max_length = self.edges_attributes.max().item()\n",
    "\n",
    "        self.nodes[:,:,:2] -= loc_min\n",
    "        self.nodes[:,:,:2] /= loc_max\n",
    "        self.nodes[:,:,2:] /=self.vehicle_time_budget\n",
    "\n",
    "        self.vehicle_speed *= self.vehicle_time_budget/loc_max\n",
    "        self.vehicle_time_budget = 1\n",
    "        self.edges_attributes /= loc_max\n",
    "        return loc_max, 1\n",
    "\n",
    "    def save(self, folder_path):\n",
    "        torch.save({\n",
    "            'veh_count':self.vehicle_count,\n",
    "            'veh_speed':self.vehicle_speed,\n",
    "            'nodes':self.nodes,\n",
    "            'edges_index':self.edges_index,\n",
    "            'edges_attributes':self.edges_attributes,\n",
    "            'customer_count':self.customer_count,\n",
    "            'customer_mask':self.customer_mask\n",
    "        }, folder_path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, folder_path):\n",
    "        return cls(**torch.load(folder_path))\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a4b362d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialzing edges\n"
     ]
    }
   ],
   "source": [
    "## testing Normalize function\n",
    "\n",
    "data = DVRPSR_Dataset.create_data(batch_size=1, vehicle_count=2, vehicle_speed=, Lambda=0.0125, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "625ec521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5348e+02, -2.7868e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 1.3548e+02,  6.3629e+00,  8.4400e+00,  3.0431e+02],\n",
       "         [ 1.3853e+02,  4.1748e+01,  1.2450e+01,  4.3070e+01],\n",
       "         [ 1.5720e+02,  3.8793e+01,  1.2310e+01,  0.0000e+00],\n",
       "         [ 1.2608e+02,  1.9041e+00,  8.5100e+00,  1.8300e+00],\n",
       "         [ 1.3274e+02,  7.2597e+00,  9.3400e+00,  1.0158e+02],\n",
       "         [ 1.1312e+02, -7.5473e-02,  8.4100e+00,  2.9705e+02],\n",
       "         [ 1.2074e+02,  1.7892e+01,  1.2140e+01,  2.0499e+02],\n",
       "         [ 1.4845e+02, -8.4152e+00,  1.1550e+01,  4.7340e+01],\n",
       "         [ 1.3364e+02, -4.9474e+00,  9.4400e+00,  0.0000e+00],\n",
       "         [ 1.3663e+02,  2.6947e+00,  1.0350e+01,  2.3596e+02]]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nodes\n",
    "nodes = data.nodes\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1c94f26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000],\n",
       "         [0.1219],\n",
       "         [0.2837],\n",
       "         [0.2521],\n",
       "         [0.1678],\n",
       "         [0.1392],\n",
       "         [0.2442],\n",
       "         [0.2339],\n",
       "         [0.0456],\n",
       "         [0.1205],\n",
       "         [0.1070],\n",
       "         [0.1219],\n",
       "         [0.0000],\n",
       "         [0.2145],\n",
       "         [0.2357],\n",
       "         [0.0628],\n",
       "         [0.0174],\n",
       "         [0.1405],\n",
       "         [0.1130],\n",
       "         [0.1187],\n",
       "         [0.0692],\n",
       "         [0.0232],\n",
       "         [0.2837],\n",
       "         [0.2145],\n",
       "         [0.0000],\n",
       "         [0.1141],\n",
       "         [0.2521],\n",
       "         [0.2112],\n",
       "         [0.2955],\n",
       "         [0.1797],\n",
       "         [0.3088],\n",
       "         [0.2835],\n",
       "         [0.2361],\n",
       "         [0.2521],\n",
       "         [0.2357],\n",
       "         [0.1141],\n",
       "         [0.0000],\n",
       "         [0.2914],\n",
       "         [0.2410],\n",
       "         [0.3548],\n",
       "         [0.2538],\n",
       "         [0.2899],\n",
       "         [0.3000],\n",
       "         [0.2509],\n",
       "         [0.1678],\n",
       "         [0.0628],\n",
       "         [0.2521],\n",
       "         [0.2914],\n",
       "         [0.0000],\n",
       "         [0.0516],\n",
       "         [0.0792],\n",
       "         [0.1018],\n",
       "         [0.1487],\n",
       "         [0.0616],\n",
       "         [0.0639],\n",
       "         [0.1392],\n",
       "         [0.0174],\n",
       "         [0.2112],\n",
       "         [0.2410],\n",
       "         [0.0516],\n",
       "         [0.0000],\n",
       "         [0.1264],\n",
       "         [0.0968],\n",
       "         [0.1340],\n",
       "         [0.0739],\n",
       "         [0.0362],\n",
       "         [0.2442],\n",
       "         [0.1405],\n",
       "         [0.2955],\n",
       "         [0.3548],\n",
       "         [0.0792],\n",
       "         [0.1264],\n",
       "         [0.0000],\n",
       "         [0.1178],\n",
       "         [0.2192],\n",
       "         [0.1273],\n",
       "         [0.1429],\n",
       "         [0.2339],\n",
       "         [0.1130],\n",
       "         [0.1797],\n",
       "         [0.2538],\n",
       "         [0.1018],\n",
       "         [0.0968],\n",
       "         [0.1178],\n",
       "         [0.0000],\n",
       "         [0.2307],\n",
       "         [0.1584],\n",
       "         [0.1328],\n",
       "         [0.0456],\n",
       "         [0.1187],\n",
       "         [0.3088],\n",
       "         [0.2899],\n",
       "         [0.1487],\n",
       "         [0.1340],\n",
       "         [0.2192],\n",
       "         [0.2307],\n",
       "         [0.0000],\n",
       "         [0.0919],\n",
       "         [0.0980],\n",
       "         [0.1205],\n",
       "         [0.0692],\n",
       "         [0.2835],\n",
       "         [0.3000],\n",
       "         [0.0616],\n",
       "         [0.0739],\n",
       "         [0.1273],\n",
       "         [0.1584],\n",
       "         [0.0919],\n",
       "         [0.0000],\n",
       "         [0.0496],\n",
       "         [0.1070],\n",
       "         [0.0232],\n",
       "         [0.2361],\n",
       "         [0.2509],\n",
       "         [0.0639],\n",
       "         [0.0362],\n",
       "         [0.1429],\n",
       "         [0.1328],\n",
       "         [0.0980],\n",
       "         [0.0496],\n",
       "         [0.0000]]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edges_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a556a233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d148a511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "l_max = data.nodes[:,:,:2].max().item()\n",
    "l_min = data.nodes[:,:,:2].min().item()\n",
    "print(l_max, l_min)\n",
    "l_max -= l_min\n",
    "print(l_max, l_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cea18563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3548)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_max = data.edges_attributes[:,:,:1].max()\n",
    "e_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "260e9126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3267.2869)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vehicle_speed*400/e_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "039be35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1159.3320040839722"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vehicle_speed*400/l_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "32ff9bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1219])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = torch.pairwise_distance(data.nodes[:,0,:2], data.nodes[:,1,:2])/l_max\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "74d6d543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4a7d0d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9776, 0.0340, 0.0000, 0.0000],\n",
       "         [0.8689, 0.0892, 0.0211, 0.7608],\n",
       "         [0.8873, 0.3029, 0.0311, 0.1077],\n",
       "         [1.0000, 0.2851, 0.0308, 0.0000],\n",
       "         [0.8121, 0.0623, 0.0213, 0.0046],\n",
       "         [0.8523, 0.0946, 0.0234, 0.2539],\n",
       "         [0.7339, 0.0504, 0.0210, 0.7426],\n",
       "         [0.7798, 0.1588, 0.0304, 0.5125],\n",
       "         [0.9472, 0.0000, 0.0289, 0.1183],\n",
       "         [0.8577, 0.0209, 0.0236, 0.0000],\n",
       "         [0.8758, 0.0671, 0.0259, 0.5899]]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fc6bd5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2837])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_norm = torch.pairwise_distance(data.nodes[:,0,:2], data.nodes[:,2,:2])\n",
    "edges_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "82b7fd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0979])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_norm/data.vehicle_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "01fc0426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8983300102099303"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vehicle_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebd818",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class DVRPSR_Environment:\n",
    "    vehicle_feature = 8  # vehicle coordinates(x_i,y_i), veh_time_time_budget, total_travel_time, last_customer,\n",
    "                         # next(destination) customer, last rewards, next rewards\n",
    "    customer_feature = 4\n",
    "\n",
    "    # TODO: change pending cost for rewards\n",
    "\n",
    "    def __init__(self, data, nodes=None, customer_mask=None, edges_attributes = None,\n",
    "                 pending_cost=1, \n",
    "                 dynamic_reward=0.2,\n",
    "                 budget_penalty = 10):\n",
    "\n",
    "        self.vehicle_count = data.vehicle_count\n",
    "        self.vehicle_speed = data.vehicle_speed\n",
    "        self.vehicle_time_budget = data.vehicle_time_budget\n",
    "\n",
    "        self.nodes = data.nodes if nodes is None else nodes\n",
    "        self.edge_index = data.edges_index\n",
    "        self.edge_attributes = data.edges_attributes if edges_attributes is None else edges_attributes\n",
    "        self.init_customer_mask = data.customer_mask if customer_mask is None else customer_mask\n",
    "\n",
    "        self.minibatch, self.nodes_count, _ = self.nodes.size()\n",
    "        self.distance_matrix = self.edge_attributes.view((self.minibatch, self.nodes_count, self.nodes_count))\n",
    "        self.pending_cost = pending_cost\n",
    "        self.dynamic_reward = dynamic_reward\n",
    "        self.budget_penalty = budget_penalty\n",
    "\n",
    "    def _update_current_vehicles(self, dest, customer_index, tau=0):\n",
    "\n",
    "        # calculate travel time\n",
    "        # TODO: 1) in real world setting we need to calculate the distance of arc\n",
    "        # If nodes i and j are directly connected by a road segment (i, j) ∈ A, then t(i,j)=t_ij;\n",
    "        # otherwise, t(i,j)=t_ik1 +t_k1k2 +...+t_knj, where k1,...,kn ∈ V are the nodes along the\n",
    "        # shortest path from node i to node j.\n",
    "        #      2) calculate stating time for each vehicle $\\tau $, currently is set to zero\n",
    "        \n",
    "        # update vehicle previous and next customer id\n",
    "        self.current_vehicle[:, :, 4] = self.current_vehicle[:, :, 5]\n",
    "        self.current_vehicle[:, :, 5] = customer_index\n",
    "        \n",
    "        # get the distance from current vehicle to its next destination\n",
    "        dist = torch.zeros((self.minibatch, 1))\n",
    "        for i in range(self.minibatch):\n",
    "            dist[i, 0] = self.distance_matrix[i][int(self.current_vehicle[i, :, 4])][int(self.current_vehicle[i, :, 5])]\n",
    "            \n",
    "        \n",
    "        # total travel time    \n",
    "        tt = dist / self.vehicle_speed\n",
    "\n",
    "        # customers which are dynamicaly appeared\n",
    "        dyn_cust = (dest[:, :, 3] > 0).float()\n",
    "\n",
    "        # budget left while travelling to destination nodes\n",
    "        budget = tau + tt + dest[:, :, 2]\n",
    "        # print(budget, tau, tt, dest[:,:,2])\n",
    "\n",
    "        # update vehicle features based on destination nodes\n",
    "        self.current_vehicle[:, :, :2] = dest[:, :, :2]\n",
    "        self.current_vehicle[:, :, 2] -= budget\n",
    "        self.current_vehicle[:, :, 3] += tt\n",
    "        self.current_vehicle[:, :, 6] = self.current_vehicle[:, :, 7]\n",
    "        self.current_vehicle[:, :, 7] = -dist\n",
    "\n",
    "        # update vehicles states\n",
    "        self.vehicles = self.vehicles.scatter(1,\n",
    "                                              self.current_vehicle_index[:, :, None].expand(-1, -1, self.vehicle_feature),\n",
    "                                              self.current_vehicle)\n",
    "\n",
    "        return dist, dyn_cust\n",
    "\n",
    "    def _done(self, customer_index):\n",
    "        \n",
    "        self.vehicle_done.scatter_(1, self.current_vehicle_index, torch.logical_or((customer_index == 0), \n",
    "                                                                     (self.current_vehicle[:, :, 2] <= 0)))\n",
    "        # print(self.veh_done, cust_idx==0,self.cur_veh[:,:,2]<=0, (cust_idx==0) | (self.cur_veh[:,:,2]<=0))\n",
    "        self.done = bool(self.vehicle_done.all())\n",
    "\n",
    "    def _update_mask(self, customer_index):\n",
    "\n",
    "        self.new_customer = False\n",
    "        self.served.scatter_(1, customer_index, customer_index > 0)\n",
    "\n",
    "        # cost for a vehicle to go to customer and back to deport considering service duration\n",
    "        cost = torch.zeros((self.minibatch, self.nodes_count,1))\n",
    "        for i in range(self.minibatch):\n",
    "            for j in range(self.nodes_count):\n",
    "                dist_vehicle_customer_depot = self.distance_matrix[i][int(self.current_vehicle[i, :, 4])][j] + \\\n",
    "                                              self.distance_matrix[i][j][0]\n",
    "                cost[i,j] = dist_vehicle_customer_depot\n",
    "                \n",
    "        cost = cost / self.vehicle_speed\n",
    "\n",
    "        cost += self.nodes[:, :, None, 2]\n",
    "\n",
    "        overtime_mask = self.current_vehicle[:, :, None, 2] - cost\n",
    "        overtime_mask = overtime_mask.squeeze(2).unsqueeze(1)\n",
    "        overtime = torch.zeros_like(self.mask).scatter_(1,\n",
    "                                                        self.current_vehicle_index[:, :, None].expand(-1, -1, self.nodes_count),\n",
    "                                                        overtime_mask < 0)\n",
    "\n",
    "        self.mask = self.mask | self.served[:, None, :] | overtime | self.vehicle_done[:, :, None]\n",
    "        self.mask[:, :, 0] = 0  # depot\n",
    "\n",
    "    # updating current vehicle to find the next available vehicle\n",
    "    def _update_next_vehicle(self, veh_index=None):\n",
    "        \n",
    "        if veh_index is None:\n",
    "            avail = self.vehicles[:, :, 3].clone()\n",
    "            avail[self.vehicle_done] = float('inf')\n",
    "            self.current_vehicle_index = avail.argmin(1, keepdim=True)\n",
    "        else:\n",
    "            self.current_vehicle_index = veh_index\n",
    "            \n",
    "        self.current_vehicle = self.vehicles.gather(1, self.current_vehicle_index[:, :, None].expand(-1, -1, self.vehicle_feature))\n",
    "        self.current_vehicle_mask = self.mask.gather(1, self.current_vehicle_index[:, :, None].expand(-1, -1, self.nodes_count))\n",
    "\n",
    "    def _update_dynamic_customers(self):\n",
    "\n",
    "        time = self.current_vehicle[:, :, 3].clone()\n",
    "\n",
    "        if self.init_customer_mask is None:\n",
    "            reveal_dyn_reqs = torch.logical_and((self.customer_mask), (self.nodes[:, :, 3] <= time))\n",
    "        else:\n",
    "            reveal_dyn_reqs = torch.logical_and((self.customer_mask ^ self.init_customer_mask), (self.nodes[:, :, 3] <= time))\n",
    "\n",
    "        if reveal_dyn_reqs.any():\n",
    "            self.new_customer = True\n",
    "            self.customer_mask = self.customer_mask ^ reveal_dyn_reqs\n",
    "            self.mask = self.mask ^ reveal_dyn_reqs[:, None, :].expand(-1, self.vehicle_count, -1)\n",
    "            self.vehicle_done = torch.logical_and(self.vehicle_done, (reveal_dyn_reqs.any(1) ^ True).unsqueeze(1))\n",
    "            self.vehicles[:, :, 3] = torch.max(self.vehicles[:, :, 3], time)\n",
    "            self._update_next_vehicle()\n",
    "\n",
    "    def reset(self):\n",
    "        # reset vehicle (minibatch*veh_count*veh_feature)\n",
    "        self.vehicles = self.nodes.new_zeros((self.minibatch, self.vehicle_count, self.vehicle_feature))\n",
    "        self.vehicles[:, :, :2] = self.nodes[:, :1, :2]\n",
    "        self.vehicles[:, :, 2] = self.vehicle_time_budget\n",
    "\n",
    "        # reset vehicle done\n",
    "        self.vehicle_done = self.nodes.new_zeros((self.minibatch, self.vehicle_count), dtype=torch.bool)\n",
    "        self.done = False\n",
    "\n",
    "        # reset cust_mask\n",
    "        self.customer_mask = self.nodes[:, :, 3] > 0\n",
    "        if self.init_customer_mask is not None:\n",
    "            self.customer_mask = self.customer_mask | self.init_customer_mask\n",
    "\n",
    "        # reset new customers and served customer since now to zero (all false)\n",
    "        self.new_customer = True\n",
    "        self.served = torch.zeros_like(self.customer_mask)\n",
    "\n",
    "        # reset mask (minibatch*veh_count*nodes)\n",
    "        self.mask = self.customer_mask[:, None, :].repeat(1, self.vehicle_count, 1)\n",
    "\n",
    "        # reset current vehicle index, current vehicle, current vehicle mask\n",
    "        self.current_vehicle_index = self.nodes.new_zeros((self.minibatch, 1), dtype=torch.int64)\n",
    "        \n",
    "        self.current_vehicle = self.vehicles.gather(1, \n",
    "                                                    self.current_vehicle_index[:, :, None].expand(-1, -1, self.vehicle_feature))\n",
    "        self.current_vehicle_mask = self.mask.gather(1, \n",
    "                                             self.current_vehicle_index[:, :, None].expand(-1, -1, self.nodes_count))\n",
    "\n",
    "    \n",
    "    def step(self, customer_index, veh_index = None):\n",
    "        dest = self.nodes.gather(1, customer_index[:, :, None].expand(-1, -1, self.customer_feature))\n",
    "        dist, dyn_cust = self._update_current_vehicles(dest, customer_index)\n",
    "\n",
    "        #cust = (dest[:, :, 3] >= 0).float()\n",
    "\n",
    "        self._done(customer_index)\n",
    "        self._update_mask(customer_index)\n",
    "        self._update_next_vehicle(veh_index)\n",
    "\n",
    "        #reward = -dist * (1 - dyn_cust*self.dynamic_reward)\n",
    "        reward = self.current_vehicle[:, :, 7] - self.current_vehicle[:,:,6] + self.dynamic_reward*dyn_cust\n",
    "        pending_static_customers = torch.logical_and((self.served ^ True), \n",
    "                                                     (self.nodes[:, :, 3] == 0)).float().sum(-1,keepdim=True) - 1\n",
    "        \n",
    "        reward -= self.pending_cost*pending_static_customers\n",
    "\n",
    "        if self.done:\n",
    "\n",
    "            if self.init_customer_mask is not None:\n",
    "                self.served += self.init_customer_mask\n",
    "            # penalty for pending customers\n",
    "            pending_customers = torch.logical_and((self.served ^ True), \n",
    "                                                  (self.nodes[:, :, 3] >= 0)).float().sum(-1, keepdim=True) - 1\n",
    "\n",
    "            # TODO: penalty for having unused time budget as well not serving customers\n",
    "            reward -= self.dynamic_reward*pending_customers\n",
    "            \n",
    "\n",
    "        self._update_dynamic_customers()\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def state_dict(self, dest_dict=None):\n",
    "        if dest_dict is None:\n",
    "            dest_dict = {'vehicles': self.vehicles,\n",
    "                         'vehicle_done': self.vehicle_done,\n",
    "                         'served': self.served,\n",
    "                         'mask': self.mask,\n",
    "                         'current_vehicle_index': self.current_vehicle_index}\n",
    "\n",
    "        else:\n",
    "            dest_dict[\"vehicles\"].copy_(self.vehicles)\n",
    "            dest_dict[\"vehicle_done\"].copy_(self.vehicle_done)\n",
    "            dest_dict[\"served\"].copy_(self.served)\n",
    "            dest_dict[\"mask\"].copy_(self.mask)\n",
    "            dest_dict[\"current_vehicle_index\"].copy_(self.current_vehicle_index)\n",
    "\n",
    "        return dest_dict\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.vehicles.copy_(state_dict[\"vehicles\"])\n",
    "        self.vehicle_done.copy_(state_dict[\"vehicle_done\"])\n",
    "        self.served.copy_(state_dict[\"served\"])\n",
    "        self.mask.copy_(state_dict[\"mask\"])\n",
    "        self.current_vehicle_index.copy_(state_dict[\"current_vehicle_index\"])\n",
    "\n",
    "        self.current_vehicle = self.vehicles.gather(1, \n",
    "                                                    self.current_vehicle_index[:, :, None].expand(-1, -1, self.vehicle_feature))\n",
    "        self.current_vehicle_mask = self.mask.gather(1, self.current_vehicle_index[:, :, None].expand(-1, -1, self.customer_feature))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad20a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce_loss(logprobs, rewards, baseline = None, weights = None, discount = 1.0, reduction = 'mean'):\n",
    "    r\"\"\"\n",
    "    :param logprobs:  Iterable of length :math:`L` on tensors of size :math:`N \\times 1`\n",
    "    :param rewards:   Iterable of length :math:`L` on tensors of size :math:`N \\times 1`\n",
    "                    or single tensor of size :math:`N \\times 1` to use rewards cumulated on the whole trajectory\n",
    "    :param baseline:  Iterable of length :math:`L` on tensors of size :math:`N \\times 1`\n",
    "                    or single tensor of size :math:`N \\times 1` to use rewards cumulated on the whole trajectory\n",
    "    :param weights:   Iterable of length :math:`L` on tensors of size :math:`N \\times 1`\n",
    "    :param discount:  Discount applied to cumulated future reward\n",
    "    :param reduction: 'none' No reduction,\n",
    "                      'sum'  Compute sum of loss on batch,\n",
    "                      'mean' Compute mean of loss on batch\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = repeat(1.0)\n",
    "\n",
    "    if isinstance(rewards, torch.Tensor):\n",
    "        if baseline is None:\n",
    "            baseline = torch.zeros_like(rewards)\n",
    "\n",
    "        loss = torch.stack([-logp * w for logp,w in zip(logprobs, weights)]).sum(dim = 0)\n",
    "        loss *= (rewards - baseline.detach())\n",
    "\n",
    "        if baseline.requires_grad:\n",
    "            loss += F.smooth_l1_loss(baseline, rewards)\n",
    "\n",
    "    else:\n",
    "        if baseline is None:\n",
    "            baseline = repeat(torch.zeros_like(rewards[0]))\n",
    "\n",
    "        cumul = torch.zeros_like(rewards[0])\n",
    "        vals = []\n",
    "        for r in reversed(rewards):\n",
    "            cumul = r + discount * cumul\n",
    "            vals.append(cumul)\n",
    "        vals.reverse()\n",
    "\n",
    "        loss = []\n",
    "        bl_loss = []\n",
    "        for val, logp, bl, w in zip(vals, logprobs, baseline, weights):\n",
    "            loss.append( -logp * (val - bl.detach()) * w )\n",
    "            if bl.requires_grad:\n",
    "                bl_loss.append( F.smooth_l1_loss(bl, val) )\n",
    "        loss = torch.stack(loss).sum(dim = 0)\n",
    "\n",
    "        if bl_loss:\n",
    "            loss += torch.stack(bl_loss).sum(dim = 0)\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return loss\n",
    "    elif reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    else: # reduction == 'mean'\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8789c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DVRPSR_Dataset.create_data(batch_size=4, \n",
    "                                  vehicle_count=2,\n",
    "                                  vehicle_speed=1/3, \n",
    "                                  Lambda=0.2, \n",
    "                                  dod=0.75, \n",
    "                                  horizon=600)\n",
    "data.normalize()\n",
    "env = DVRPSR_Environment(data)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eae784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = 'mps' if torch.device('mps') else 'cpu'\n",
    "device = 'cpu'\n",
    "env.nodes = env.nodes.to(device)\n",
    "env.edge_attributes = env.edge_attributes.to(device)\n",
    "env.edge_index = env.edge_index.to(device)\n",
    "env.edge_index.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16844ad1",
   "metadata": {},
   "source": [
    "## Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51333e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "import math\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f284f3",
   "metadata": {},
   "source": [
    "## Graph Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f34c0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_head, query_size, key_size = None, value_size = None, edge_dim_size = None, bias = False):\n",
    "        \n",
    "        super(GraphMultiHeadAttention, self).__init__()\n",
    "        self.num_head = num_head\n",
    "        self.query_size = query_size\n",
    "        \n",
    "        self.key_size = self.query_size if key_size is None else key_size\n",
    "        self.value_size = self.key_size if value_size is None else value_size\n",
    "        self.edge_dim_size = self.query_size//2 if edge_dim_size is None else edge_dim_size\n",
    "        \n",
    "        self.scaling_factor = self.key_size**-0.5\n",
    "        \n",
    "        self.keys_per_head = self.key_size // self.num_head\n",
    "        self.values_per_head = self.value_size // self.num_head\n",
    "        self.edge_size_per_head = self.edge_dim_size\n",
    "        \n",
    "        self.edge_embedding = nn.Linear(self.edge_dim_size, self.edge_size_per_head, bias = bias)\n",
    "        self.query_embedding = nn.Linear(self.query_size, self.num_head * self.keys_per_head, bias = bias)\n",
    "        self.key_embedding = nn.Linear(self.key_size, self.num_head * self.keys_per_head, bias = bias)\n",
    "        self.value_embedding = nn.Linear(self.value_size, self.num_head * self.values_per_head, bias = bias)\n",
    "        self.recombine = nn.Linear(self.num_head * self.values_per_head, self.value_size, bias = bias)\n",
    "        \n",
    "        \n",
    "        self.K_project_pre = None\n",
    "        self.V_project_pre = None\n",
    "        \n",
    "        self.initialize_weights()\n",
    "\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        #TODO: add xavier initialziation as well\n",
    "        \n",
    "        nn.init.uniform_(self.query_embedding.weight, -self.scaling_factor, self.scaling_factor)\n",
    "        nn.init.uniform_(self.key_embedding.weight, -self.scaling_factor, self.scaling_factor)\n",
    "        inv_sq_dv = self.value_size ** -0.5\n",
    "        nn.init.uniform_(self.value_embedding.weight, -inv_sq_dv, inv_sq_dv)\n",
    "        \n",
    "    def precompute(self, keys, values = None):\n",
    "        \n",
    "        values = keys if values is None else values\n",
    "        \n",
    "        size_KV = keys.size(-2)\n",
    "        \n",
    "        self.K_project_pre = self.key_embedding(keys).view(\n",
    "                             -1, size_KV, self.num_head, self.keys_per_head).permute(0, 2, 3, 1)\n",
    "        \n",
    "        self.V_project_pre = self.value_embedding(values).view(\n",
    "                              -1, size_KV, self.num_head, self.values_per_head).permute(0, 2, 1, 3)\n",
    "        \n",
    "        \n",
    "    def forward(self, queries, keys = None, values = None, edge_attributes = None, mask = None, edge_mask=None):\n",
    "        \n",
    "        *batch_size, size_Q, _ = queries.size()\n",
    "        \n",
    "        # get queries projection\n",
    "        Q_project = self.query_embedding(queries).view(\n",
    "                              -1, size_Q, self.num_head, self.keys_per_head).permute(0, 2, 1, 3)\n",
    "        \n",
    "        # get keys projection\n",
    "        if keys is None:\n",
    "            if self.K_project_pre is None:\n",
    "                size_KV = size_Q\n",
    "                K_project = self.key_embedding(queries).view(\n",
    "                                -1, size_KV, self.num_head, self.keys_per_head).permute(0, 2, 3, 1)\n",
    "            else:\n",
    "                size_KV = self.K_project_pre.size(-1)\n",
    "                K_project = self.K_project_pre\n",
    "        else:\n",
    "            size_KV = keys.size(-2)\n",
    "            K_project = self.key_embedding(keys).view(\n",
    "                            -1, size_KV, self.num_head, self.keys_per_head).permute(0, 2, 3, 1)\n",
    "            \n",
    "         # get values projection   \n",
    "        if values is None:\n",
    "            if self.V_project_pre is None:\n",
    "                V_project = self.value_embedding(queries).view(\n",
    "                                -1, size_KV, self.num_head, self.values_per_head).permute(0, 2, 1, 3)\n",
    "            else:\n",
    "                V_project = self.V_project_pre\n",
    "        else:\n",
    "            V_project = self.value_embedding(values).view(\n",
    "                            -1, size_KV, self.num_head, self.values_per_head).permute(0, 2, 1, 3)\n",
    "            \n",
    "        \n",
    "        # calculate the compability\n",
    "        attention = Q_project.matmul(K_project)\n",
    "        attention *= self.scaling_factor\n",
    "        \n",
    "        # if edge attributes are required\n",
    "        if edge_attributes is not None:\n",
    "                \n",
    "            #TODO: edge mask (is it required)\n",
    "            edge_project = self.edge_embedding(edge_attributes).view(\n",
    "                                -1, size_Q, size_Q, self.edge_size_per_head)\n",
    "                \n",
    "            # get enhanced attention inclusing edge attributes\n",
    "            attention_expanded = attention.unsqueeze(-1).expand(-1, -1, -1, -1, self.edge_size_per_head)\n",
    "            \n",
    "            # Expand edge attributes to match the number of attention heads\n",
    "            edge_project_expanded = edge_project.unsqueeze(1).expand(-1, attention.size(1), -1, -1, -1)\n",
    "            \n",
    "            attention = attention_expanded * edge_project_expanded\n",
    "            attention = attention.mean(-1)\n",
    "            \n",
    "            #print(attention.size())\n",
    "        \n",
    "            \n",
    "            \n",
    "        if mask is not None:\n",
    "\n",
    "            if mask.numel() * self.num_head == attention.numel():\n",
    "                m = mask.view(-1, 1, size_Q, size_KV).expand_as(attention)\n",
    "            else:\n",
    "                m = mask.view(-1, 1, 1, size_KV).expand_as(attention)\n",
    "\n",
    "            attention[m.bool()] = -float('inf')\n",
    "            \n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        attention = attention.matmul(V_project).permute(0, 2, 1, 3).contiguous().view(\n",
    "                                                *batch_size, size_Q, self.num_head * self.values_per_head)\n",
    "        \n",
    "        output = self.recombine(attention)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bfd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoderlayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_head, model_size, ff_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = GraphMultiHeadAttention(num_head, query_size=model_size)\n",
    "        self.BN1 = nn.BatchNorm1d(model_size)\n",
    "        self.FFN_layer1 = nn.Linear(model_size, ff_size)\n",
    "        \n",
    "        self.FFN_layer2 = nn.Linear(ff_size, model_size)\n",
    "        self.BN2 = nn.BatchNorm1d(model_size)\n",
    "        \n",
    "    def forward(self, h, e = None, mask = None):\n",
    "        \n",
    "        h_attn = self.attention(h, edge_attributes = e, mask=mask)\n",
    "        h_bn = self.BN1((h_attn + h).permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        \n",
    "        h_layer1 = F.relu(self.FFN_layer1(h_bn))\n",
    "        h_layer2 = self.FFN_layer2(h_layer1)\n",
    "        \n",
    "        h_out = self.BN2((h_bn + h_layer2).permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        \n",
    "        if mask is not None:\n",
    "            h_out[mask] = 0\n",
    "            \n",
    "        return h_out\n",
    "    \n",
    "class GraphEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder_layer, num_head, model_size, ff_szie):\n",
    "        super().__init__()\n",
    "        \n",
    "        for l in range(encoder_layer):\n",
    "            self.add_module(str(l), GraphEncoderlayer(num_head, model_size, ff_szie))\n",
    "            \n",
    "    def forward(self, h_in, e_in = None,  mask=None):\n",
    "        \n",
    "        h = h_in\n",
    "        e = e_in\n",
    "        \n",
    "        for child in self.children():\n",
    "            h = child(h, e, mask=mask)\n",
    "        return h\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5083689",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tetsing the encoder-decoder model\n",
    "\n",
    "customer_encoder = GraphEncoder(encoder_layer=3, num_head=8, model_size=128, ff_szie=256)\n",
    "\n",
    "cust_feature = 4\n",
    "edge_feature = 1\n",
    "model_size = 128\n",
    "edge_embedding_dim = 64\n",
    "customers = env.nodes\n",
    "edges = env.edge_attributes\n",
    "customer_mask = env.customer_mask\n",
    "vehicle_mask = env.current_vehicle_mask\n",
    "\n",
    "depot_embedding = nn.Linear(cust_feature, model_size)\n",
    "cust_embedding = nn.Linear(cust_feature, model_size)\n",
    "edge_embedding = nn.Linear(edge_feature, edge_embedding_dim)\n",
    "\n",
    "cust_emb = torch.cat((\n",
    "            depot_embedding(customers[:, 0:1, :]),\n",
    "            cust_embedding(customers[:, 1:, :])), dim=1)\n",
    "\n",
    "edge_emb = edge_embedding(edges)\n",
    "\n",
    "if customer_mask is not None:\n",
    "    cust_emb[customer_mask] = 0\n",
    "\n",
    "print(edge_emb.size())\n",
    "\n",
    "cust_encoding = customer_encoder(cust_emb, edge_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f32ba0",
   "metadata": {},
   "source": [
    "## Graph Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphAttentionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, customer_feature, vehicle_feature, model_size=128, encoder_layer=3, \n",
    "                 num_head=8, ff_size=128, tanh_xplor=10, edge_embedding_dim = 64, greedy = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # get models parameters for encoding-decoding\n",
    "        self.model_size = model_size\n",
    "        self.scaling_factor = self.model_size**0.5\n",
    "        self.tanh_xplor = tanh_xplor\n",
    "        self.greedy = greedy\n",
    "        \n",
    "        # Initialize encoder and embeddings\n",
    "        self.customer_encoder = GraphEncoder(encoder_layer=3, num_head=8, model_size=128, ff_szie=512)\n",
    "        self.customer_embedding = nn.Linear(customer_feature, model_size)\n",
    "        self.depot_embedding = nn.Linear(customer_feature, model_size)\n",
    "        \n",
    "        # initialize edge embedding\n",
    "        self.edge_embedding = nn.Linear(1, edge_embedding_dim)\n",
    "        \n",
    "        # Initialize vehicle embedding and encoding\n",
    "        #self.vehicle_embedding = nn.Linear(vehicle_feature, ff_size, bias=False)\n",
    "         \n",
    "        self.fleet_attention = GraphMultiHeadAttention(num_head, vehicle_feature, model_size)\n",
    "        \n",
    "        self.vehicle_attention = GraphMultiHeadAttention(num_head, model_size)\n",
    "        \n",
    "        # customer projection\n",
    "        self.customer_projection = nn.Linear(self.model_size, self.model_size) # TODO: MLP instaed of nn.Linear\n",
    "        \n",
    "        \n",
    "    \n",
    "    def encode_customers(self, env, customer_mask = None):\n",
    "        \n",
    "        customer_emb = torch.cat((self.depot_embedding(env.nodes[:,:1,:]),\n",
    "                                  self.customer_embedding(env.nodes[:,1:,:])), dim=1)\n",
    "        if customer_mask is not None:\n",
    "            customer_emb[customer_mask] = 0\n",
    "            \n",
    "        edge_emb = self.edge_embedding(env.edge_attributes)\n",
    "        \n",
    "        self.customer_encoding = self.customer_encoder(customer_emb, edge_emb, mask = customer_mask)\n",
    "        \n",
    "        self.fleet_attention.precompute(self.customer_encoding)\n",
    "        \n",
    "        self.customer_representation = self.customer_projection(self.customer_encoding)\n",
    "        if customer_mask is not None:\n",
    "            self.customer_representation[customer_mask] = 0\n",
    "            \n",
    "    \n",
    "        \n",
    "    def vehicle_representation(self, vehicles, vehicle_index, vehicle_mask=None):\n",
    "        \n",
    "        #vehicles_embedding = self.vehicle_embedding(vehicles)\n",
    "        \n",
    "        #print(vehicles_embedding.size(), self.customer_representation.size())\n",
    "        \n",
    "        fleet_representation = self.fleet_attention(vehicles, mask = vehicle_mask)\n",
    "        \n",
    "#         print(fleet_representation.size())\n",
    "        \n",
    "        vehicle_query = fleet_representation.gather(0, vehicle_index.unsqueeze(2).expand(-1, -1, self.model_size))\n",
    "        \n",
    "        self._vehicle_representation = self.vehicle_attention(vehicle_query, \n",
    "                                                              fleet_representation,\n",
    "                                                              fleet_representation)\n",
    "        \n",
    "        return self._vehicle_representation\n",
    "    \n",
    "    \n",
    "    \n",
    "    def score_customers(self, vehicle_representation):\n",
    "        \n",
    "        #print(vehicle_representation.size(), self.customer_representation.size())\n",
    "        compact = torch.bmm(vehicle_representation,\n",
    "                            self.customer_representation.transpose(2,1))\n",
    "        compact *= self.scaling_factor\n",
    "        \n",
    "        if self.tanh_xplor is not None:\n",
    "            compact = self.tanh_xplor*compact.tanh()\n",
    "        \n",
    "        return compact\n",
    "    \n",
    "    \n",
    "    def get_prop(self, compact, vehicle_mask = None):\n",
    "        \n",
    "        compact = compact\n",
    "        \n",
    "        compact[vehicle_mask] = -float('inf')\n",
    "        compact = F.softmax(compact, dim=-1)\n",
    "        return compact\n",
    "    \n",
    "    \n",
    "    def step(self, env, old_action=None):\n",
    "        \n",
    "        _vehicle_representation = self.vehicle_representation(env.vehicles, \n",
    "                                                              env.current_vehicle_index,\n",
    "                                                              env.current_vehicle_mask)\n",
    "        \n",
    "        compact = self.score_customers(_vehicle_representation)\n",
    "        prop = self.get_prop(compact, env.current_vehicle_mask)\n",
    "        #print(compact.size())\n",
    "        \n",
    "        # step actions based on model act or evalaute\n",
    "        if old_action is not None:\n",
    "            \n",
    "            # get entropy\n",
    "            dist = Categorical(prop)\n",
    "            old_actions_logp = dist.log_prob(old_action[:, 1].unsqueeze(-1))\n",
    "            entropy = dist.entropy()\n",
    "            \n",
    "            is_done = float(env.done)\n",
    "            \n",
    "            entropy = entropy * (1. - is_done)\n",
    "            old_actions_logp = old_actions_logp*(1. - is_done)\n",
    "            return old_action[:, 1].unsqueeze(-1), entropy, old_actions_logp\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            dist = Categorical(prop)\n",
    "            \n",
    "            if self.greedy:\n",
    "                _, customer_index = p.max(dim=-1)\n",
    "            else:\n",
    "                customer_index = dist.sample()\n",
    "                \n",
    "            is_done = float(env.done)\n",
    "\n",
    "            logp = dist.log_prob(customer_index)\n",
    "            logp = logp * (1. - is_done)\n",
    "            \n",
    "            return customer_index, logp\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, env, old_actions=None, is_update=False):\n",
    "        \n",
    "        if is_update:\n",
    "            env.reset()\n",
    "            entropys, old_actions_logps = [], []\n",
    "            \n",
    "            steps = old_actions.size(0)\n",
    "\n",
    "            for i in range(steps):\n",
    "                if env.new_customer:\n",
    "                    self.encode_customers(env, env.customer_mask)\n",
    "                    \n",
    "                \n",
    "                if i < steps-1:\n",
    "                    old_action = old_actions[i,:,:]\n",
    "                    next_action = old_actions[i+1,:,:]\n",
    "                else:\n",
    "                    # this would be the last action which the agent takes and envrionment is done\n",
    "                    old_action = old_actions[i,:,:]\n",
    "                    next_action = old_actions[i,:,:]\n",
    "                    \n",
    "        \n",
    "                next_vehicle_index = next_action[:,0].unsqueeze(-1)\n",
    "                #print(next_vehicle_index)\n",
    "            \n",
    "\n",
    "                customer_index, entropy, logp = self.step(env, old_action)\n",
    "                \n",
    "                env.step(customer_index, next_vehicle_index)\n",
    "                \n",
    "                old_actions_logps.append(logp)\n",
    "                entropys.append(entropy)\n",
    "                \n",
    "            entropys = torch.cat(entropys, dim=1)\n",
    "            num_e = entropys.ne(0).float().sum(1)\n",
    "            entropy = entropys.sum(1) / num_e\n",
    "            \n",
    "            old_actions_logps = torch.cat(old_actions_logps, dim=1)\n",
    "            old_actions_logps = old_actions_logps.sum(1)\n",
    "            \n",
    "                \n",
    "            return entropy, old_actions_logps, 0\n",
    "        \n",
    "        else:\n",
    "            env.reset()\n",
    "            actions, logps, rewards = [], [], []\n",
    "\n",
    "            while not env.done:\n",
    "                if env.new_customer:\n",
    "                    self.encode_customers(env, env.customer_mask)\n",
    "\n",
    "                customer_index, logp = self.step(env)\n",
    "                actions.append((env.current_vehicle_index, customer_index))\n",
    "                logps.append(logp)\n",
    "                rewards.append(env.step(customer_index))\n",
    "\n",
    "            #actions = torch.cat(actions, dim=1)\n",
    "            logps = torch.cat(logps, dim=1)\n",
    "            logp = logps.sum(dim=1)\n",
    "            \n",
    "            rewards = torch.cat(rewards, dim=1)\n",
    "            rewards = rewards.sum(dim=1)\n",
    "            \n",
    "\n",
    "            return actions, logp, rewards\n",
    "\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ee22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing GraphAttentionModel\n",
    "\n",
    "model = GraphAttentionModel(4, 8)\n",
    "actions, logps, rewards = model(env, old_actions=None, is_update = False)\n",
    "print(\"Forward pass ok for DVRPSR\")\n",
    "\n",
    "from itertools import repeat\n",
    "#loss = reinforce_loss(logps, rewards)\n",
    "#loss.backward()\n",
    "print(\"Backward pass ok for DVRPSR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c918d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d96cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formate_old_actions(actions):\n",
    "    old_actions = []\n",
    "\n",
    "    for action in actions:\n",
    "        old_action = []\n",
    "        for i in range(action[0].size(0)):\n",
    "            old_action.append([action[0][i].item(), action[1][i].item()])\n",
    "        old_actions.append(old_action)             \n",
    "    return old_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872bce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_actions = formate_old_actions(actions)\n",
    "old_actions = torch.tensor(old_actions)\n",
    "old_actions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ea117",
   "metadata": {},
   "source": [
    "## PPO agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e74ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \n",
    "    # critic will take environment as imput and ouput the values for loss function \n",
    "    # which is basically the estimation of complexity of actions\n",
    "    \n",
    "    def __init__(self, model, customers_count, ff_size = 512):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.model = model\n",
    "        self.ff_layer1 = nn.Linear(customers_count, ff_size)\n",
    "        self.ff_layer2 = nn.Linear(ff_size, customers_count)\n",
    "        \n",
    "    def eval_step(self, env, compatibility, customer_index):\n",
    "        compact = compatibility.clone()\n",
    "        compact[env.current_vehicle_mask] = 0\n",
    "        \n",
    "        value = self.ff_layer1(compact)\n",
    "        value = F.relu(value)\n",
    "        value = self.ff_layer2(value)\n",
    "        \n",
    "        val = value.gather(2, customer_index.unsqueeze(1)).expand(-1, 1, -1)\n",
    "        return val.squeeze(1)\n",
    "        \n",
    "        \n",
    "    def __call__(self, env):\n",
    "        self.model.encode_customers(env)\n",
    "        env.reset()\n",
    "        \n",
    "        values = []\n",
    "        \n",
    "        while not env.done:\n",
    "            \n",
    "            _vehicle_presentation = self.model.vehicle_representation(env.vehicles,\n",
    "                                                                     env.current_vehicle_index,\n",
    "                                                                     env.current_vehicle_mask)\n",
    "            compatibility = self.model.score_customers(_vehicle_presentation)\n",
    "            prop = self.model.get_prop(compatibility, env.current_vehicle_mask)\n",
    "            dist = Categorical(prop)\n",
    "            customer_index = dist.sample()\n",
    "            \n",
    "            values.append(self.eval_step(env, compatibility, customer_index))\n",
    "            \n",
    "            return values[0]\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c0b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_net = Critic(model, 161, 512)\n",
    "critic_net(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad60bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor_Critic(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                customer_feature,\n",
    "                vehicle_feature,\n",
    "                customers_count,\n",
    "                model_size = 128,\n",
    "                encoder_layer = 3,\n",
    "                num_head = 8,\n",
    "                ff_size_actor = 128,\n",
    "                ff_size_critic = 512,\n",
    "                tanh_xplor = 10,\n",
    "                edge_embedding_dim = 64,\n",
    "                greedy = False):\n",
    "        \n",
    "        super(Actor_Critic, self).__init__()\n",
    "        \n",
    "        model = GraphAttentionModel(customer_feature, vehicle_feature, model_size, encoder_layer, \n",
    "                                        num_head, ff_size_actor, tanh_xplor, edge_embedding_dim, greedy)\n",
    "        self.actor = model\n",
    "        \n",
    "        self.critic = Critic(model, customers_count, ff_size_critic)\n",
    "        \n",
    "    def act(self, env, old_actions=None, is_update=False):\n",
    "        \n",
    "        actions, logps, rewards = self.actor(env)\n",
    "        return actions, logps, rewards\n",
    "    \n",
    "    \n",
    "    def evaluate(self, env, old_actions, is_update):\n",
    "        \n",
    "        entropys, old_logps, _ = self.actor(env, old_actions, is_update)\n",
    "        values = self.critic(env)\n",
    "        return entropys, old_logps, values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989422cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.nodes = []\n",
    "        self.edge_attributes = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.log_probs = []\n",
    "        \n",
    "    def clear(self):\n",
    "        self.nodes.clear()\n",
    "        self.edge_attributes.clear()\n",
    "        self.actions.clear()\n",
    "        self.rewards.clear()\n",
    "        self.log_probs.clear()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "import math\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import time\n",
    "\n",
    "# from PPORolloutBaselin import RolloutBaseline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "max_grad_norm = 2\n",
    "\n",
    "class AgentPPO:\n",
    "    \n",
    "    def __init__(self,\n",
    "                customer_feature,\n",
    "                vehicle_feature,\n",
    "                customers_count,\n",
    "                model_size = 128,\n",
    "                encoder_layer = 3,\n",
    "                num_head = 8,\n",
    "                ff_size_actor = 128,\n",
    "                ff_size_critic = 512,\n",
    "                tanh_xplor = 10,\n",
    "                edge_embedding_dim = 64,\n",
    "                greedy = False,\n",
    "                learning_rate = 3e-4,\n",
    "                ppo_epoch = 3,\n",
    "                batch_size = 4,\n",
    "                entropy_value = 0.2,\n",
    "                epsilon_clip = 0.2):\n",
    "        \n",
    "        self.policy = Actor_Critic(customer_feature, vehicle_feature, customers_count, model_size = 128,\n",
    "                                   encoder_layer = 3, num_head = 8, ff_size_actor = 128, ff_size_critic = 512,\n",
    "                                   tanh_xplor = 10, edge_embedding_dim = 64, greedy = False)\n",
    "        \n",
    "        self.old_policy = Actor_Critic(customer_feature, vehicle_feature, customers_count, model_size = 128,\n",
    "                                   encoder_layer = 3, num_head = 8, ff_size_actor = 128, ff_size_critic = 512,\n",
    "                                   tanh_xplor = 10, edge_embedding_dim = 64, greedy = False)\n",
    "        \n",
    "        self.old_policy.load_state_dict(self.policy.state_dict())\n",
    "        \n",
    "        # ppo update parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.ppo_epoch = ppo_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.entropy_value = entropy_value\n",
    "        self.epsilon_clip = epsilon_clip\n",
    "        self.batch_index = 1\n",
    "        \n",
    "        # initialize the Adam optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.policy.parameters(), lr=learning_rate)\n",
    "        self.MSE_loss = nn.MSELoss()\n",
    "        \n",
    "        # actor-critic parameters\n",
    "        self.customer_feature = customer_feature\n",
    "        self.vehicle_feature = vehicle_feature\n",
    "        self.customers_count = customers_count\n",
    "        self.model_size = model_size\n",
    "        self.encoder_layer = encoder_layer\n",
    "        self.num_head = num_head\n",
    "        self.ff_size_actor = ff_size_actor\n",
    "        self.ff_size_critic = ff_size_critic\n",
    "        self.tanh_xplor = tanh_xplor\n",
    "        self.edge_embedding_dim = edge_embedding_dim\n",
    "        self.greedy = greedy\n",
    "        \n",
    "        self.times, self.losses, self.rewards, self.critic_rewards = [], [], [], []\n",
    "        \n",
    "    def advantage_normalization(self, advantage):\n",
    "        \n",
    "        std = advantage.std()\n",
    "        \n",
    "        assert std != 0. and not torch.isnan(std), 'Need nonzero std'\n",
    "        \n",
    "        norm_advantage = (advantage - advantage.mean()) / (advantage.std() + 1e-8)\n",
    "        return norm_advantage\n",
    "    \n",
    "    def pad_actions(self, actions):\n",
    "        max_len = max([a.size(0) for a in actions])\n",
    "        padded_actions = []\n",
    "        for a in actions:\n",
    "            pad_length = max_len - a.size(0)\n",
    "            padded_a = F.pad(a, (0, 0, 0, pad_length))\n",
    "            padded_actions.append(padded_a)\n",
    "        return torch.stack(padded_actions), max_len\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def update(self, memory, epoch, data=None, env=None):\n",
    "        \n",
    "        old_nodes = torch.stack(memory.nodes)\n",
    "        old_edge_attributes = torch.stack(memory.edge_attributes)\n",
    "        old_rewards = torch.stack(memory.rewards).unsqueeze(-1)\n",
    "        old_log_probs = torch.stack(memory.log_probs).unsqueeze(-1)\n",
    "        \n",
    "        # preprocessing on old actions\n",
    "        padded_actions, max_length = self.pad_actions(memory.actions)\n",
    "        \n",
    "        # create update data for PPO\n",
    "        datas = []\n",
    "        \n",
    "        #print(memory.actions.size())\n",
    "        \n",
    "        for i in range(old_nodes.size(0)):\n",
    "            \n",
    "            data_to_load = Data(nodes = old_nodes[i],\n",
    "                                edge_attributes = old_edge_attributes[i],\n",
    "                                actions = padded_actions[i],\n",
    "                                rewards = old_rewards[i],\n",
    "                                log_probs = old_log_probs[i])\n",
    "            \n",
    "            datas.append(data_to_load)\n",
    "        #print(datas[0], self.batch_size)\n",
    "            \n",
    "        \n",
    "            \n",
    "        self.policy.to(device)\n",
    "        \n",
    "        data_loader = DataLoader(datas, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        scheduler = LambdaLR(self.optimizer, lr_lambda=lambda f: 0.96 ** epoch)\n",
    "        value_buffer = 0\n",
    "        \n",
    "        env = env if env is not None else DVRPSR_Environment\n",
    "        \n",
    "        for i in range(self.ppo_epoch):\n",
    "            \n",
    "            self.policy.train()\n",
    "            epoch_start = time.time()\n",
    "            start = epoch_start\n",
    "            \n",
    "            self.times, self.losses, self.rewards, self.critic_rewards = [], [], [], []\n",
    "            \n",
    "            for batch_index, minibatch_data in enumerate(data_loader):\n",
    "                \n",
    "                self.batch_index += 1\n",
    "                \n",
    "                if data.customer_mask is None:\n",
    "                    nodes = minibatch_data.nodes.to(device)\n",
    "                    customer_mask = None\n",
    "                    edge_attributes = minibatch_data.edge_attributes.to(device)\n",
    "                    \n",
    "                nodes = nodes.view(self.batch_size, self.customers_count, self.customer_feature)\n",
    "                edge_attributes = edge_attributes.view(self.batch_size, self.customers_count*self.customers_count,1)\n",
    "                \n",
    "                old_actions_for_env = minibatch_data.actions.view(self.batch_size, max_length,2).permute(1,0,2)\n",
    "                \n",
    "                dyna_env = env(data, nodes, customer_mask, edge_attributes)\n",
    "                \n",
    "                entropy, log_probs, values = self.policy.evaluate(dyna_env, old_actions_for_env, True)\n",
    "                \n",
    "                # normalize the rewards and get the MSE loss with critics values\n",
    "                R = minibatch_data.rewards\n",
    "                R_norm = self.advantage_normalization(R)\n",
    "                \n",
    "                print(R_norm, values.size())\n",
    "                \n",
    "                mse_loss = self.MSE_loss(R_norm, values)\n",
    "                \n",
    "                # PPO ration (r(0)_t)\n",
    "                ratio = torch.exp(log_probs - minibatch_data.log_probs)\n",
    "                \n",
    "                # PPO advantage\n",
    "                advantage = R_norm - values.detach()\n",
    "                \n",
    "                # PPO overall loss function\n",
    "                actor_loss1 = ratio * advantage\n",
    "                actor_loss2 = torch.clamp(ratio, 1-self.epsilon_clip, 1+self.epsilon_clip)*advantage\n",
    "                \n",
    "                actor_loss = torch.min(actor_loss1, actor_loss2)\n",
    "                \n",
    "                # total loss\n",
    "                loss = actor_loss + 0.5*mse_loss - self.entropy_value*entropy\n",
    "                \n",
    "                # optimizer and backpropogation\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.mean().backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.policy.parameters(), max_grad_norm)\n",
    "                self.optimizer.step()\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "                self.rewards.append(torch.mean(R_norm.detach()).item())\n",
    "                self.losses.append(torch.mean(loss.detach()).item())\n",
    "                self.critic_rewards.append(torch.mean(values.detach()).item())\n",
    "            \n",
    "        self.old_policy.load_state_dict(self.policy.state_dict())\n",
    "        \n",
    "# if __name__ == '__main__':\n",
    "#     raise Exception('Cannot be called from main')\n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d197eb",
   "metadata": {},
   "source": [
    "## Train PPO Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f6cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cpu' if torch.backends.mps.is_available()else 'cpu')\n",
    "\n",
    "customers_count = 21\n",
    "\n",
    "class TrainPPOAgent:\n",
    "    \n",
    "    def __init__(self,\n",
    "                customer_feature,\n",
    "                vehicle_feature,\n",
    "                customers_count,\n",
    "                model_size = 128,\n",
    "                encoder_layer = 3,\n",
    "                num_head = 8,\n",
    "                ff_size_actor = 128,\n",
    "                ff_size_critic = 512,\n",
    "                tanh_xplor = 10,\n",
    "                edge_embedding_dim = 64,\n",
    "                greedy = False,\n",
    "                learning_rate = 3e-4,\n",
    "                ppo_epoch = 3,\n",
    "                batch_size = 4,\n",
    "                entropy_value = 0.2,\n",
    "                epsilon_clip = 0.2,\n",
    "                epoch = 40,\n",
    "                timestep = 2):\n",
    "        \n",
    "        self.greedy = greedy\n",
    "        self.memory = Memory()\n",
    "        self.batch_size = batch_size\n",
    "        self.update_timestep = timestep\n",
    "        self.epoch = epoch\n",
    "        self.agent = AgentPPO(customer_feature, vehicle_feature, customers_count, model_size = 128,\n",
    "                              encoder_layer = 3, num_head = 8, ff_size_actor = 128, ff_size_critic = 512,\n",
    "                              tanh_xplor = 10, edge_embedding_dim = 64, greedy = False, learning_rate = 3e-4,\n",
    "                              ppo_epoch = 3, batch_size = 4, entropy_value = 0.2, epsilon_clip = 0.2)\n",
    "        \n",
    "        \n",
    "    def run_train(self, datas, env, batch_size):\n",
    "        \n",
    "        train_data_loader = DataLoader(datas, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "        memory = Memory()\n",
    "        self.agent.old_policy.to(device)\n",
    "        \n",
    "        costs = []\n",
    "        \n",
    "        for i in range(self.epoch):\n",
    "            \n",
    "            print('running epoch {}'.format(i))\n",
    "            self.agent.old_policy.train()\n",
    "            times, losses, rewards1, critic_rewards = [], [], [], []\n",
    "\n",
    "            \n",
    "            epoch_start = time.time()\n",
    "            start_time = epoch_start\n",
    "            \n",
    "            for batch_index, minibatch in enumerate(train_data_loader):\n",
    "                \n",
    "                if datas.customer_mask is None:\n",
    "                    nodes, customer_mask, edge_attributes = minibatch[0], None, minibatch[1]\n",
    "                    \n",
    "                #print(nodes.size(), edge_attributes.size())\n",
    "                \n",
    "                nodes = nodes.view(batch_size, customers_count, 4)\n",
    "                edge_attributes = edge_attributes.view(batch_size, customers_count*customers_count, 1)\n",
    "                \n",
    "                nodes.to(device)\n",
    "                edge_attributes.to(device)\n",
    "                \n",
    "                #print(nodes.size(), self.batch_size)\n",
    "                \n",
    "                \n",
    "                dyna_env = env(datas, nodes, customer_mask, edge_attributes)\n",
    "                \n",
    "                actions, logps, rewards = self.agent.old_policy.act(dyna_env)\n",
    "                \n",
    "                ## formate the actions for memory\n",
    "                actions = formate_old_actions(actions)\n",
    "                actions = torch.tensor(actions)\n",
    "                actions = actions.permute(1, 0, 2)\n",
    "                \n",
    "                actions = actions.to(torch.device('cpu')).detach()\n",
    "                logps   = logps.to(torch.device('cpu')).detach()\n",
    "                rewards = rewards.to(torch.device('cpu')).detach()\n",
    "                \n",
    "                for i in range(self.batch_size):\n",
    "                    memory.nodes.append(nodes[i])\n",
    "                    memory.edge_attributes.append(edge_attributes[i])\n",
    "                    memory.rewards.append(rewards[i])\n",
    "                    memory.log_probs.append(logps[i])\n",
    "                    memory.actions.append(actions[i])\n",
    "                    \n",
    "                if (batch_index+1) % self.update_timestep == 0:\n",
    "                    self.agent.update(memory, i, datas, env)\n",
    "                    memory.clear()\n",
    "                    \n",
    "                time_Space = 100\n",
    "                rewards1.append(torch.mean(rewards.detach()).item())\n",
    "                \n",
    "                if (batch_index+1) % time_Space == 0:\n",
    "                    end = time.time()\n",
    "                    times.append(end - start)\n",
    "                    start = end\n",
    "                    mean_reward = np.mean(rewards1[-time_Space:])\n",
    "                    print('  Batch %d/%d, reward: %2.3f,took: %2.4fs' %(batch_idx, len(data_loader), \n",
    "                                                                        mean_reward, times[-1]))\n",
    "                    \n",
    "                    \n",
    "                ### TODO: test epoch code/function    \n",
    "                \n",
    "    \n",
    "def train():\n",
    "        \n",
    "    class RunBuilder():\n",
    "        @staticmethod\n",
    "\n",
    "        def get_runs(params):\n",
    "\n",
    "            Run = namedtuple('Run', params.keys())\n",
    "            runs = []\n",
    "            for v in product(*params.values()):\n",
    "                runs.append(Run(*v))\n",
    "            return runs\n",
    "\n",
    "    params = OrderedDict(customer_feature = [4],\n",
    "             vehicle_feature = [8],\n",
    "             customers_count = [21],\n",
    "             model_size = [128],\n",
    "             encoder_layer = [3],\n",
    "             num_head = [8],\n",
    "             ff_size_actor = [128],\n",
    "             ff_size_critic = [512],\n",
    "             tanh_xplor = [10],\n",
    "             edge_embedding_dim = [64],\n",
    "             greedy = [False],\n",
    "             learning_rate = [3e-4],\n",
    "             ppo_epoch = [3],\n",
    "             batch_size = [4],\n",
    "             entropy_value = [0.2],\n",
    "             epsilon_clip = [0.2],\n",
    "             epoch = [4],\n",
    "             timestep = [2])  \n",
    "\n",
    "\n",
    "    runs = RunBuilder.get_runs(params)\n",
    "\n",
    "    for customer_feature, vehicle_feature, customers_count, model_size, \\\n",
    "        encoder_layer, num_head, ff_size_actor, ff_size_critic, tanh_xplor, edge_embedding_dim, greedy,\\\n",
    "        learning_rate, ppo_epoch, batch_size, entropy_value, epsilon_clip, epoch, timestep in runs:\n",
    "\n",
    "        data = DVRPSR_Dataset.create_data(batch_size=batch_size*2, vehicle_speed=1/3)\n",
    "        data.normalize()\n",
    "        env = DVRPSR_Environment\n",
    "        \n",
    "        trainppo = TrainPPOAgent(customer_feature, vehicle_feature, customers_count, model_size,\n",
    "                                 encoder_layer, num_head, ff_size_actor, ff_size_critic, tanh_xplor, \n",
    "                                 edge_embedding_dim, greedy,learning_rate, ppo_epoch, batch_size, \n",
    "                                 entropy_value, epsilon_clip, epoch, timestep)\n",
    "        \n",
    "        trainppo.run_train(data, env, batch_size)\n",
    "        \n",
    "\n",
    "   \n",
    "\n",
    "train()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4080a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = []\n",
    "# for i in range(4):\n",
    "#     datas = Data(nodes = data.nodes[i],\n",
    "#                  customer_mask = data.customer_mask[i] if data.customer_mask is not None else 'None',\n",
    "#                  edge_attributes = data.edges_attributes[i])\n",
    "#     train_data.append(datas)\n",
    "    \n",
    "train_data_loader = DataLoader(data, batch_size=4, shuffle=True)\n",
    "print(train_data_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21813134",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_index, minibatch in enumerate(train_data_loader):\n",
    "    print(minibatch[1])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1797ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    nodes, customer_mask, edge_attributes = minibatch.nodes, minibatch.customer_mask, minibatch.edge_attributes\n",
    "    print(nodes.size(), customer_mask.size(), edge_attributes.size())\n",
    "\n",
    "    nodes = nodes.view(batch_size, customers_count, 4)\n",
    "    edge_attributes = edge_attributes.view(batch_size, customers_count*customers_count, 1)\n",
    "    if customer_mask is not None:\n",
    "        customer_mask = customer_mask.view(batch_size, customers_count, 1)\n",
    "        customer_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12b1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b8d2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d806d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea23be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98fc7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268858e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82964b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12507612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a3d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0f31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b10234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7290f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
